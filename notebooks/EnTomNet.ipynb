{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661b332f-6eae-4acc-9a92-3d6207778a21",
   "metadata": {},
   "source": [
    "# ToMnet  \n",
    "\n",
    "In this notebook we are going to develop the codebase for ToMNet to work on our simulation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3637e333-6b37-42de-a0ae-75f9db6fc9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pymc\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de85f71e-7d64-4264-9500-ae64e257ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import osmnx as ox\n",
    "\n",
    "# Adjust this path as needed to point to your project root\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757e0029",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd1a603-1b06-4747-8c23-62d35a466e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "mp.set_start_method('fork', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e8c6d4-ffd3-44d8-8a23-6d37a93f6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_world_src.environment.campus_env import CampusEnvironment\n",
    "from real_world_src.agents.agent_factory import AgentFactory\n",
    "from real_world_src.agents.agent_species import ShortestPathAgent\n",
    "from real_world_src.simulation.simulator import Simulator\n",
    "#from real_world_src.simulation.experiment_1 import Simulator\n",
    "\n",
    "from real_world_src.utils.run_manager import RunManager\n",
    "from real_world_src.utils.config import VISUAL_CONFIG\n",
    "from real_world_src.utils.config import get_agent_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495bee3-fe4c-449e-b383-71dffececdab",
   "metadata": {},
   "source": [
    "## Step 1: Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29bfc584-7cfe-408f-be2b-f7d5b68b44b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started new simulation run #4\n",
      "All visualizations will be saved to: /root/Theory-of-mind/notebooks/visuals/run_4_20250625_130223\n",
      "Loading map data for University of California, San Diego, La Jolla, CA, USA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment loaded with 3136 nodes and 8704 edges\n"
     ]
    }
   ],
   "source": [
    "# Create a run manager\n",
    "run_manager = RunManager('visuals')\n",
    "run_dir = run_manager.start_new_run()\n",
    "\n",
    "# Initialize campus environment\n",
    "campus = CampusEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d36b7b-9778-4e7c-b6e6-9946da46e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to establish the set of common goals (just choose the landmark nodes)\n",
    "goals = [469084068, 49150691, 768264666, 1926666015, 1926673385, 49309735,\n",
    "         273627682, 445989107, 445992528, 446128310, 1772230346, 1926673336, \n",
    "         2872424923, 3139419286, 4037576308]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c8ddb05-8af6-4915-b424-59f6d79ea0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# if you used dill, just replace pickle with dill\n",
    "\n",
    "with open('data/agents.pkl', 'rb') as f:\n",
    "    agents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2f34921-df42-40b0-9b12-4b2df0e4bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/path_data.json\", 'r') as file:\n",
    "    path_data = json.load(file)\n",
    "\n",
    "with open(\"./data/goal_data.json\", 'r') as file:\n",
    "    goal_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c93c2e69-3ea5-402a-b014-f49b1a88dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_keys_to_int(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {int(k) if isinstance(k, str) and k.isdigit() else k: convert_keys_to_int(v) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [convert_keys_to_int(item) for item in data]\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d09bd6a6-181a-485f-bfd4-80db4d858f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_data = convert_keys_to_int(goal_data)\n",
    "path_data = convert_keys_to_int(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb94a293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [10287722097, 10287722098, 7180458320, 10287722101, 10287722103, 7180469572, 7180469562, 7180469571, 7180469570, 10287734757, 7180469569, 5973392484, 10287701220, 10282621354, 10282621352, 10282621353, 5973392477, 12242411857, 12242411842, 1926673385, 1926673336], 1: [9681289454, 9681289486, 9990697277, 9131115149, 10028680338, 9681289487, 9681289482, 9099230484, 10825625401, 9131115136, 9131115124, 10825625265, 10825625264, 10825625266, 9099230483, 9099230481, 9099230480, 9681216665, 2872424924, 9886044515, 9886044514, 9456403537, 9886044230, 446130583, 3701741646, 5742738421, 9675336075, 768264666, 3333766414, 5394721596, 10299244134, 5394721591, 7180485021, 7179725216, 7179725224, 454862513, 7179725220, 447621416, 447637140, 447635692, 7179685056, 5390812819, 7179565954, 5390812787, 7179588596, 4037576308], 2: [7179630163, 7179630164, 7179630138, 7179630166, 7179630167, 7179630168, 7179630169, 7179588654, 7179588656, 7179588642, 5466326131, 10261555877, 10261555874, 7179588643, 7179588627, 7179588644, 7179588645, 7179588646, 9642608244, 7179588647, 7179588648, 7179588615, 7179588649, 7179588650, 7179588651, 7990587621, 7179588607, 7179588592, 7179588595, 7179565960, 7179565953, 7179565949, 12256231265, 12186966197, 7179658877, 7179685058, 7179685072, 7179685075, 6296458760, 5529658591, 5529658589, 7179725222, 7179725216, 7180485021, 5394721591, 10299244134, 5394721596, 3333766414, 446616503, 1146841843, 1146841833, 5811887320, 4868801842, 1146863120, 1146863123, 1146863130, 446128299, 446128311, 446128310], 3: [10825615565, 9681289461, 9681289471, 9681289486, 9990697277, 9131115149, 10028680338, 9681289487, 9681289482, 9099230484, 10825625401, 9131115136, 9131115124, 10825625265, 10825625264, 10825625266, 9099230483, 9099230481, 8861736082, 9146901571, 9146901593, 9146901567, 7316852640, 5457413138, 4022670373, 5546567879, 5546567865, 5546567898, 5546567901, 9620619953, 469081875, 10297064190, 9622038216, 9622059678, 9622059676, 1715024517, 8994595979, 10297059264, 10297059268, 5391208975, 10309785025, 10309785024, 469084068], 4: [5391193406, 5538551741, 5391193402, 5404644401, 5391193405, 7161876382, 1446008141, 49504463, 7237743310, 7161923989, 7237743290, 7237743291, 7179588593, 4037576308, 7179588596, 5390812787, 7179565954, 5390812819, 7179685056, 447635692, 447637140, 447621416, 7179725220, 454862513, 7179725224, 7179725216, 7180485021, 5394721591, 10299244134, 5394721596, 3333766414, 768264666], 5: [9842899683, 9842899684, 9842899685, 9842899686, 9842899661, 9842899663, 5973380951, 5973392477, 12242411857, 12242411859, 12242411860, 12242411862, 12242411863, 7180469574, 9990697272, 7180469573, 2016829244, 7180458321, 7180458379, 2993062672, 2993062668, 2993062664, 7180458154, 9863143459, 7180458176, 5801803417, 10309785019, 9641821983, 469084068], 6: [10282667166, 10282667164, 10279001415, 8085649268, 8085649272, 8085649273, 5934982831, 1989046927, 5935081749, 9641914645, 9630910094, 4023228690, 9630910092, 4023183266, 10282833379, 10285438400, 10285438391, 9625384597, 9622059688, 1926666015, 7180458322, 12521392946, 49463411, 2993062668, 2993062664, 7180458154, 9863143459, 7180458176, 5801803417, 10309785019, 9641821983, 469084068], 7: [8905639874, 8905639854, 10309785018, 10309785021, 10309785020, 469084068, 5404634603, 9815476367, 469084101, 1176646981, 5986666652, 469082581, 5986666648, 469084070, 7180458125, 9620618699, 7180458170, 2993062633, 8908715202, 8908715204, 8861736063, 9125448451, 9867139448, 9867139445, 9867139442, 9574118157, 9408616471, 9408616468, 7179565949, 7179565953, 7179565960, 7179588595, 7179588592, 7179588607, 7990587621, 7179588651, 7179588650, 7179588649, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 6433577305, 3139419286], 8: [11597450926, 11597450929, 5538555030, 11597450936, 11597450935, 11597450939, 11597450945, 11597450944, 11597450940, 9630909959, 3687377589, 3687377587, 3687377586, 2930609913, 8085649233, 447640985, 447640953, 8085649234, 8085649240, 49429968, 8085649282, 8085622110, 8085649293, 8085649298, 5973397110, 5973397108, 8085649300, 8085622107, 8085649310, 8085622108, 10289788054, 5935130725, 10287844481, 9674860399, 10289788025, 8166713598, 9630910066, 9630910067, 10282604892, 10282621309, 9630910070, 9630910075, 9630910077, 9630910078, 10291723243, 446606685, 5457413150, 8708060834, 5457413144, 9880108367, 4023183266, 10282833379, 10296008979, 10296008981, 4023183267, 10296008982, 10295979870, 1715024598, 10296001360, 5406225464, 3464861413, 11750711840, 7311197591, 9456334313, 9456334309, 9146901571, 9681216665, 2872424924, 9886044515, 9886044514, 9456403537, 9886044230, 446130583, 3701741646, 5742738421, 9675336075, 768264666, 3333766414, 5394721596, 324739415, 7180469577, 7180469576, 7180469575, 445989086, 445989107], 9: [10266434399, 10266434400, 10266434403, 5935081762, 10280786542, 10280786545, 9880108368, 9880108369, 9880108365, 9880108367, 4023183266, 10282833379, 10285438400, 10285438391, 9625384597, 9622059688, 1926666015, 7180458323, 7180458276, 2993062666, 2993062665, 1715024582, 5448402860, 10311860666, 5391208974, 5404634605, 5391208975, 10309785025, 469084101, 1176646981, 5986666652, 469082581, 5986666648, 469084070, 7180458125, 9620618699, 7180458170, 2993062633, 8908715203, 8522708968, 8522708981, 8908715199, 49463428, 1176649664, 2993062640, 49150691], 10: [5740082875, 5740082876, 5740082877, 5388224308, 7249339431, 7161876379, 9544330409, 7161876384, 7161923989, 7237743290, 7237743291, 7179588593, 4037576308, 7179588596, 5390812787, 7179565954, 7179565949, 9408616468, 9408616471, 9574118157, 9867139442, 9867139445, 9867139448, 9125448451, 8861736063, 8908715204, 8908715202, 2993062633, 7180458170, 9620618699, 7180458125, 469084070, 5986666648, 469082581, 5986666652, 1176646981, 469084101, 10309785025, 5391208975, 5404634605, 5391208974, 10311860666, 5448402860, 1715024582, 2993062665, 2993062666, 7180458276, 7180458323, 1926666015], 11: [12072377550, 10553246949, 12072377525, 12072377528, 12256265397, 10299528791, 7179685083, 9611588635, 7179725200, 10028680333, 10299265351, 768264666, 9456403558, 9612217735, 1146841843, 1146841833, 5811887320, 4868801842, 1146863120, 445992528], 12: [7179630172, 7179658696, 5466068421, 5466059061, 5538555412, 2478669728, 5538555415, 7179588655, 273627682, 4536669341, 7179588642, 5466326131, 10261555877, 10261555874, 7179588643, 7179588627, 7179588644, 7179588645, 7179588646, 9642608244, 7179588647, 7179588648, 7179588615, 7179588649, 7179588650, 7179588651, 7990587621, 7179588607, 7179588592, 7179588595, 7179565960, 7179565953, 7179565949, 12256231265, 12186966197, 7179658877, 7179685058, 7179685072, 7179685075, 6296458760, 5529658591, 5529658589, 7179725222, 7179725216, 7180485021, 5394721591, 10299244134, 5394721596, 3333766414, 768264666], 13: [7180450257, 7180458170, 5430976754, 5430976761, 7180458116, 5983732118, 4553390952, 7179725195, 49655807, 9611588639, 9620618673, 1361121389, 5391010350, 1361121406, 1361121331, 10299258505, 10296096680, 10296096665, 446616561, 5391230841, 5432894231, 3297844022, 5457413133, 5742738421, 9456403559, 446616501, 9612217735, 1146841843, 1146841833, 5811887320, 4868801842, 1146863120, 445992528], 14: [11972409289, 471275043, 914259719, 914259708, 5811901152, 11970887718, 10825138803, 10825138800, 5811663003, 446128315, 9456403543, 9456403568, 9456403566, 9456403570, 446130583, 5390959120, 3297844023, 5432894231, 5391230841, 446616561, 10296096665, 10296096680, 10299258505, 1361121331, 1361121406, 5391010350, 1361121389, 9620618673, 9611588639, 49655807, 7179725195, 4553390952, 4553390941, 49721328, 10553246952, 9840480984, 9125448453, 8861736063, 8861736065, 8861736064, 8522708975, 8522708977, 8908715198, 49463428, 1176649664, 2993062640, 49150691], 15: [9408616468, 9408616471, 9867133513, 9739748081, 9867139424, 12072377542, 9125448454, 10553246949, 12072377525, 12072377528, 12256265397, 10299528791, 7179685083, 9611588635, 7179725200, 10028680333, 10299265351, 768264666, 9675336075, 5742738421, 3701741646, 446130583, 9886044230, 9456403537, 9886044514, 9886044515, 2872424924, 2872424923], 16: [8370173787, 7179630146, 7179630171, 5466326126, 12068458769, 6269754982, 3139408393, 3333758514, 3139408385, 6269754976, 7179588615, 7179588649, 7179588650, 7179588651, 7990587621, 7179588607, 7179588592, 7179588595, 7179565960, 7179565953, 7179565949, 9408616468, 9408616471, 9574118157, 9867139442, 9867139445, 9867139448, 9125448451, 8861736063, 8908715204, 8908715202, 2993062633, 7180458170, 9620618699, 7180458125, 469084070, 5986666648, 469082581, 5986666652, 1176646981, 469084101, 9815476367, 5404634603, 469084068], 17: [10299265346, 10299265347, 10299265345, 10553146306, 10553232133, 5432894231, 3297844022, 5457413133, 5742738421, 9456403559, 446616501, 9612217735, 1146841843, 1146841833, 5811887320, 4868801842, 1146863120, 445992528], 18: [2338944705, 1926666011, 1926666015, 7180458323, 7180458363, 1926666013, 9886047934, 9886047936, 9886047932, 9886047938, 4554611506, 9886047940, 5546557183, 7180458297, 7180458339, 469081881, 10296140538, 5404634618, 469081879, 469081878, 469081877, 9620619953, 469081875, 10297064190, 10299244033, 9429180937, 1361121381, 5448402852, 1361121324, 7179725194, 446616561, 10553146306, 10299265345, 5457413137, 768264666, 3333766414, 5394721596, 324739415, 7180469577, 7180469576, 7180469575, 445989086, 445989107], 19: [8921957007, 8921957004, 8921957000, 8921956995, 8921956997, 9408642069, 9408642072, 1533709584, 7180485070, 1196394851, 445989099, 446001726, 9675671137, 1533685318, 536367019, 536367015, 7180485026, 9612295423, 536366858, 7180485023, 446656756, 1146834982, 7464948170, 5811887324, 4868801842, 1146863120, 1146863123, 1146863130, 446128299, 446128311, 446128310], 20: [10296008987, 10296008988, 10296008982, 10295979870, 1715024598, 10296001360, 5406225464, 3464861413, 11750711840, 7311197591, 10825625356, 9456334312, 10825625285, 9456334308, 8861736082, 9099230480, 2872424923], 21: [10279001416, 9880108068, 10279001417, 10279001419, 10279001414, 10282667162, 9880108070, 9641914655, 8085649268, 8085649272, 8085649273, 5934982831, 1989046927, 5935081749, 9641914645, 5935081753, 10295648346, 914043411, 914043430, 49550453, 10825615534, 9612217722, 9612217721, 9612217720, 9612217731, 9612217719, 9681289483, 9099230482, 9620619989, 9131115124, 10825625265, 10825625264, 10825625266, 9099230483, 9099230481, 9099230480, 2872424923], 22: [8851759232, 8851756712, 4868801218, 7150807343, 9067479131, 9612266992, 10768068864, 10768068857, 8235254797, 9408642063, 1388150630, 324535395, 9408642060, 445988588, 446690226, 7180485067, 1196394851, 445989083, 445989107, 5457413160, 10296110009, 10296088704, 10296110075, 445989240, 10296088688, 7179725218, 7179725221, 454862518, 454862513, 7179725222, 5529658589, 5529658591, 1668259348, 1668259352, 6296458761, 6296458763, 9611588628, 9611588629, 7179725188, 7179685082, 9429180956, 12186966196, 12186966198, 12256231224, 12186999705, 12186999708, 12256231227, 10553246949, 12072377550, 12072377549, 10553246969, 9125448453, 8861736063, 8861736065, 8861736064, 8522708975, 8522708977, 8908715198, 49463428, 1176649664, 2993062640, 49150691], 23: [469081875, 10297064190, 10299244033, 9429180937, 1361121381, 5448402852, 1361121324, 7179725194, 446616561, 10553146306, 10299265345, 5457413137, 768264666, 3333766414, 5394721596, 324739415, 7180469577, 7180469576, 7180469575, 445989086, 445989107], 24: [11838001794, 11838001793, 11838001769, 11837871266, 11838001795, 10180295247, 10180295250, 10295637750, 914043410, 11030490971, 10282833388, 10295648348, 10295648331, 8921798256, 5935081752, 9630910097, 5935081748, 10266091475, 1772230346], 25: [10266029765, 3337511375, 3337511379, 471275280, 9630910136, 471275282, 9880108176, 471275278, 9880108074, 3337511384, 9880108064, 5934982832, 8085649272, 8085649273, 5934982831, 1989046927, 5935081749, 9641914645, 9630910094, 4023228690, 9630910092, 4023183266, 10282833379, 10285438400, 10285438391, 9625384597, 9622059688, 1926666015, 7180458323, 7180458276, 2993062666, 2993062665, 1715024582, 5448402860, 10311860666, 5391208974, 5404634605, 5391208975, 10309785025, 469084101, 1176646981, 5986666652, 469082581, 5986666648, 469084070, 7180458125, 9620618699, 7180458170, 2993062633, 8908715202, 8908715204, 8861736063, 9125448451, 9867139448, 9867139445, 9867139442, 9574118157, 9408616471, 9408616468, 7179565949, 7179565953, 7179565960, 7179588595, 7179588592, 7179588607, 7990587621, 7179588651, 7179588650, 7179588649, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 10261555874, 10261555877, 5466326131, 7179588642, 4536669341, 273627682], 26: [5551778718, 658984821, 658984717, 658984053, 5446951527, 658984059, 5446951521, 48899387, 5446951522, 49504441, 5388236178, 7161876382, 1446008141, 49504463, 7237743310, 7161923989, 7237743290, 7237743291, 7179588593, 4037576308, 7179588596, 5390812787, 7179565954, 7179565949, 9408616468, 9408616471, 9574118157, 9867139442, 9867139445, 9867139448, 9125448451, 8861736063, 8908715204, 8908715202, 2993062633, 7180458170, 9620618699, 7180458125, 469084070, 5986666648, 469082581, 5986666652, 1176646981, 469084101, 10309785025, 5391208975, 5404634605, 5391208974, 10311860666, 5448402860, 1715024582, 2993062665, 2993062666, 7180458276, 7180458323, 1926666015], 27: [1352176236, 1352176304, 7965230952, 1352176342, 1352176355, 1352176392, 3451647253, 7179588736, 3326353507, 3326353509, 5745765321, 3326356072, 7179588776, 12556955247, 5565181504, 7179588755, 7179588763, 7179588746, 7179588765, 7179588764, 4515887425, 7179588595, 7179565960, 7179565953, 9579010287, 6868505371, 49150677, 10301347700, 2993062639, 49150691], 28: [1668259895, 469081878, 469081877, 9620619953, 469081875, 10297064190, 10299244033, 9429180937, 1361121381, 5448402852, 1361121324, 7179725194, 446616561, 10553146306, 10299265345, 5457413137, 768264666], 29: [471954451, 536380635, 7737751716, 3418056008, 9845790731, 10273923944, 10273923943, 10273923945, 10273923946, 445992528, 1146863105, 10241316977, 446128299, 446128311, 446128310, 446647553, 9456403573, 9456403547, 9456403543, 9456403568, 9456403537, 9456403580, 9610102429, 9886044246, 11750864586, 11750864589, 9681362121, 9681362119, 5546567892, 5546567879, 5546567865, 469081882, 469081878, 469081879, 5404634618, 10296140538, 469081881, 7180458339, 7180458297, 5546557183, 9886047940, 4554611506, 9886047938, 9886047932, 9886047936, 9886047934, 1926666013, 7180458363, 7180458323, 1926666015], 30: [1190394772, 1176657662, 7179685057, 7179685054, 7179685074, 7179685071, 447621458, 447621416, 7179725220, 454862513, 7179725224, 7179725216, 7180485021, 5394721591, 10299244134, 5394721596, 3333766414, 768264666, 9675336075, 5742738421, 3701741646, 446130583, 9886044230, 9456403537, 9886044514, 9886044515, 2872424924, 9681216665, 9099230480, 9099230481, 9099230483, 10825625266, 10825625264, 10825625265, 9131115124, 9620619989, 9099230482, 9681289483, 9612217719, 9612217731, 9612217720, 9612217721, 9612217722, 10825615534, 49550453, 914043430, 914043411, 10295648346, 5935081753, 9641914645, 9630910097, 5935081748, 10266091475, 1772230346], 31: [5404632949, 5406225437, 7180458190, 3798588088, 5404629713, 319438800, 9620619917, 9620618700, 9620618699, 7180458172, 9620618692, 5983732113, 7180458116, 5983732118, 4553390952, 7179725195, 49655807, 9611588639, 9620618673, 1361121389, 5391010350, 1361121406, 1361121331, 10299258505, 10296096680, 10296096665, 446616561, 5391230841, 5432894231, 3297844022, 5457413133, 5742738421, 9456403559, 446616501, 9612217735, 1146841843, 1146841833, 5811887320, 4868801842, 1146863120, 445992528], 32: [5921568250, 7179565981, 7179565982, 7179565960, 7179565953, 7179565949, 12256231265, 12186966197, 7179658877, 7179685058, 7179685072, 7179685075, 6296458760, 5529658591, 5529658589, 7179725222, 7179725216, 7180485021, 5394721591, 10299244134, 5394721596, 3333766414, 446616503, 1146841843, 1146841833, 5811887320, 4868801842, 1146863120, 445992528], 33: [10301407436, 10301407437, 10301407493, 7180458105, 7180458102, 9552931566, 6059250359, 9552931569, 10297059295, 9552931562, 1545508762, 10299192807, 1361121344, 1361121381, 5448402852, 1361121324, 5391230841, 5432894231, 3297844022, 5457413133, 5742738421, 9456403559, 9456403563, 5390959627, 446645809, 446647557, 9886044307, 9456403573, 446647553, 446128310], 34: [9067479121, 4868801218, 7150807343, 9067479131, 9612266992, 10768068864, 10768068857, 8235254797, 9408642063, 1388150630, 324535395, 9408642060, 445988588, 446690226, 7180485067, 1196394851, 445989083, 445989107, 5457413160, 10296110009, 10296088704, 10296110075, 445989240, 10296088688, 7179725218, 7179725221, 454862518, 454862513, 7179725222, 5529658589, 5529658591, 1668259348, 1668259352, 6296458761, 6296458763, 9611588628, 9611588629, 7179725188, 7179685082, 9429180956, 12186966196, 12186966198, 12256231224, 12186999705, 12186999708, 12256231227, 10553246949, 12072377550, 12072377549, 10553246969, 9125448453, 8861736063, 8861736065, 8861736064, 8522708975, 8522708977, 8908715198, 49463428, 1176649664, 2993062640, 49150691], 35: [3687377770, 3687377755, 1772229389, 8298109277, 1772229388, 1772229386, 3687377728, 1772229374, 10133683717, 1772229154, 3545794010, 8085622087, 1772238324, 1772238314, 1926673336, 1926673385, 12242411842, 12242411857, 12242411859, 12242411860, 12242411862, 12242411863, 7180469574, 9990697272, 7180469573, 2016829244, 7180458321, 7180458379, 12521392946, 49463411, 2993062665, 1715024582, 5448402860, 10311860666, 5391208974, 5404634605, 5391208975, 10309785025, 469084101, 1176646981, 5986666652, 469082581, 5986666648, 469084070, 7180458125, 9620618699, 7180458170, 2993062633, 8908715202, 8908715204, 8861736063, 9125448451, 9867139448, 9867139445, 9867139442, 9574118157, 9408616471, 9408616468, 7179565949, 7179565953, 7179565960, 7179588595, 7179588592, 7179588607, 7990587621, 7179588651, 7179588650, 7179588649, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 10261555874, 10261555877, 5466326131, 7179588642, 4536669341, 273627682], 36: [10266029767, 10281307624, 471275278, 9880108074, 3337511384, 9880108064, 5934982832, 8085649272, 8085649273, 5934982831, 1989046927, 5935081749, 9641914645, 9630910094, 4023228690, 9630910092, 4023183266, 10282833379, 10285438400, 10285438391, 9625384597, 9622059688, 1926666015, 7180458323, 7180458276, 2993062666, 2993062665, 1715024582, 5448402860, 10311860666, 5391208974, 5404634605, 5391208975, 10309785025, 469084101, 1176646981, 5986666652, 469082581, 5986666648, 469084070, 7180458125, 9620618699, 7180458170, 2993062633, 8908715202, 8908715204, 8861736063, 9125448451, 9867139448, 9867139445, 9867139442, 9574118157, 9408616471, 9408616468, 7179565949, 7179565953, 7179565960, 7179588595, 7179588592, 7179588607, 7990587621, 7179588651, 7179588650, 7179588649, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 6433577305, 3139419286], 37: [8861736052, 7729384167, 7729384168, 8861736049, 8861736065, 8522708967, 8522708971, 8908715202, 2993062633, 7180458170, 9620618699, 7180458125, 469084070, 5986666648, 469082581, 5986666652, 1176646981, 469084101, 9815476367, 5404634603, 469084068], 38: [5391208974, 5404634605, 5391208975, 10297059268, 10297059264, 8994595979, 1715024517, 9622059676, 9622059678, 5398780622, 5398780623, 469084079, 9552931569, 10297059295, 9552931562, 1545508762, 10299192807, 1361121344, 1361121381, 5448402852, 1361121324, 7179725194, 446616561, 10553146306, 10299265345, 5457413137, 768264666], 39: [2993062653, 1176646984, 8905639876, 5986666655, 8905639877, 5986666653, 5986666638, 1176646981, 5986666652, 469082581, 5430976750, 698283636, 8994595958, 8994595954, 469082557, 5398780623, 469084079, 9552931569, 10297059295, 9552931562, 1545508762, 10299192807, 1361121344, 1361121381, 5448402852, 1361121324, 5391230841, 5432894231, 3297844022, 5457413133, 5742738421, 9456403559, 9456403563, 5390959627, 446645809, 446647557, 9886044307, 9456403573, 446647553, 446128310], 40: [5404634605, 5391208974, 10311860666, 5448402860, 1715024582, 2993062665, 49463411, 12521392946, 7180458379, 7180458321, 2016829244, 7180469573, 9990697272, 7180469574, 12242411863, 12242411862, 12242411860, 12242411859, 12242411857, 12242411842, 1926673385, 1926673336], 41: [914259245, 914259241, 914259338, 914259337, 914259336, 914259327, 7965311572, 7965311562, 6981724630, 6981724619, 7179565982, 7179565960, 7179565953, 7179565949, 12256231265, 12186966197, 7179658877, 7179685058, 7179685072, 7179685075, 6296458760, 5529658591, 5529658589, 7179725222, 7179725216, 7180485021, 5394721591, 10299244134, 5394721596, 3333766414, 446616503, 1146841843, 1146841833, 5811887320, 4868801842, 1146863120, 1146863123, 1146863130, 446128299, 446128311, 446128310], 42: [9456403570, 446130583, 5390959120, 3297844023, 5432894231, 5391230841, 1361121324, 5448402852, 1361121381, 1361121344, 10299192807, 1545508762, 9552931562, 10297059295, 9552931569, 469084079, 5398780623, 5398780622, 9622059678, 9622059676, 1715024517, 8994595979, 10297059264, 10297059268, 5391208975, 10309785025, 10309785024, 469084068], 43: [8932713585, 2013783144, 2028895482, 1715024517, 9622059676, 9622059678, 5398780622, 5398780623, 469084079, 9552931569, 10297059295, 9552931562, 1545508762, 10299192807, 1361121344, 1361121381, 5448402852, 1361121324, 7179725194, 446616561, 10553146306, 10299265345, 5457413137, 768264666, 3333766414, 5394721596, 324739415, 7180469577, 7180469576, 7180469575, 445989086, 445989107], 44: [5986666652, 469082581, 5986666648, 469084070, 7180458125, 9620618699, 7180458170, 2993062633, 8908715202, 8908715204, 8861736063, 9125448451, 9867139448, 9867139445, 9867139442, 9574118157, 9408616471, 9408616468, 7179565949, 7179565954, 5390812787, 7179588596, 4037576308], 45: [10825625355, 10825625353, 10825625215, 10825625217, 10825625209, 9681289450, 10825625308, 10825615601, 10825615604, 10825625205, 9612217728, 9612217727, 9612217726, 9612217725, 9612217724, 10825615563, 11030490971, 10282833388, 10295648348, 10295648331, 8921798256, 5935081752, 9630910097, 5935081748, 10266091475, 1772230346], 46: [4597316411, 4597316410, 4596804910, 4597316406, 658984746, 4597331159, 4597331163, 1350616562, 658984737, 5390733109, 5390733114, 5390733108, 5390733101, 5390733100, 5740082884, 5740082883, 5388224286, 5740071615, 5740082879, 5740082876, 5740082877, 5388224308, 7249339431, 7161876379, 9544330409, 7161876384, 7161923989, 7237743290, 7237743291, 7179588593, 4037576308, 7179588596, 5390812787, 7179565954, 5390812819, 7179685056, 447635692, 447637140, 447621416, 7179725220, 454862513, 7179725224, 7179725216, 7180485021, 5394721591, 10299244134, 5394721596, 3333766414, 768264666, 9675336075, 5742738421, 3701741646, 446130583, 9886044230, 9456403537, 9886044514, 9886044515, 2872424924, 2872424923], 47: [5538554970, 5538554973, 9675671137, 446001726, 445989099, 9612261734, 445989103, 445989084, 445989083, 445989107, 5457413160, 10296110009, 10296088704, 10296110075, 445989240, 10296088688, 7179725218, 7179725221, 454862518, 7179725219, 447621458, 447637139, 447635688, 7179685055, 5390812819, 7179565954, 5390812787, 7179588596, 4037576308], 48: [2295398926, 7179588699, 7179588694, 7179588698, 7179588716, 3326353512, 3335554173, 2295398915, 6801459624, 9642608260, 9642608259, 12556955249, 5921568236, 9642608255, 9642608254, 7295860704, 4515887426, 4037576300, 4515887425, 7179588595, 7179565960, 7179565953, 9579010287, 6868505371, 49150677, 10301347700, 2993062639, 49150691], 49: [10299258485, 10299258484, 1361121394, 7179725196, 7179725197, 7179685083, 7179725198, 10299528789, 7179685082, 7179725188, 7179685072, 7179685058, 7179658877, 12186966197, 12256231265, 7179565949, 7179565953, 7179565960, 7179588595, 4515887425, 4037576300, 4515887426, 7295860704, 9642608254, 9642608255, 5921568236, 12556955249, 9642608259, 9642608260, 6801459624, 2295398915, 3335554173, 3326353512, 7179588716, 7179588698, 7179588714, 7179588712, 2295398923, 2501321596, 49309735], 50: [2478669695, 2478669708, 2478669707, 273628792, 2478669718, 5466059075, 2478669721, 7179630177, 7179630138, 7179630166, 7179630167, 7179630168, 7179630169, 7179588654, 7179588656, 7179588642, 7179658686, 2183114704, 3139419286], 51: [5457413145, 5457413148, 5457413144, 9880108367, 4023183266, 10282833379, 10285438400, 10285438391, 9625384597, 9622059688, 1926666015, 7180458323, 7180458276, 2993062666, 2993062665, 1715024582, 5448402860, 10311860666, 5391208974, 5404634605, 5391208975, 10309785025, 469084101, 1176646981, 5986666652, 469082581, 5986666648, 469084070, 7180458125, 9620618699, 7180458170, 2993062633, 8908715202, 8908715204, 8861736063, 9125448451, 9867139448, 9867139445, 9867139442, 9574118157, 9408616471, 9408616468, 7179565949, 7179565953, 7179565960, 7179588595, 7179588592, 7179588607, 7990587621, 7179588651, 7179588650, 7179588649, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 6433577305, 3139419286], 52: [9642608293, 9642608286, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 6433577305, 3139419286, 1352179342, 1352179344, 7179658807, 49309737, 49309735], 53: [7179725198, 7179685083, 9611588635, 7179725200, 10028680333, 10299265351, 768264666, 9456403558, 9456403559, 9456403563, 5390959627, 446645809, 446647557, 9886044307, 9456403573, 446647553, 446128310], 54: [10825625353, 10825625215, 9681289456, 9681289466, 9681289461, 9681289471, 9681289486, 9990697277, 9131115149, 10028680338, 9681289487, 9681289482, 9099230484, 10825625401, 9131115136, 9131115124, 10825625265, 10825625264, 10825625266, 9099230483, 9099230481, 9099230480, 9681216665, 2872424924, 9886044515, 9886044514, 9456403537, 9886044230, 446130583, 3701741646, 5742738421, 9675336075, 768264666, 3333766414, 5394721596, 10299244134, 5394721591, 7180485021, 7179725216, 7179725222, 5529658589, 5529658591, 6296458760, 7179685075, 7179685072, 7179685058, 7179658877, 12186966197, 12256231265, 7179565949, 7179565953, 7179565960, 7179588595, 7179588592, 7179588607, 7990587621, 7179588651, 7179588650, 7179588649, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 10261555874, 10261555877, 5466326131, 7179588642, 4536669341, 273627682], 55: [7179588764, 4515887425, 7179588595, 7179565960, 7179565953, 7179565949, 12256231265, 12186966197, 7179658877, 7179685058, 7179685072, 7179685075, 6296458760, 5529658591, 5529658589, 7179725222, 7179725216, 7180485021, 5394721591, 10299244134, 5394721596, 3333766414, 446616503, 1146841843, 1146841833, 5811887320, 4868801842, 1146863120, 445992528], 56: [446128299, 1146863130, 1146863123, 1146863120, 4868801842, 5811887320, 1146841833, 1146841843, 446616503, 7180485022, 1533658482, 447635764, 7180485048, 7180485035, 7180469575, 445989086, 445989107], 57: [5404632943, 5404632949, 5406225437, 7180458190, 3798588088, 5404629713, 319438800, 7180450273, 7180450257, 7180458170, 2993062633, 8908715202, 8908715204, 8861736063, 9125448451, 9867139448, 9867139445, 9867139442, 9574118157, 9408616471, 9408616468, 7179565949, 7179565953, 7179565960, 7179588595, 7179588592, 7179588607, 7990587621, 7179588651, 7179588650, 7179588649, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 6433577305, 3139419286], 58: [1176649662, 1176649666, 1176649608, 1176649597, 7180450274, 7180450246, 7180450249, 7180450257, 9620618700, 7180458169, 7180458125, 469084070, 5986666648, 469082581, 5986666652, 1176646981, 469084101, 10309785025, 5391208975, 5404634605, 5391208974, 10311860666, 5448402860, 1715024582, 2993062665, 49463411, 12521392946, 7180458379, 7180458321, 2016829244, 7180469573, 9990697272, 7180469574, 12242411863, 12242411862, 12242411860, 12242411859, 12242411857, 12242411842, 1926673385], 59: [9880108359, 9880108306, 5457413145, 5457413148, 5457413144, 9880108367, 4023183266, 10282833379, 10285438400, 10285438391, 9625384597, 9622059688, 1926666015, 7180458323, 7180458276, 2993062666, 2993062665, 1715024582, 5448402860, 10311860666, 5391208974, 5404634605, 5391208975, 10309785025, 469084101, 1176646981, 5986666652, 469082581, 5986666648, 469084070, 7180458125, 9620618699, 7180458170, 2993062633, 8908715202, 8908715204, 8861736063, 9125448451, 9867139448, 9867139445, 9867139442, 9574118157, 9408616471, 9408616468, 7179565949, 7179565953, 7179565960, 7179588595, 7179588592, 7179588607, 7990587621, 7179588651, 7179588650, 7179588649, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 10261555874, 10261555877, 5466326131, 7179588642, 4536669341, 273627682], 60: [7179630172, 7179658696, 5466068421, 5466059061, 5538555412, 2478669728, 5538555415, 7179588655, 273627682, 4536669341, 7179588642, 5466326131, 10261555877, 10261555874, 7179588643, 7179588627, 7179588644, 7179588645, 7179588646, 9642608244, 7179588647, 7179588648, 7179588615, 7179588649, 7179588650, 7179588651, 7990587621, 7179588607, 7179588592, 7179588595, 7179565960, 7179565953, 7179565949, 9408616468, 9408616471, 9574118157, 9867139442, 9867139445, 9867139448, 9125448451, 8861736063, 8908715204, 8908715202, 2993062633, 7180458170, 9620618699, 7180458125, 469084070, 5986666648, 469082581, 5986666652, 1176646981, 469084101, 10309785025, 5391208975, 5404634605, 5391208974, 10311860666, 5448402860, 1715024582, 2993062665, 2993062666, 7180458276, 7180458323, 1926666015], 61: [5391010350, 1361121389, 9620618673, 9611588639, 49655807, 7179725195, 4553390952, 4553390941, 49721328, 10553246952, 12072393886, 12072393909, 12072393911, 12072393915, 12072393913, 12072393887, 12256265400, 12072393888, 10553246950, 10553246948, 12072377547, 12072377550, 12072377548, 12072377544, 12072377542, 9867139424, 9739748081, 9867133513, 9408616471, 9408616468, 7179565949, 7179565954, 5390812787, 7179588596, 4037576308], 62: [10180295245, 11838001794, 8921798250, 914043423, 914043424, 914043426, 914043429, 10825615563, 914043430, 49550453, 10825615534, 9612217722, 9612217721, 9612217720, 9612217731, 9612217719, 9681289483, 9099230482, 9620619989, 9131115124, 10825625265, 10825625264, 10825625266, 9099230483, 9099230481, 9099230480, 9681216665, 2872424924, 9886044515, 9886044514, 9456403537, 9886044230, 446130583, 3701741646, 5742738421, 9675336075, 768264666, 3333766414, 5394721596, 10299244134, 5394721591, 7180485021, 7179725216, 7179725222, 5529658589, 5529658591, 6296458760, 7179685075, 7179685072, 7179685058, 7179658877, 12186966197, 12256231265, 7179565949, 7179565953, 7179565960, 7179588595, 7179588592, 7179588607, 7990587621, 7179588651, 7179588650, 7179588649, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 6433577305, 3139419286], 63: [1926673373, 8085622114, 5973397108, 8085649300, 8085622107, 8085649310, 8085622108, 10289788054, 5935130725, 10287844481, 9674860399, 10289788025, 8166713598, 9630910066, 9630910067, 10282604892, 10282621309, 9630910070, 9630910075, 9630910077, 9630910078, 10291723243, 446606685, 5457413150, 8708060834, 5457413144, 9880108367, 4023183266, 10282833379, 10296008979, 10296008981, 4023183267, 10296008982, 10295979870, 1715024598, 10296001360, 5406225464, 3464861413, 11750711840, 7311197591, 10825625356, 9456334312, 10825625285, 9456334308, 8861736082, 9099230480, 2872424923, 446128318, 914043397, 446128315, 446647550, 446647553, 446128310, 446128311, 446128299, 10241316977, 1146863105, 445992528], 64: [1352176304, 7965230952, 1352176342, 1352176355, 1352176392, 3451647253, 7179588736, 3326353507, 3326353509, 5745765321, 3326356072, 7179588776, 12556955247, 5565181504, 7179588755, 7179588763, 7179588746, 7179588765, 7179588764, 4515887425, 7179588595, 7179565960, 7179565953, 7179565949, 9408616468, 9408616471, 9574118157, 9867139442, 9867139445, 9867139448, 9125448451, 8861736063, 8908715204, 8908715202, 2993062633, 7180458170, 9620618699, 7180458125, 469084070, 5986666648, 469082581, 5986666652, 1176646981, 469084101, 10309785025, 5391208975, 5404634605, 5391208974, 10311860666, 5448402860, 1715024582, 2993062665, 49463411, 12521392946, 7180458379, 7180458321, 2016829244, 7180469573, 9990697272, 7180469574, 12242411863, 12242411862, 12242411860, 12242411859, 12242411857, 12242411842, 1926673385], 65: [10296096678, 10296096668, 10296096680, 10299258505, 1361121331, 1361121406, 5391010350, 1361121389, 9620618673, 9611588639, 49655807, 7179725195, 4553390952, 4553390941, 49721328, 10553246952, 12072393886, 12072393909, 12072393911, 12072393915, 12072393913, 12072393887, 12256265400, 12072393888, 10553246950, 10553246948, 12072377547, 12072377550, 12072377548, 12072377544, 12072377542, 9867139424, 9739748081, 9867133513, 9408616471, 9408616468, 7179565949, 7179565954, 5390812787, 7179588596, 4037576308], 66: [11750711840, 3464861413, 5406225464, 10296001360, 5406225461, 10296001357, 5406225460, 1926667755, 10295715290, 10295715292, 10295715293, 10282833382, 9630910092, 4023228690, 9630910094, 9641914645, 9630910097, 5935081748, 10266091475, 1772230346], 67: [9408642105, 9408642106, 8921957004, 5387846596, 445988286, 445988304, 445988301, 445988300, 5394745289, 445988298, 445988293, 1533685294, 445989107, 445989086, 7180469575, 7180469576, 7180469577, 324739415, 5394721596, 3333766414, 768264666, 5457413137, 10299265345, 10553146306, 446616561, 7179725194, 1361121324, 5448402852, 1361121381, 9429180937, 10299244033, 10297064190, 469081875, 9620619953, 469081877, 469081878, 469081879, 5404634618, 10296140538, 469081881, 7180458339, 7180458297, 5546557183, 9886047940, 4554611506, 9886047938, 9886047932, 9886047936, 9886047934, 1926666013, 7180458363, 7180458323, 1926666015], 68: [10299244133, 5394721590, 5394721591, 10299244134, 5394721596, 3333766414, 768264666, 9675336075, 5742738421, 3701741646, 446130583, 9886044230, 9456403537, 9886044514, 9886044515, 2872424924, 9681216665, 9099230480, 9099230481, 9099230483, 10825625266, 10825625264, 10825625265, 9131115124, 9620619989, 9099230482, 9681289483, 9612217719, 9612217731, 9612217720, 9612217721, 9612217722, 10825615534, 49550453, 914043430, 914043411, 10295648346, 5935081753, 9641914645, 9630910097, 5935081748, 10266091475, 1772230346], 69: [5538555021, 11597450932, 5538555030, 11597450936, 11597450935, 11597450939, 11597450945, 11597450944, 11597450940, 9630909959, 3687377589, 3687377587, 3687377586, 2930609913, 8085649233, 5538555044, 447640986, 447640954, 1772238274, 1772238291, 1926673336, 1926673385, 12242411842, 12242411857, 12242411859, 12242411860, 12242411862, 12242411863, 7180469574, 9990697272, 7180469573, 2016829244, 7180458321, 7180458379, 12521392946, 49463411, 2993062665, 1715024582, 5448402860, 10311860666, 5391208974, 5404634605, 5391208975, 10309785025, 469084101, 1176646981, 5986666652, 469082581, 5986666648, 469084070, 7180458125, 9620618699, 7180458170, 2993062633, 8908715202, 8908715204, 8861736063, 9125448451, 9867139448, 9867139445, 9867139442, 9574118157, 9408616471, 9408616468, 7179565949, 7179565953, 7179565960, 7179588595, 7179588592, 7179588607, 7990587621, 7179588651, 7179588650, 7179588649, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 10261555874, 10261555877, 5466326131, 7179588642, 4536669341, 273627682], 70: [1533639503, 1533639513, 9886044307, 446647557, 9456403547, 9456403543, 9456403569, 9456403529, 9886044515, 2872424924, 9681216665, 9099230480, 9099230481, 9099230483, 10825625266, 10825625264, 10825625265, 9131115124, 9620619989, 9099230482, 9681289483, 9612217719, 9612217731, 9612217720, 9612217721, 9612217722, 10825615534, 49550453, 914043430, 914043411, 10295648346, 5935081753, 9641914645, 9630910097, 5935081748, 10266091475, 1772230346], 71: [10296110075, 445989240, 10296088688, 7179725218, 7179725221, 454862518, 7179725219, 447621458, 447637139, 447635688, 7179685055, 5390812819, 7179565954, 5390812787, 7179588596, 4037576308], 72: [9880108075, 9880108076, 10281307624, 471275278, 9880108074, 3337511384, 9880108064, 5934982832, 8085649272, 8085649273, 5934982831, 1989046927, 5935081749, 9641914645, 5935081753, 10295648346, 914043411, 914043430, 49550453, 9612217723, 9612217732, 8861736083, 9612217729, 9131115149, 9612217704, 10028680336, 9681289478, 914259699, 9612070211, 445990912, 9612189414, 9612189415, 10825166615, 914043404, 10825141111, 10825138800, 5811663003, 446128310], 73: [5565212307, 5565212308, 5565212309, 5565212316, 5565212310, 5565212313, 7990587615, 9642608270, 9642608272, 7990587606, 7990587629, 7179588741, 7179588592, 7179588595, 7179565960, 7179565953, 9579010287, 6868505371, 49150677, 10301347700, 2993062639, 49150691], 74: [11597450945, 11597450944, 11597450940, 9630909959, 3687377589, 3687377587, 3687377586, 2930609913, 8085649233, 447640985, 447640953, 8085649234, 8085649240, 49429968, 8085649282, 8085622110, 8085649293, 8085649298, 5973397110, 5973397108, 8085649300, 8085622107, 8085649310, 8085622108, 10289788054, 5935130725, 10287844481, 9674860399, 10289788025, 8166713598, 9630910066, 9630910067, 10282604892, 10282621309, 9630910070, 9630910075, 9630910077, 9630910078, 10291723243, 446606685, 5457413150, 8708060834, 5457413144, 9880108367, 4023183266, 10282833379, 10296008979, 10296008981, 4023183267, 10296008982, 10295979870, 1715024598, 10296001360, 5406225464, 3464861413, 11750711840, 7311197591, 10825625356, 9456334312, 10825625285, 9456334308, 8861736082, 9099230480, 2872424923], 75: [10285438401, 10285438403, 9880108367, 4023183266, 10282833379, 10296008979, 10296008981, 4023183267, 10296008982, 10295979870, 1715024598, 10296001360, 5406225464, 3464861413, 11750711840, 7311197591, 10825625356, 9456334312, 10825625285, 9456334308, 8861736082, 9099230480, 2872424923, 446128318, 914043397, 446128315, 446647550, 446647553, 446128310], 76: [9620618684, 9620618685, 9620618688, 5391215257, 7180458105, 5398780623, 5398780622, 9622059678, 9622059676, 3422595499, 1545527871, 469082565, 7180458280, 7180458363, 7180458323, 1926666015], 77: [9863143444, 9863143441, 1176646972, 5404632924, 5406225438, 1176646983, 2993062653, 9620619917, 9620618700, 9620618699, 7180458170, 2993062633, 8908715202, 8908715204, 8861736063, 9125448451, 9867139448, 9867139445, 9867139442, 9574118157, 9408616471, 9408616468, 7179565949, 7179565953, 7179565960, 7179588595, 4515887425, 4037576300, 4515887426, 7295860704, 9642608254, 9642608255, 5921568236, 12556955249, 9642608259, 9642608260, 6801459624, 2295398915, 3335554173, 3326353512, 7179588716, 7179588698, 7179588714, 7179588712, 2295398923, 2501321596, 49309735], 78: [6434338912, 658984702, 5388224265, 5388224262, 8638509520, 7153002858, 1196407946, 49504477, 8638506514, 8638506506, 7161923987, 6434338915, 7237743291, 7179588593, 4037576308, 7179588596, 5390812787, 7179565954, 5390812819, 7179685056, 447635692, 447637140, 447621416, 7179725220, 454862513, 7179725224, 7179725216, 7180485021, 5394721591, 10299244134, 5394721596, 3333766414, 446616503, 1146841843, 1146841833, 5811887320, 4868801842, 1146863120, 1146863123, 1146863130, 446128299, 446128311, 446128310], 79: [4350609730, 4350609731, 4350609725, 655435908, 4350609716, 4350609700, 4350609698, 655435909, 7179630173, 7179630176, 7179630172, 7179658696, 5466068421, 5466059061, 5538555412, 2478669728, 5538555415, 7179588655, 273627682, 4536669341, 7179588642, 5466326131, 10261555877, 10261555874, 7179588643, 7179588627, 7179588644, 7179588645, 7179588646, 9642608244, 7179588647, 7179588648, 7179588615, 7179588649, 7179588650, 7179588651, 7990587621, 7179588607, 7179588592, 7179588595, 7179565960, 7179565953, 7179565949, 9408616468, 9408616471, 9574118157, 9867139442, 9867139445, 9867139448, 9125448451, 8861736063, 8908715204, 8908715202, 2993062633, 7180458170, 9620618699, 7180458125, 469084070, 5986666648, 469082581, 5986666652, 1176646981, 469084101, 10309785025, 5391208975, 5404634605, 5391208974, 10311860666, 5448402860, 1715024582, 2993062665, 49463411, 12521392946, 7180458379, 7180458321, 2016829244, 7180469573, 9990697272, 7180469574, 12242411863, 12242411862, 12242411860, 12242411859, 12242411857, 12242411842, 1926673385], 80: [7180485022, 446616503, 446616502, 9612217735, 446616501, 536375831, 5390959627, 9456403563, 9456403570, 9456403566, 9886044230, 9456403537, 9886044514, 9886044515, 2872424924, 9681216665, 9146901571, 9456334309, 9456334313, 7311197591, 11750711840, 3464861413, 5406225464, 10296001360, 1715024598, 10295979870, 10296008982, 4023183267, 10296008981, 10296008979, 10282833379, 4023183266, 9880108367, 5457413144, 8708060834, 5457413150, 446606685, 10291723243, 9630910078, 9630910077, 9630910075, 9630910070, 10282621309, 10282604892, 9630910067, 9630910066, 8166713598, 10289788025, 9674860399, 10287844481, 5935130725, 10289788054, 8085622108, 8085649310, 8085622107, 8085649300, 5973397108, 8085622114, 8085622116, 8085622112, 8085622113, 1926673385], 81: [4597286050, 9784057790, 49685143, 658984776, 4596804930, 4596843549, 4596843552, 658984756, 658984757, 7644787987, 7029570105, 7965583172, 7738294594, 7965583155, 658984679, 9642612964, 273628799, 273628800, 1457843000, 9642612957, 273628801, 1457843003, 1457843009, 7179630171, 273628806, 7179588656, 273627682], 82: [3545794010, 8085622087, 1772238324, 1772238314, 1926673336, 8085622111, 1926673373, 8085622114, 5973397108, 8085649300, 8085622107, 8085649310, 8085622108, 10289788054, 5935130725, 10287844481, 9674860399, 10289788025, 8166713598, 9630910066, 9630910067, 10282604892, 10282621309, 9630910070, 9630910075, 9630910077, 9630910078, 10291723243, 446606685, 5457413150, 8708060834, 5457413144, 9880108367, 4023183266, 10282833379, 10296008979, 10296008981, 4023183267, 10296008982, 10295979870, 1715024598, 10296001360, 5406225464, 3464861413, 11750711840, 7311197591, 9456334313, 9456334309, 9146901571, 9681216665, 2872424924, 9886044515, 9886044514, 9456403537, 9886044230, 446130583, 3701741646, 5742738421, 9675336075, 768264666, 3333766414, 5394721596, 324739415, 7180469577, 7180469576, 7180469575, 445989086, 445989107], 83: [8905639862, 7180458167, 1176646984, 7180458169, 7180458125, 9620618699, 7180458170, 2993062633, 8908715202, 8908715204, 8861736063, 9125448451, 9867139448, 9867139445, 9867139442, 9574118157, 9408616471, 9408616468, 7179565949, 7179565953, 7179565960, 7179588595, 7179588592, 7179588607, 7990587621, 7179588651, 7179588650, 7179588649, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 10261555874, 10261555877, 5466326131, 7179588642, 4536669341, 273627682], 84: [8166713597, 8166713598, 9630910066, 9630910067, 10282604892, 10282621309, 9630910070, 9630910075, 9630910077, 9630910078, 10291723243, 446606685, 5457413150, 8708060834, 5457413144, 9880108367, 4023183266, 10282833379, 10296008979, 10296008981, 4023183267, 10296008982, 10295979870, 1715024598, 10296001360, 5406225464, 3464861413, 11750711840, 7311197591, 10825625356, 9456334312, 10825625285, 9456334308, 8861736082, 9099230480, 2872424923, 446128318, 914043397, 446128315, 446647550, 446647553, 446128310, 446128311, 446128299, 10241316977, 1146863105, 445992528], 85: [7965587915, 7965587917, 7965587919, 7965587922, 7965587923, 8638509529, 7965583177, 7965583175, 7965583181, 5388224303, 5388224270, 7965583166, 9544330520, 5388224289, 5740071616, 5388224300, 5388224301, 5388224315, 8881625234, 5388224302, 7161876379, 9544330409, 7161876384, 7161923989, 7237743290, 7237743291, 7179588593, 7179588587, 7179565952, 7179565950, 7179685053, 7179685057, 7179685054, 7179685074, 7179685071, 7179725227, 7179725217, 7179725221, 7179725218, 10296088688, 445989240, 10296110075, 10296088704, 10296110009, 5457413160, 445989107], 86: [10295637751, 10282833388, 11030490971, 914043411, 914043430, 49550453, 9612217723, 9612217732, 8861736083, 9612217729, 9131115149, 9612217704, 10028680336, 9681289478, 914259699, 9612070211, 445990912, 9612189414, 9612189415, 10825166615, 914043404, 10825141111, 10825138800, 5811663003, 446128310, 446128311, 446128299, 10241316977, 1146863105, 445992528], 87: [9463773740, 7179588788, 6269754976, 5565187409, 273629733, 4515887405, 3333758501, 7644788209, 4037576308, 7179588596, 5390812787, 7179565954, 5390812819, 7179685056, 447635692, 447637140, 447621416, 7179725220, 454862513, 7179725224, 7179725216, 7180485021, 5394721591, 10299244134, 5394721596, 3333766414, 446616503, 1146841843, 1146841833, 5811887320, 4868801842, 1146863120, 445992528], 88: [10296008984, 10296008985, 10296008988, 10296008982, 4023183267, 10285438391, 9625384597, 9622059688, 1926666015, 7180458323, 7180458276, 2993062666, 2993062665, 1715024582, 5448402860, 10311860666, 5391208974, 5404634605, 5391208975, 10309785025, 469084101, 1176646981, 5986666652, 469082581, 5986666648, 469084070, 7180458125, 9620618699, 7180458170, 2993062633, 8908715202, 8908715204, 8861736063, 9125448451, 9867139448, 9867139445, 9867139442, 9574118157, 9408616471, 9408616468, 7179565949, 7179565953, 7179565960, 7179588595, 4515887425, 4037576300, 4515887426, 7295860704, 9642608254, 9642608255, 5921568236, 12556955249, 9642608259, 9642608260, 6801459624, 2295398915, 3335554173, 3326353512, 7179588716, 7179588698, 7179588714, 7179588712, 2295398923, 2501321596, 49309735], 89: [9641821961, 5391208974, 5404634605, 5391208975, 10297059268, 10297059264, 8994595979, 1715024517, 9622059676, 9622059678, 5398780622, 5398780623, 469084079, 9552931569, 10297059295, 9552931562, 1545508762, 10299192807, 1361121344, 1361121381, 5448402852, 1361121324, 7179725194, 446616561, 10553146306, 10299265345, 5457413137, 768264666], 90: [5388224290, 5740071616, 5388224300, 5388224301, 5388224315, 8881625234, 5388224302, 7161876379, 9544330409, 7161876384, 7161923989, 7237743290, 7237743291, 7179588593, 4037576308, 7179588596, 5390812787, 7179565954, 5390812819, 7179685056, 447635692, 447637140, 447621416, 7179725220, 454862513, 7179725224, 7179725216, 7180485021, 5394721591, 10299244134, 5394721596, 3333766414, 446616503, 1146841843, 1146841833, 5811887320, 4868801842, 1146863120, 445992528], 91: [7179588648, 7179588615, 7179588649, 7179588650, 7179588651, 7990587621, 7179588607, 7179588592, 7179588595, 7179565960, 7179565953, 7179565949, 9408616468, 9408616471, 9574118157, 9867139442, 9867139445, 9867139448, 9125448451, 8861736063, 8908715204, 8908715202, 2993062633, 7180458170, 9620618699, 7180458125, 469084070, 5986666648, 469082581, 5986666652, 1176646981, 469084101, 10309785025, 5391208975, 5404634605, 5391208974, 10311860666, 5448402860, 1715024582, 2993062665, 2993062666, 7180458276, 7180458323, 1926666015, 9622059688, 9625384597, 10285438391, 10285438400, 10282833379, 4023183266, 9630910092, 4023228690, 9630910094, 9641914645, 9630910097, 5935081748, 10266091475, 1772230346], 92: [12059861212, 9611821116, 9611821098, 1354495933, 445988608, 9611821086, 9408642090, 9408642096, 9408642086, 9408642097, 8921956997, 9408642069, 9408642072, 1533709584, 7180485070, 1196394851, 445989083, 445989084, 445989086, 7180469575, 7180469576, 7180469577, 324739415, 5394721596, 3333766414, 768264666], 93: [9630406142, 7180458152, 9863143459, 7180458176, 5457413132, 7180458165, 5448402860, 10311860666, 5391208974, 5404634605, 5391208975, 10297059268, 10297059264, 8994595979, 1715024517, 9622059676, 9622059678, 9622038216, 10297064190, 469081875, 5390959099, 9681362119, 5390959116, 5391202008, 446723668, 446721191, 9886044406, 2872424924, 2872424923], 94: [7179588776, 12556955247, 5565181504, 7179588755, 7179588763, 7179588746, 7179588765, 7179588764, 4515887425, 7179588595, 7179565960, 7179565953, 7179565949, 12256231265, 12186966197, 7179658877, 7179685058, 7179685072, 7179685075, 6296458760, 5529658591, 5529658589, 7179725222, 7179725216, 7180485021, 5394721591, 10299244134, 5394721596, 3333766414, 446616503, 1146841843, 1146841833, 5811887320, 4868801842, 1146863120, 1146863123, 1146863130, 446128299, 446128311, 446128310], 95: [9674860395, 7180458339, 469081881, 10296140538, 5404634618, 469081879, 469081878, 469081882, 5546567865, 5546567879, 5546567892, 2872424927, 446132667, 446723668, 446721191, 9886044406, 2872424924, 2872424923], 96: [5565212310, 5565212313, 7990587615, 9642608270, 9642608272, 7990587606, 7990587629, 7179588741, 7179588592, 7179588595, 7179565960, 7179565953, 7179565949, 9408616468, 9408616471, 9574118157, 9867139442, 9867139445, 9867139448, 9125448451, 8861736063, 8908715204, 8908715202, 2993062633, 7180458170, 9620618699, 7180458125, 469084070, 5986666648, 469082581, 5986666652, 1176646981, 469084101, 10309785025, 5391208975, 5404634605, 5391208974, 10311860666, 5448402860, 1715024582, 2993062665, 2993062666, 7180458276, 7180458323, 1926666015, 9622059688, 9625384597, 10285438391, 10285438400, 10282833379, 4023183266, 9630910092, 4023228690, 9630910094, 9641914645, 9630910097, 5935081748, 10266091475, 1772230346], 97: [5811847062, 9612082880, 5538554960, 2323614712, 9627835212, 8166761479, 8166761478, 9627835213, 6976611581, 49221957, 9612217747, 49282471, 10825622710, 9612217708, 10825615564, 9681289471, 9681289454, 9681289472, 10825615566, 9612217728, 9612217727, 9612217726, 9612217725, 9612217724, 10825615563, 11030490971, 10282833388, 10295648348, 10295648331, 8921798256, 5935081752, 9630910097, 5935081748, 10266091475, 1772230346], 98: [9408642062, 7180485028, 7180485007, 7180485023, 446656756, 1146834982, 7464948170, 5811887324, 4868801842, 1146863120, 1146863123, 1146863130, 446128299, 446128311, 446128310, 446647553, 446647550, 446128315, 914043397, 446128318, 2872424923, 9099230480, 8861736082, 9456334308, 10825625285, 9456334312, 10825625356, 7311197591, 11750711840, 3464861413, 5406225464, 10296001360, 1715024598, 10295979870, 10296008982, 4023183267, 10296008981, 10296008979, 10282833379, 4023183266, 9880108367, 5457413144, 8708060834, 5457413150, 446606685, 10291723243, 9630910078, 9630910077, 9630910075, 9630910070, 10282621309, 10282604892, 9630910067, 9630910066, 8166713598, 10289788025, 9674860399, 10287844481, 5935130725, 10289788054, 8085622108, 8085649310, 8085622107, 8085649300, 5973397108, 8085622114, 8085622116, 8085622112, 8085622113, 1926673385], 99: [9674860395, 7180458339, 469081881, 10296140538, 5404634618, 469081879, 469081878, 469081877, 9620619953, 469081875, 10297064190, 9622038216, 469084079, 9552931569, 6059250359, 9552931566, 7180458102, 9552931573, 7180458117, 7180458098, 10301407421, 10301407425, 7180458113, 9620618679, 7180458116, 5983732118, 4553390952, 4553390941, 49721328, 10553246952, 12072393886, 12072393909, 12072393911, 12072393915, 12072393913, 12072393887, 12256265400, 12072393888, 10553246950, 10553246948, 12072377547, 12072377550, 12072377548, 12072377544, 12072377542, 9867139424, 9739748081, 9867133513, 9408616471, 9408616468, 7179565949, 7179565953, 7179565960, 7179588595, 7179588592, 7179588607, 7990587621, 7179588651, 7179588650, 7179588649, 7179588615, 7179588648, 7179588647, 9642608244, 7179588646, 7179588645, 7179588644, 7179588627, 7179588643, 6433577305, 3139419286]}\n"
     ]
    }
   ],
   "source": [
    "print(path_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c4eb8-925b-440f-bc9a-4c9ab04c120d",
   "metadata": {},
   "source": [
    "## Step 2: Defining ToMnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7bf98054-1d2f-4952-8679-e8265adfed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "234218a4-71e7-46bb-8543-f33f9da1f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CharacterNet(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Encode K full trajectories per agent into a single 'character' vector c  R^h.\n",
    "#     Input shape: (B, K, T_sup) of node indices (long).\n",
    "#     \"\"\"\n",
    "#     def __init__(self,\n",
    "#                  num_nodes:int,\n",
    "#                  d_emb:int   = 16,\n",
    "#                  h_lstm:int  = 64,\n",
    "#                  T_sup:int   = 50,\n",
    "#                  K:int       = 10):\n",
    "#         super().__init__()\n",
    "#         self.embedding = nn.Embedding(num_nodes, d_emb, padding_idx=0)\n",
    "#         self.lstm = nn.LSTM(d_emb, h_lstm, batch_first=True)\n",
    "#         self.K = K\n",
    "#         self.T_sup = T_sup\n",
    "\n",
    "#     def forward(self, support_trajs):\n",
    "#         # support_trajs: LongTensor[B, K, T_sup]\n",
    "#         B, K, T = support_trajs.size()\n",
    "#         assert K==self.K and T==self.T_sup\n",
    "\n",
    "#         # (B*K, T)\n",
    "#         flat = support_trajs.view(B*K, T)\n",
    "#         # (B*K, T, d_emb)\n",
    "#         emb = self.embedding(flat)\n",
    "#         # run LSTM\n",
    "#         _, (h_n, _) = self.lstm(emb)  # h_n: (1, B*K, h_lstm)\n",
    "#         h_n = h_n.squeeze(0)          # (B*K, h_lstm)\n",
    "#         # reshape to (B, K, h_lstm) and mean-pool over K\n",
    "#         chars = h_n.view(B, K, -1).mean(dim=1)  # (B, h_lstm)\n",
    "#         return chars                            #  c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2573a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Encode K full trajectories per agent into a single 'character' vector c  R^h.\n",
    "    Input shape: (B, K, T_sup) of node indices (long).\n",
    "    CharacterNet using precomputed node2vec embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 node_embeddings: np.ndarray,\n",
    "                 h_lstm: int = 64,\n",
    "                 T_sup: int = 50,\n",
    "                 K: int = 10):\n",
    "        super().__init__()\n",
    "        num_nodes, d_emb = node_embeddings.shape\n",
    "        # Use precomputed embeddings, freeze them\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(node_embeddings), freeze=True, padding_idx=0\n",
    "        )\n",
    "        self.lstm = nn.LSTM(d_emb, h_lstm, batch_first=True)\n",
    "        self.K = K\n",
    "        self.T_sup = T_sup\n",
    "\n",
    "    def forward(self, support_trajs):\n",
    "        # support_trajs: LongTensor[B, K, T_sup]\n",
    "        B, K, T = support_trajs.size()\n",
    "        assert K == self.K and T == self.T_sup\n",
    "\n",
    "        flat = support_trajs.view(B * K, T)\n",
    "        emb = self.embedding(flat)\n",
    "        _, (h_n, _) = self.lstm(emb)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        chars = h_n.view(B, K, -1).mean(dim=1)\n",
    "        return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eea9a5f4-8456-4489-8446-42cf6fe18eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentalNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Encode the query prefix into a 'mental' vector m  R^h'.\n",
    "    Inputs:\n",
    "      - prefix     : LongTensor of shape [B, T_q] (node indices, padded with 0)\n",
    "      - prefix_len : LongTensor of shape [B]   (true lengths in 1..T_q)\n",
    "    Outputs:\n",
    "      - m          : FloatTensor of shape [B, h_lstm]\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_nodes:int,\n",
    "                 d_emb:int  = 16,\n",
    "                 h_lstm:int = 64,\n",
    "                 T_q:int    = 20):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_nodes, d_emb, padding_idx=0)\n",
    "        self.lstm      = nn.LSTM(d_emb, h_lstm, batch_first=True)\n",
    "        self.T_q       = T_q\n",
    "\n",
    "    def forward(self, prefix: torch.LongTensor, prefix_len: torch.LongTensor):\n",
    "        B, T = prefix.size()\n",
    "        assert T == self.T_q, f\"Expected T_q={self.T_q}, got {T}\"\n",
    "\n",
    "        # embed all time-steps\n",
    "        emb = self.embedding(prefix)  # [B, T_q, d_emb]\n",
    "\n",
    "        # pack by actual lengths\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            emb,\n",
    "            lengths=prefix_len.cpu(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        # run through LSTM\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        # h_n: [1, B, h_lstm]\n",
    "        m = h_n.squeeze(0)            # [B, h_lstm]\n",
    "\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "754ef7ef-ca59-4a29-8cc7-1211435686f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToMNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Full ToMNet: CharacterNet + MentalNet + fusion MLP + prediction heads.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 node_embeddings: np.ndarray,\n",
    "                 num_nodes:int,\n",
    "                 num_goals:int,\n",
    "                 K:int=10,\n",
    "                 T_sup:int=50,\n",
    "                 T_q:int=20,\n",
    "                 d_emb:int=16,\n",
    "                 h_char:int=64,\n",
    "                 h_ment:int=64,\n",
    "                 z_dim:int=64):\n",
    "        super().__init__()\n",
    "        # submodules\n",
    "        self.char_net   = CharacterNet(node_embeddings, h_char, T_sup, K)\n",
    "        self.mental_net = MentalNet(num_nodes, d_emb, h_ment, T_q)\n",
    "        # embedding to get laststep token embedding\n",
    "        self.embedding  = nn.Embedding(num_nodes, d_emb, padding_idx=0)\n",
    "\n",
    "        # a small MLP to fuse [h_char + h_ment + d_emb]  z_dim\n",
    "        fusion_dim = h_char + h_ment + d_emb\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, z_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # final prediction heads\n",
    "        self.goal_head = nn.Linear(z_dim, num_goals)\n",
    "        self.next_head = nn.Linear(z_dim, num_nodes)\n",
    "\n",
    "    def forward(self,\n",
    "                sup: torch.LongTensor,       # [B, K, T_sup]\n",
    "                prefix: torch.LongTensor,    # [B, T_q]\n",
    "                prefix_len: torch.LongTensor # [B]\n",
    "               ):\n",
    "        B, K, T_sup = sup.shape\n",
    "        _, T_q     = prefix.shape\n",
    "\n",
    "        # 1) characterlevel features from the K support trajectories\n",
    "        #    --> sup_feat: [B, h_char]\n",
    "        sup_feat = self.char_net(sup)\n",
    "\n",
    "        # 2) mentalnet encoding of the current prefix\n",
    "        #    --> ment_feat: [B, h_ment]\n",
    "        ment_feat = self.mental_net(prefix, prefix_len)\n",
    "\n",
    "        # 3) take the *last nonpadded* token in each prefix, embed it\n",
    "        #    prefix_len is in [1..T_q], so subtract 1 for zerobased index\n",
    "        last_indices = (prefix_len - 1).clamp(min=0)          # [B]\n",
    "        # gather the node index at that last step\n",
    "        last_nodes   = prefix[torch.arange(B), last_indices] # [B]\n",
    "        # embed it\n",
    "        last_emb     = self.embedding(last_nodes)            # [B, d_emb]\n",
    "\n",
    "        # 4) fuse all three representations\n",
    "        #    concat  [B, h_char + h_ment + d_emb]\n",
    "        fusion_input = torch.cat([sup_feat, ment_feat, last_emb], dim=1)\n",
    "        z            = self.fusion(fusion_input)             # [B, z_dim]\n",
    "\n",
    "        # 5) heads\n",
    "        next_logits = self.next_head(z)  # [B, num_nodes]\n",
    "        goal_logits = self.goal_head(z)  # [B, num_goals]\n",
    "\n",
    "        return next_logits, goal_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987eb6d-ef56-4190-a969-c8057514dd57",
   "metadata": {},
   "source": [
    "## Step 3: Prepare the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2f981e2d-5699-40e4-b410-bf368f80096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in node2idx: 3170\n"
     ]
    }
   ],
   "source": [
    "# build node2idx so that every node in campus.G_undirected maps to 0V1\n",
    "all_nodes = set()\n",
    "for episode in path_data.values():\n",
    "    for path in episode.values():\n",
    "        all_nodes.update(path)\n",
    "all_nodes.update(campus.G_undirected.nodes())\n",
    "all_nodes = list(all_nodes)\n",
    "\n",
    "node2idx = {n: i for i, n in enumerate(all_nodes)}\n",
    "print(f\"Number of nodes in node2idx: {len(node2idx)}\")\n",
    "\n",
    "# all_nodes = list(campus.G_undirected.nodes())\n",
    "# node2idx  = {n:i for i,n in enumerate(all_nodes)}\n",
    "V = len(all_nodes)\n",
    "\n",
    "# build goal2idx likewise for your goals list\n",
    "goal2idx = {g:i for i,g in enumerate(goals)}\n",
    "G = len(goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3cb833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executed once - Find the node2vec embeddings in the data directory.\n",
    "\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "G = campus.G_undirected\n",
    "\n",
    "# Fitting node2vec model\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=100, num_walks=200, workers=16)\n",
    "n2v_model = node2vec.fit(window=10, min_count=1, batch_words=8)\n",
    "\n",
    "# Building a node_id -> embedding matrix\n",
    "embedding_dim = n2v_model.wv.vector_size\n",
    "node_embeddings = np.zeros((len(node2idx), embedding_dim), dtype=np.float32)\n",
    "\n",
    "for node, idx in node2idx.items():\n",
    "    key = str(node)\n",
    "    if key in n2v_model.wv:\n",
    "        node_embeddings[idx] = n2v_model.wv[key]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "np.save(\"data/node2vec_embeddings.npy\", node_embeddings)\n",
    "print(\"Node2Vec embeddings saved to data/node2vec_embeddings.npy\") \n",
    "# \"\"\"\n",
    "\n",
    "node_embeddings = np.load(\"data/node2vec_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ae39ba04-97e7-475d-8db7-eb71ed2f4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agent_ids = list(range(0, 70))\n",
    "test_agent_ids = list(range(70, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd493f-90b3-45bd-b3fb-9eb89e02437e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "977d257e-e483-4011-be19-2200cba11d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train examples: 289118\n",
      "# test  examples: 125153\n"
     ]
    }
   ],
   "source": [
    "# hyperparams\n",
    "K     = 10    # number of support trajectories per agent\n",
    "T_sup = 75    # max length (pad/truncate) of each support trajectory\n",
    "T_q   = 20    # prefix length for query trajectories\n",
    "\n",
    "all_episodes    = list(path_data.keys())\n",
    "examples_train  = []\n",
    "examples_test   = []\n",
    "\n",
    "for agent in agents:\n",
    "    a_id = agent.id\n",
    "\n",
    "    # choose which list to append into\n",
    "    if a_id in train_agent_ids:\n",
    "        target = examples_train\n",
    "    elif a_id in test_agent_ids:\n",
    "        target = examples_test\n",
    "    else:\n",
    "        # silently skip any id outside 099\n",
    "        continue\n",
    "\n",
    "    for ep in all_episodes:\n",
    "        #  1) build the Kshot support set for this (agent, ep) \n",
    "        other_eps   = [e for e in all_episodes if e != ep]\n",
    "        support_eps = random.sample(other_eps, K)\n",
    "\n",
    "        sup_tensor = torch.zeros(K, T_sup, dtype=torch.long)\n",
    "        for k, se in enumerate(support_eps):\n",
    "            raw_sup  = path_data[se][a_id]           # e.g. [n0, n1, n2, ]\n",
    "            idxs_sup = [node2idx[n] for n in raw_sup]\n",
    "            L        = min(len(idxs_sup), T_sup)\n",
    "            sup_tensor[k, :L] = torch.tensor(idxs_sup[:L], dtype=torch.long)\n",
    "\n",
    "        #  2) unroll *this* episodes path into (prefixnext) queries \n",
    "        raw_q        = path_data[ep][a_id]\n",
    "        idxs_q       = [node2idx[n] for n in raw_q]\n",
    "        true_goal_idx = goal2idx[goal_data[ep][a_id]]\n",
    "\n",
    "        for t in range(1, len(idxs_q)):\n",
    "            prefix_idxs = idxs_q[:t]     # length t (well pad later)\n",
    "            next_idx    = idxs_q[t]      # groundtruth next node\n",
    "\n",
    "            target.append((\n",
    "                sup_tensor.clone(),      # [KT_sup] LongTensor\n",
    "                prefix_idxs,             # Python list of length t\n",
    "                next_idx,                # int\n",
    "                true_goal_idx            # int\n",
    "            ))\n",
    "\n",
    "print(f\"# train examples: {len(examples_train)}\")\n",
    "print(f\"# test  examples: {len(examples_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ba43dabd-af6c-442b-a89d-db469ce7013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ToMNetDataset(Dataset):\n",
    "    def __init__(self, examples, T_q, pad_value=0):\n",
    "        \"\"\"\n",
    "        examples: list of tuples\n",
    "            (sup_tensor, prefix_idxs, next_idx, true_goal_idx)\n",
    "        T_q: int\n",
    "            length that we will pad/truncate every prefix to\n",
    "        pad_value: int\n",
    "            index to use for padding prefixes\n",
    "        \"\"\"\n",
    "        self.examples = examples\n",
    "        self.T_q       = T_q\n",
    "        self.pad_value = pad_value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sup_tensor, prefix_list, next_idx, true_goal_idx = self.examples[idx]\n",
    "        # sup_tensor: Tensor[K, T_sup]\n",
    "        # prefix_list: Python list, length <= T_q (unpadded)\n",
    "        # next_idx: int\n",
    "        # true_goal_idx: int\n",
    "        return sup_tensor, torch.tensor(prefix_list, dtype=torch.long), next_idx, true_goal_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a9917c4c-d249-4e75-bc0a-656a4d6ab931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomnet_collate(batch, T_q, pad_value=0):\n",
    "    \"\"\"\n",
    "    batch: list of tuples from __getitem__()\n",
    "      sup_tensor:  KT_sup\n",
    "      prefix:     [t] (list of ints)\n",
    "      next_idx:   scalar int\n",
    "      goal_idx:   scalar int\n",
    "\n",
    "    Returns:\n",
    "      sup_batch:  (B, K, T_sup)\n",
    "      prefix_batch: (B, T_q)\n",
    "      next_batch:   (B,)\n",
    "      goal_batch:   (B,)\n",
    "      prefix_lens:  (B,)  # optional if you need to mask\n",
    "    \"\"\"\n",
    "    sup_list, prefix_list, next_list, goal_list = zip(*batch)\n",
    "    B = len(batch)\n",
    "\n",
    "    # stack support tensors\n",
    "    sup_batch = torch.stack(sup_list, dim=0)    # (B, K, T_sup)\n",
    "\n",
    "    # pad prefixes to length T_q\n",
    "    prefix_batch = torch.full((B, T_q), pad_value, dtype=torch.long)\n",
    "    prefix_lens  = torch.zeros(B, dtype=torch.long)\n",
    "    for i, p in enumerate(prefix_list):\n",
    "        L = min(len(p), T_q)\n",
    "        prefix_batch[i, :L] = p[:L]\n",
    "        prefix_lens[i]      = L\n",
    "\n",
    "    next_batch = torch.tensor(next_list, dtype=torch.long)     # (B,)\n",
    "    goal_batch = torch.tensor(goal_list, dtype=torch.long)     # (B,)\n",
    "\n",
    "    return sup_batch, prefix_batch, next_batch, goal_batch, prefix_lens\n",
    "\n",
    "def tomnet_collate_fn(batch):\n",
    "    # use your existing tomnet_collate, but wrap it\n",
    "    return tomnet_collate(batch, T_q=T_q, pad_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3a53862d-f072-4c62-856a-848c7cd9dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "72e615cb-263c-48fe-95f1-c18cc7248986",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ToMNetDataset(examples_train, T_q=T_q, pad_value=0)\n",
    "test_ds  = ToMNetDataset(examples_test,  T_q=T_q, pad_value=0)\n",
    "\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=6, collate_fn=tomnet_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7ec302ed-c910-4ea1-8290-bafb4cad13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) (optional) split into train/val\n",
    "n_total = len(train_ds)\n",
    "n_val   = int(0.1 * n_total)\n",
    "n_train = n_total - n_val\n",
    "# train_ds, val_ds = random_split((train_ds), [n_train, n_val])\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size, shuffle=True,\n",
    "                                           collate_fn=tomnet_collate_fn,\n",
    "                                           num_workers=16)\n",
    "val_loader   = torch.utils.data.DataLoader(test_ds,   batch_size, shuffle=False,\n",
    "                                           collate_fn=tomnet_collate_fn,\n",
    "                                           num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b356d-8f8c-4a3b-961a-557a501d1218",
   "metadata": {},
   "source": [
    "## Step 4: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4b5078dd-6b02-497b-9a8a-0e77246e9573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 4090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4d957b84-d77b-453c-9561-6332d62634ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# 1) hyperparameters\n",
    "lr         = 1e-3\n",
    "weight_decay = 1e-5\n",
    "num_epochs = 30\n",
    "\n",
    "# 2) model, losses, optimizer\n",
    "model = ToMNet(\n",
    "    node_embeddings = node_embeddings,\n",
    "    num_nodes   = len(node2idx),\n",
    "    num_goals   = len(goal2idx),\n",
    "    T_sup=75    #  etc \n",
    ").to(device)\n",
    "\n",
    "loss_next = nn.CrossEntropyLoss()\n",
    "loss_goal = nn.CrossEntropyLoss()\n",
    "opt       = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2633766e-6773-4729-b265-208b132619f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30  train_loss=7.7873  val_loss=24.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30  train_loss=5.4329  val_loss=21.6176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30  train_loss=4.7429  val_loss=21.5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30  train_loss=4.3386  val_loss=22.2131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30  train_loss=4.0336  val_loss=23.6864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30  train_loss=3.7916  val_loss=24.8129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30  train_loss=3.6358  val_loss=26.9281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30  train_loss=3.4726  val_loss=27.6589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30  train_loss=3.3462  val_loss=29.5430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30  train_loss=3.2252  val_loss=30.6609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30  train_loss=3.1195  val_loss=32.1284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30  train_loss=3.0571  val_loss=33.2657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30  train_loss=2.9618  val_loss=34.5027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30  train_loss=2.8949  val_loss=35.8203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30  train_loss=2.8469  val_loss=37.7971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30  train_loss=2.8128  val_loss=38.2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30  train_loss=2.7505  val_loss=39.1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30  train_loss=2.7075  val_loss=39.8360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30  train_loss=2.6710  val_loss=40.9629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30  train_loss=2.6427  val_loss=42.6205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30  train_loss=2.6120  val_loss=42.7902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30  train_loss=2.5875  val_loss=44.2239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30  train_loss=2.5504  val_loss=44.6150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30  train_loss=2.5309  val_loss=45.4206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30  train_loss=2.5168  val_loss=46.6021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30  train_loss=2.4939  val_loss=47.8869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30  train_loss=2.4825  val_loss=48.5074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30  train_loss=2.4691  val_loss=47.6317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30  train_loss=2.4471  val_loss=49.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30  train_loss=2.4386  val_loss=51.0700\n",
      "Training complete. Best val loss: 21.50067294742816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_state    = None\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    #  Training \n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\", leave=False)\n",
    "    for sup, prefix, next_idx, goal_idx, pre_len in train_bar:\n",
    "        sup      = sup.to(device)       # [B, K, T_sup]\n",
    "        prefix   = prefix.to(device)    # [B, T_q]\n",
    "        pre_len  = pre_len.to(device)   # [B]\n",
    "        next_idx = next_idx.to(device)  # [B]\n",
    "        goal_idx = goal_idx.to(device)  # [B]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # forward\n",
    "        pred_next_logits, pred_goal_logits = model(sup, prefix, pre_len)\n",
    "\n",
    "        # compute losses\n",
    "        L_next = loss_next(pred_next_logits, next_idx)\n",
    "        L_goal = loss_goal(pred_goal_logits,   goal_idx)\n",
    "        loss   = L_next + L_goal\n",
    "\n",
    "        # backward + step\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_train_loss += loss.item() * prefix.size(0)\n",
    "\n",
    "        # update tqdm bar with current batch loss\n",
    "        train_bar.set_postfix(train_loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_train_loss / n_train\n",
    "\n",
    "    #  Validation \n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch}/{num_epochs} [Val]  \", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for sup, prefix, next_idx, goal_idx, pre_len in val_bar:\n",
    "            sup     = sup.to(device)       # [B,K,T_sup]\n",
    "            prefix  = prefix.to(device)    # [B,T_q]\n",
    "            pre_len = pre_len.to(device)   # [B]\n",
    "            next_idx= next_idx.to(device)\n",
    "            goal_idx= goal_idx.to(device)\n",
    "    \n",
    "            # forward\n",
    "            p_next, p_goal = model(sup, prefix, pre_len)\n",
    "            L_next        = loss_next(p_next, next_idx)\n",
    "            L_goal        = loss_goal(p_goal,   goal_idx)\n",
    "            batch_loss    = (L_next + L_goal).item()\n",
    "    \n",
    "            total_val_loss += batch_loss * prefix.size(0)\n",
    "            val_bar.set_postfix(val_loss=batch_loss)\n",
    "    \n",
    "    avg_val_loss = total_val_loss / n_val\n",
    "\n",
    "    # print a summary line\n",
    "    print(f\"Epoch {epoch}/{num_epochs}  \"\n",
    "          f\"train_loss={avg_train_loss:.4f}  val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    # save best\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_state    = model.state_dict()\n",
    "\n",
    "# finally, load best\n",
    "model.load_state_dict(best_state)\n",
    "print(\"Training complete. Best val loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4ce4944f-65b9-4d07-abbe-1cbd2ea660e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"data/en_tomnet_cpu.pth\", _use_new_zipfile_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77722b-6ada-4ea9-9b9d-de2fd758a966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19aa3684-fe0e-41a2-bb83-f60c2b2f6310",
   "metadata": {},
   "source": [
    "## Step 5: Testing and Evaluation with ToMnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5948eebd-b47f-43f2-9a09-198131fec605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_world_src.utils.metrics import brier_along_path, accuracy_along_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "305c7ac8-7199-4d54-a30f-24163b36e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def make_support_tensor(agent_id, episode_id, path_data, node2idx, K, T_sup):\n",
    "    # all eps for this agent\n",
    "    all_eps = [ep for ep in path_data.keys() if ep != episode_id]\n",
    "    # pick K random others:\n",
    "    support_eps = random.sample(all_eps, K)\n",
    "    sup_tensor = torch.zeros(K, T_sup, dtype=torch.long)\n",
    "    for k, ep in enumerate(support_eps):\n",
    "        raw = path_data[ep][agent_id]            # list of nodeids\n",
    "        idxs = [node2idx[n] for n in raw]\n",
    "        L = min(len(idxs), T_sup)\n",
    "        sup_tensor[k, :L] = torch.tensor(idxs[:L], dtype=torch.long)\n",
    "    return sup_tensor  # (KT_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cb198264-b8ce-48e5-a108-09c77fb5b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_goal_dists(\n",
    "    model, agent_id, test_ep,\n",
    "    path_data, node2idx, goal2idx,\n",
    "    K, T_sup, T_q,\n",
    "    device='cuda'\n",
    "):\n",
    "    model.eval()\n",
    "    # 1) build support once\n",
    "    sup     = make_support_tensor(agent_id, test_ep, path_data, node2idx, K, T_sup)\n",
    "    sup     = sup.to(device).unsqueeze(0)     # add batchdim  [1,K,T_sup]\n",
    "\n",
    "    raw_seq = path_data[test_ep][agent_id]\n",
    "    idxs    = [node2idx[n] for n in raw_seq]\n",
    "    N       = len(idxs)\n",
    "\n",
    "    goal_dists = []   # will be list of length N each [num_goals]\n",
    "    with torch.no_grad():\n",
    "        for t in range(1, N):\n",
    "            # build prefix up to t (we treat t=0 as no steps seen)\n",
    "            prefix_len = min(t, T_q)\n",
    "            # pad prefix to T_q\n",
    "            prefix = torch.zeros(T_q, dtype=torch.long)\n",
    "            if prefix_len>0:\n",
    "                prefix[:prefix_len] = torch.tensor(idxs[:prefix_len], dtype=torch.long)\n",
    "            # move to device and batchdim\n",
    "            prefix     = prefix.to(device).unsqueeze(0)       # [1,T_q]\n",
    "            prefix_len = torch.tensor([prefix_len], dtype=torch.long, device=device)\n",
    "\n",
    "            # forward through ToMNet\n",
    "            _, goal_logits = model(sup, prefix, prefix_len)   # [1, num_goals]\n",
    "            p_goal = F.softmax(goal_logits, dim=-1)[0]        # remove batchdim  [num_goals]\n",
    "\n",
    "            goal_dists.append(p_goal.cpu().numpy())\n",
    "\n",
    "    return goal_dists   # shape (N  num_goals) array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "69e4ad74-c445-4c2a-b224-5b84b538674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_id=2\n",
    "test_ep=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b598a77b-1d5b-4b9d-b38e-5276a56f020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = infer_goal_dists(\n",
    "    model, agent_id, test_ep,\n",
    "    path_data, node2idx, goal2idx,\n",
    "    K=10, T_sup=75, T_q=20,\n",
    "    device='mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "54cb6ba3-5d6e-45ba-bd24-eee03c3b783f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.9700037e-02, 4.1934591e-02, 4.2667102e-02, 1.6633566e-02,\n",
       "       4.2453900e-02, 1.3219656e-03, 7.1684784e-01, 3.0715207e-02,\n",
       "       3.6191505e-03, 3.9450587e-03, 5.6437729e-04, 2.2187973e-03,\n",
       "       1.6689390e-03, 6.7154737e-03, 5.8993991e-02], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "878899dc-e522-4388-aba4-a8343dbf75c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path_data[test_ep][agent_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "26c7729b-0eff-4608-be85-58e16290ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal2idx: { goal_node_id  index }\n",
    "idx2goal = { idx: goal for goal, idx in goal2idx.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0631dd72-3d54-43fa-9be4-0c8609ac470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_posteriors = [\n",
    "    { idx2goal[i]: float(p) for i, p in enumerate(prob_row) }\n",
    "    for prob_row in dists\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0f9624fb-4b64-4f68-9f6a-aead9e53a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = brier_along_path(path_data[test_ep][agent_id], \n",
    "                                  goal_data[test_ep][agent_id], \n",
    "                                  goal_posteriors, \n",
    "                                  goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7a141571-85f0-4966-baf8-78a3d716ad09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9333333333333338,\n",
       " 1.501533557717727,\n",
       " 1.3576638356658357,\n",
       " 0.3141094508369385,\n",
       " 0.4645409359343576,\n",
       " 0.4645409359343576,\n",
       " 0.4645409359343576,\n",
       " 0.4645409359343576,\n",
       " 0.4645409359343576,\n",
       " 0.4645409359343576,\n",
       " 0.4645409359343576]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dc49a261-2859-4710-837e-302366b8435b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{469084068: 0.029700037091970444,\n",
       "  49150691: 0.04193459078669548,\n",
       "  768264666: 0.04266710206866264,\n",
       "  1926666015: 0.016633566468954086,\n",
       "  1926673385: 0.04245389997959137,\n",
       "  49309735: 0.0013219655957072973,\n",
       "  273627682: 0.716847836971283,\n",
       "  445989107: 0.030715206637978554,\n",
       "  445992528: 0.0036191504914313555,\n",
       "  446128310: 0.003945058677345514,\n",
       "  1772230346: 0.0005643772892653942,\n",
       "  1926673336: 0.0022187973372638226,\n",
       "  2872424923: 0.0016689390176907182,\n",
       "  3139419286: 0.006715473718941212,\n",
       "  4037576308: 0.05899399146437645},\n",
       " {469084068: 0.028176836669445038,\n",
       "  49150691: 0.6207568049430847,\n",
       "  768264666: 0.0006248040590435266,\n",
       "  1926666015: 0.0009719524532556534,\n",
       "  1926673385: 0.0018185089575126767,\n",
       "  49309735: 0.029667353257536888,\n",
       "  273627682: 0.08413557708263397,\n",
       "  445989107: 0.002388264751061797,\n",
       "  445992528: 0.00103567645419389,\n",
       "  446128310: 0.00016870972467586398,\n",
       "  1772230346: 4.500039358390495e-05,\n",
       "  1926673336: 1.2612237014764105e-06,\n",
       "  2872424923: 4.7963148972485214e-05,\n",
       "  3139419286: 0.0002663767081685364,\n",
       "  4037576308: 0.22989489138126373},\n",
       " {469084068: 0.02951580286026001,\n",
       "  49150691: 0.16033445298671722,\n",
       "  768264666: 0.003703456139191985,\n",
       "  1926666015: 0.002065087202936411,\n",
       "  1926673385: 0.00031156098702922463,\n",
       "  49309735: 0.04145743325352669,\n",
       "  273627682: 0.49987247586250305,\n",
       "  445989107: 0.037862326949834824,\n",
       "  445992528: 0.0014715921133756638,\n",
       "  446128310: 0.00011032242036890239,\n",
       "  1772230346: 4.2374871611627896e-08,\n",
       "  1926673336: 2.966553154237772e-07,\n",
       "  2872424923: 4.386529781186255e-06,\n",
       "  3139419286: 0.004063054453581572,\n",
       "  4037576308: 0.2192276418209076},\n",
       " {469084068: 0.006805506534874439,\n",
       "  49150691: 0.14277322590351105,\n",
       "  768264666: 0.001946393633261323,\n",
       "  1926666015: 0.0003565799561329186,\n",
       "  1926673385: 2.424005742795998e-07,\n",
       "  49309735: 0.00442517502233386,\n",
       "  273627682: 0.011387605220079422,\n",
       "  445989107: 0.006328516639769077,\n",
       "  445992528: 4.497002737480216e-05,\n",
       "  446128310: 3.4463917018001666e-06,\n",
       "  1772230346: 5.524964485914552e-09,\n",
       "  1926673336: 1.998812448888998e-09,\n",
       "  2872424923: 8.315991806284728e-08,\n",
       "  3139419286: 0.0001599790557520464,\n",
       "  4037576308: 0.825768232345581},\n",
       " {469084068: 0.05047997459769249,\n",
       "  49150691: 0.21345558762550354,\n",
       "  768264666: 0.08274393528699875,\n",
       "  1926666015: 0.0005949157057330012,\n",
       "  1926673385: 2.7822639481200895e-07,\n",
       "  49309735: 0.009572681039571762,\n",
       "  273627682: 0.09096483141183853,\n",
       "  445989107: 0.007218523882329464,\n",
       "  445992528: 7.548655958089512e-06,\n",
       "  446128310: 4.140669261687435e-05,\n",
       "  1772230346: 2.0785994081506942e-07,\n",
       "  1926673336: 3.621520194840855e-09,\n",
       "  2872424923: 1.891739088932809e-06,\n",
       "  3139419286: 4.290704509912757e-06,\n",
       "  4037576308: 0.5449139475822449},\n",
       " {469084068: 0.01533290185034275,\n",
       "  49150691: 0.675879180431366,\n",
       "  768264666: 0.006698795594274998,\n",
       "  1926666015: 0.0009010895737446845,\n",
       "  1926673385: 2.2148657308207476e-07,\n",
       "  49309735: 0.007388008292764425,\n",
       "  273627682: 0.015767179429531097,\n",
       "  445989107: 0.004545012954622507,\n",
       "  445992528: 1.390847592119826e-05,\n",
       "  446128310: 5.230745955486782e-06,\n",
       "  1772230346: 3.8462562024221825e-09,\n",
       "  1926673336: 3.542240945009212e-10,\n",
       "  2872424923: 3.365809320143853e-08,\n",
       "  3139419286: 5.321389835444279e-06,\n",
       "  4037576308: 0.27346310019493103},\n",
       " {469084068: 0.03513764962553978,\n",
       "  49150691: 0.6530922651290894,\n",
       "  768264666: 0.10565313696861267,\n",
       "  1926666015: 0.0006554664578288794,\n",
       "  1926673385: 1.5701851907579112e-06,\n",
       "  49309735: 0.006943258922547102,\n",
       "  273627682: 0.03305334970355034,\n",
       "  445989107: 0.017032312229275703,\n",
       "  445992528: 5.6568651416455396e-06,\n",
       "  446128310: 2.0813611627090722e-05,\n",
       "  1772230346: 1.3943305177122056e-08,\n",
       "  1926673336: 2.0323513982845043e-09,\n",
       "  2872424923: 6.52727862870961e-07,\n",
       "  3139419286: 2.764912642305717e-05,\n",
       "  4037576308: 0.1483762115240097},\n",
       " {469084068: 0.07023580372333527,\n",
       "  49150691: 0.557238757610321,\n",
       "  768264666: 0.0013650346081703901,\n",
       "  1926666015: 0.0004501638177316636,\n",
       "  1926673385: 1.4676062392027234e-06,\n",
       "  49309735: 0.02751203253865242,\n",
       "  273627682: 0.020464278757572174,\n",
       "  445989107: 0.016006629914045334,\n",
       "  445992528: 4.373101546661928e-06,\n",
       "  446128310: 4.6195236791390926e-06,\n",
       "  1772230346: 3.592571351518359e-09,\n",
       "  1926673336: 1.4417621541085168e-09,\n",
       "  2872424923: 2.3792118497567571e-07,\n",
       "  3139419286: 4.193009590380825e-05,\n",
       "  4037576308: 0.306674599647522},\n",
       " {469084068: 0.11368461698293686,\n",
       "  49150691: 0.13352248072624207,\n",
       "  768264666: 0.014880448579788208,\n",
       "  1926666015: 0.000517397653311491,\n",
       "  1926673385: 2.7993962703476427e-07,\n",
       "  49309735: 0.09602352976799011,\n",
       "  273627682: 0.2898239195346832,\n",
       "  445989107: 0.01327578816562891,\n",
       "  445992528: 1.997553772525862e-05,\n",
       "  446128310: 2.5528544938424602e-05,\n",
       "  1772230346: 9.194017214220196e-10,\n",
       "  1926673336: 3.645274637698037e-10,\n",
       "  2872424923: 5.753894924964698e-07,\n",
       "  3139419286: 0.0003604447701945901,\n",
       "  4037576308: 0.3378649652004242},\n",
       " {469084068: 0.004554014652967453,\n",
       "  49150691: 0.20220638811588287,\n",
       "  768264666: 0.0010214351350441575,\n",
       "  1926666015: 0.0004972831811755896,\n",
       "  1926673385: 3.028825688033976e-07,\n",
       "  49309735: 0.020647365599870682,\n",
       "  273627682: 0.5655668377876282,\n",
       "  445989107: 0.003929705824702978,\n",
       "  445992528: 2.397200842096936e-05,\n",
       "  446128310: 2.930504479081719e-06,\n",
       "  1772230346: 1.1601658522764069e-09,\n",
       "  1926673336: 7.718483491236938e-11,\n",
       "  2872424923: 5.533198788043592e-08,\n",
       "  3139419286: 0.0002447671431582421,\n",
       "  4037576308: 0.20130495727062225},\n",
       " {469084068: 0.0010624962160363793,\n",
       "  49150691: 0.09997730702161789,\n",
       "  768264666: 0.0015114102279767394,\n",
       "  1926666015: 0.0012544463388621807,\n",
       "  1926673385: 4.743779982163687e-07,\n",
       "  49309735: 0.017008280381560326,\n",
       "  273627682: 0.7335906028747559,\n",
       "  445989107: 0.009923942387104034,\n",
       "  445992528: 1.6732898075133562e-05,\n",
       "  446128310: 8.080596671788953e-06,\n",
       "  1772230346: 7.209936203622647e-09,\n",
       "  1926673336: 8.722271793715208e-10,\n",
       "  2872424923: 7.935534540592926e-08,\n",
       "  3139419286: 8.767628605710343e-05,\n",
       "  4037576308: 0.13555850088596344},\n",
       " {469084068: 0.019254349172115326,\n",
       "  49150691: 0.22783245146274567,\n",
       "  768264666: 0.0013603062834590673,\n",
       "  1926666015: 0.007832163013517857,\n",
       "  1926673385: 5.780372589470062e-07,\n",
       "  49309735: 0.0005004129488952458,\n",
       "  273627682: 0.5572205185890198,\n",
       "  445989107: 0.0034356345422565937,\n",
       "  445992528: 3.164152246881713e-07,\n",
       "  446128310: 1.2119612335936836e-07,\n",
       "  1772230346: 2.119021047519709e-08,\n",
       "  1926673336: 5.816350734377806e-10,\n",
       "  2872424923: 1.4438317208487206e-08,\n",
       "  3139419286: 1.391913065162953e-05,\n",
       "  4037576308: 0.18254923820495605},\n",
       " {469084068: 0.007063495460897684,\n",
       "  49150691: 0.0298052616417408,\n",
       "  768264666: 0.03736421465873718,\n",
       "  1926666015: 0.04952152073383331,\n",
       "  1926673385: 4.9958158342633396e-05,\n",
       "  49309735: 0.00012994889402762055,\n",
       "  273627682: 0.4656515419483185,\n",
       "  445989107: 0.025762824341654778,\n",
       "  445992528: 2.459624511175207e-06,\n",
       "  446128310: 2.820374220391386e-06,\n",
       "  1772230346: 8.646301807857526e-08,\n",
       "  1926673336: 1.068047961183538e-08,\n",
       "  2872424923: 1.98539760276617e-06,\n",
       "  3139419286: 0.00010945435496978462,\n",
       "  4037576308: 0.38453447818756104},\n",
       " {469084068: 0.109401635825634,\n",
       "  49150691: 0.060100723057985306,\n",
       "  768264666: 0.6695603132247925,\n",
       "  1926666015: 0.01534862071275711,\n",
       "  1926673385: 1.521407193649793e-05,\n",
       "  49309735: 2.3943755422806134e-06,\n",
       "  273627682: 0.01711096055805683,\n",
       "  445989107: 0.023190870881080627,\n",
       "  445992528: 1.93851792573696e-06,\n",
       "  446128310: 2.330222741875332e-06,\n",
       "  1772230346: 2.482977379258955e-08,\n",
       "  1926673336: 1.2791923076349576e-09,\n",
       "  2872424923: 2.1408614259144088e-07,\n",
       "  3139419286: 5.782674747933925e-07,\n",
       "  4037576308: 0.10526424646377563},\n",
       " {469084068: 0.16851206123828888,\n",
       "  49150691: 0.13864755630493164,\n",
       "  768264666: 0.3623062074184418,\n",
       "  1926666015: 0.005169447977095842,\n",
       "  1926673385: 3.932687468477525e-05,\n",
       "  49309735: 3.6972622183384374e-05,\n",
       "  273627682: 0.00034290587063878775,\n",
       "  445989107: 0.07629894465208054,\n",
       "  445992528: 5.44381009603967e-07,\n",
       "  446128310: 2.4456898017888307e-07,\n",
       "  1772230346: 7.28063220822861e-10,\n",
       "  1926673336: 5.655871326837314e-10,\n",
       "  2872424923: 1.0116299797857664e-08,\n",
       "  3139419286: 1.4897707387717674e-06,\n",
       "  4037576308: 0.24864432215690613},\n",
       " {469084068: 0.12409437447786331,\n",
       "  49150691: 0.8307555913925171,\n",
       "  768264666: 0.02837592549622059,\n",
       "  1926666015: 0.0002883753622882068,\n",
       "  1926673385: 9.095611517295765e-07,\n",
       "  49309735: 1.7173579180962406e-06,\n",
       "  273627682: 0.0002709421096369624,\n",
       "  445989107: 0.000711483065970242,\n",
       "  445992528: 9.035481411956425e-07,\n",
       "  446128310: 1.8420167862132075e-06,\n",
       "  1772230346: 8.619882585492178e-11,\n",
       "  1926673336: 4.889964544396719e-10,\n",
       "  2872424923: 2.1177322118148822e-09,\n",
       "  3139419286: 6.522067330649861e-09,\n",
       "  4037576308: 0.015497944317758083},\n",
       " {469084068: 0.07805223017930984,\n",
       "  49150691: 0.011234075762331486,\n",
       "  768264666: 0.8686491250991821,\n",
       "  1926666015: 0.008140087127685547,\n",
       "  1926673385: 0.00011193015961907804,\n",
       "  49309735: 1.3418148228083737e-06,\n",
       "  273627682: 5.4425840062322095e-05,\n",
       "  445989107: 0.0040110074914991856,\n",
       "  445992528: 6.290554779297963e-07,\n",
       "  446128310: 6.473057112543756e-08,\n",
       "  1772230346: 1.0345849688064845e-07,\n",
       "  1926673336: 3.515548074872754e-09,\n",
       "  2872424923: 1.779775882226886e-09,\n",
       "  3139419286: 7.30896898559763e-09,\n",
       "  4037576308: 0.029744988307356834},\n",
       " {469084068: 0.4005448818206787,\n",
       "  49150691: 0.155986949801445,\n",
       "  768264666: 0.11005985736846924,\n",
       "  1926666015: 0.11885333806276321,\n",
       "  1926673385: 2.9155822630855255e-05,\n",
       "  49309735: 2.662233100636513e-07,\n",
       "  273627682: 0.0005637891008518636,\n",
       "  445989107: 0.01931839808821678,\n",
       "  445992528: 4.5338417464790837e-08,\n",
       "  446128310: 2.570229362675036e-08,\n",
       "  1772230346: 2.824846800919545e-09,\n",
       "  1926673336: 5.108173084522605e-08,\n",
       "  2872424923: 2.5771582090605705e-10,\n",
       "  3139419286: 2.9576332494229973e-08,\n",
       "  4037576308: 0.19464316964149475},\n",
       " {469084068: 0.5941498279571533,\n",
       "  49150691: 0.3863382041454315,\n",
       "  768264666: 0.007103643845766783,\n",
       "  1926666015: 0.0010587639408186078,\n",
       "  1926673385: 3.5484223189996555e-05,\n",
       "  49309735: 1.256188170373207e-06,\n",
       "  273627682: 0.00027071635122410953,\n",
       "  445989107: 0.001965953968465328,\n",
       "  445992528: 3.783238753385376e-07,\n",
       "  446128310: 3.216407549189171e-07,\n",
       "  1772230346: 1.00742958419886e-09,\n",
       "  1926673336: 3.272470294746199e-08,\n",
       "  2872424923: 1.9597884204358706e-08,\n",
       "  3139419286: 3.4802840787051537e-07,\n",
       "  4037576308: 0.009075155481696129},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444},\n",
       " {469084068: 0.40319541096687317,\n",
       "  49150691: 0.23337095975875854,\n",
       "  768264666: 0.20182423293590546,\n",
       "  1926666015: 0.0002446283760946244,\n",
       "  1926673385: 1.321659851782897e-06,\n",
       "  49309735: 2.599954598281329e-07,\n",
       "  273627682: 5.05125499330461e-05,\n",
       "  445989107: 0.07170389592647552,\n",
       "  445992528: 4.293967322155368e-06,\n",
       "  446128310: 1.1110572586403578e-06,\n",
       "  1772230346: 4.341374815197696e-09,\n",
       "  1926673336: 2.8344513225420087e-07,\n",
       "  2872424923: 1.4982687446263299e-07,\n",
       "  3139419286: 6.113140926800043e-08,\n",
       "  4037576308: 0.08960290998220444}]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa5088-3575-4e85-b426-362412cc9a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb15665c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
