{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661b332f-6eae-4acc-9a92-3d6207778a21",
   "metadata": {},
   "source": [
    "# ToMnet  \n",
    "\n",
    "In this notebook we are going to develop the codebase for ToMNet to work on our simulation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3637e333-6b37-42de-a0ae-75f9db6fc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de85f71e-7d64-4264-9500-ae64e257ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import osmnx as ox\n",
    "\n",
    "# Adjust this path as needed to point to your project root\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "757e0029",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7dd1a603-1b06-4747-8c23-62d35a466e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "mp.set_start_method('fork', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1e8c6d4-ffd3-44d8-8a23-6d37a93f6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_world_src.environment.campus_env import CampusEnvironment\n",
    "from real_world_src.agents.agent_factory import AgentFactory\n",
    "from real_world_src.agents.agent_species import ShortestPathAgent\n",
    "from real_world_src.simulation.simulator import Simulator\n",
    "#from real_world_src.simulation.experiment_1 import Simulator\n",
    "\n",
    "from real_world_src.utils.run_manager import RunManager\n",
    "from real_world_src.utils.config import VISUAL_CONFIG\n",
    "from real_world_src.utils.config import get_agent_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495bee3-fe4c-449e-b383-71dffececdab",
   "metadata": {},
   "source": [
    "## Step 1: Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29bfc584-7cfe-408f-be2b-f7d5b68b44b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading map data for University of California, San Diego, La Jolla, CA, USA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment loaded with 3136 nodes and 8704 edges\n"
     ]
    }
   ],
   "source": [
    "# Create a run manager\n",
    "# run_manager = RunManager('visuals')\n",
    "# run_dir = run_manager.start_new_run()\n",
    "\n",
    "# Initialize campus environment\n",
    "campus = CampusEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59d36b7b-9778-4e7c-b6e6-9946da46e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to establish the set of common goals (just choose the landmark nodes)\n",
    "goals = [469084068, 49150691, 768264666, 1926666015, 1926673385, 49309735,\n",
    "         273627682, 445989107, 445992528, 446128310, 1772230346, 1926673336, \n",
    "         2872424923, 3139419286, 4037576308]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c8ddb05-8af6-4915-b424-59f6d79ea0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# if you used dill, just replace pickle with dill\n",
    "\n",
    "with open('data/agents.pkl', 'rb') as f:\n",
    "    agents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2f34921-df42-40b0-9b12-4b2df0e4bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/path_data.json\", 'r') as file:\n",
    "    path_data = json.load(file)\n",
    "\n",
    "with open(\"./data/goal_data.json\", 'r') as file:\n",
    "    goal_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c93c2e69-3ea5-402a-b014-f49b1a88dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_keys_to_int(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {int(k) if isinstance(k, str) and k.isdigit() else k: convert_keys_to_int(v) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [convert_keys_to_int(item) for item in data]\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d09bd6a6-181a-485f-bfd4-80db4d858f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_data = convert_keys_to_int(goal_data)\n",
    "path_data = convert_keys_to_int(path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c4eb8-925b-440f-bc9a-4c9ab04c120d",
   "metadata": {},
   "source": [
    "## Step 2: Defining ToMnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7bf98054-1d2f-4952-8679-e8265adfed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2573a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Encode K full trajectories per agent into a single 'character' vector c ∈ R^h.\n",
    "    Input shape: (B, K, T_sup) of node indices (long).\n",
    "    CharacterNet using precomputed node2vec embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 node_embeddings: np.ndarray,\n",
    "                 h_lstm: int = 64,\n",
    "                 T_sup: int = 50,\n",
    "                 K: int = 10):\n",
    "        super().__init__()\n",
    "        num_nodes, d_emb = node_embeddings.shape\n",
    "        # Use precomputed embeddings, freeze them\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(node_embeddings), freeze=True, padding_idx=0\n",
    "        )\n",
    "        self.lstm = nn.LSTM(d_emb, h_lstm, batch_first=True)\n",
    "        self.K = K\n",
    "        self.T_sup = T_sup\n",
    "\n",
    "    def forward(self, support_trajs):\n",
    "        # support_trajs: LongTensor[B, K, T_sup]\n",
    "        B, K, T = support_trajs.size()\n",
    "        assert K == self.K and T == self.T_sup\n",
    "\n",
    "        flat = support_trajs.view(B * K, T)\n",
    "        emb = self.embedding(flat)\n",
    "        _, (h_n, _) = self.lstm(emb)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        chars = h_n.view(B, K, -1).mean(dim=1)\n",
    "        return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea9a5f4-8456-4489-8446-42cf6fe18eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentalNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Encode the query prefix into a 'mental' vector m ∈ R^h'.\n",
    "    Inputs:\n",
    "      - prefix     : LongTensor of shape [B, T_q] (node indices, padded with 0)\n",
    "      - prefix_len : LongTensor of shape [B]   (true lengths in 1..T_q)\n",
    "    Outputs:\n",
    "      - m          : FloatTensor of shape [B, h_lstm]\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 node_embeddings: np.ndarray,\n",
    "                 h_lstm:int = 64,\n",
    "                 T_q:int    = 20,\n",
    "                 dropout:float = 0.1,\n",
    "                 use_attention: bool = True):\n",
    "        super().__init__()\n",
    "        num_nodes, d_emb = node_embeddings.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(node_embeddings), freeze=False, padding_idx=0\n",
    "        )\n",
    "        # self.embedding = nn.Embedding(num_nodes, d_emb, padding_idx=0)\n",
    "        self.lstm      = nn.LSTM(d_emb, h_lstm, batch_first=True, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(2 * h_lstm)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.T_q       = T_q\n",
    "        self.use_attention = use_attention\n",
    "        if use_attention:\n",
    "            self.attn = nn.Linear(h_lstm * 2, 1)\n",
    "        \n",
    "    def forward(self, prefix: torch.LongTensor, prefix_len: torch.LongTensor):\n",
    "        B, T = prefix.size()\n",
    "        assert T == self.T_q, f\"Expected T_q={self.T_q}, got {T}\"\n",
    "\n",
    "        # embed all time-steps\n",
    "        emb = self.embedding(prefix)  # [B, T_q, d_emb]\n",
    "\n",
    "        # pack by actual lengths\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            emb,\n",
    "            lengths=prefix_len.cpu(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "        \n",
    "        packed_out, (h_n, _) = self.lstm(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True, total_length=self.T_q)\n",
    "        out = self.layer_norm(self.dropout(out))  # [B, T_q, 2*h_lstm]\n",
    "\n",
    "        if self.use_attention:\n",
    "            mask = torch.arange(self.T_q, device=prefix.device)[None, :] < prefix_len[:, None]\n",
    "            attn_scores = self.attn(out).squeeze(-1)  # [B, T_q]\n",
    "            attn_scores[~mask] = float('-inf')\n",
    "            attn_weights = torch.softmax(attn_scores, dim=1).unsqueeze(-1)  # [B, T_q, 1]\n",
    "            m = (out * attn_weights).sum(dim=1)  # [B, 2*h_lstm]\n",
    "        else:\n",
    "            # Use last valid hidden state for each sequence\n",
    "            idx = (prefix_len - 1).clamp(min=0)\n",
    "            m = out[torch.arange(B), idx]  # [B, 2*h_lstm]\n",
    "\n",
    "        return m\n",
    "\n",
    "        # # run through LSTM\n",
    "        # _, (h_n, _) = self.lstm(packed)\n",
    "        # # h_n: [1, B, h_lstm]\n",
    "        # m = h_n.squeeze(0)            # [B, h_lstm]\n",
    "\n",
    "        # return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "754ef7ef-ca59-4a29-8cc7-1211435686f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToMNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Full ToMNet: CharacterNet + MentalNet + fusion MLP + prediction heads.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 node_embeddings: np.ndarray,\n",
    "                 num_nodes:int,\n",
    "                 num_goals:int,\n",
    "                 K:int=10,\n",
    "                 T_sup:int=50,\n",
    "                 T_q:int=20,\n",
    "                 h_char:int=64,\n",
    "                 h_ment:int=64,\n",
    "                 z_dim:int=32):\n",
    "        super().__init__()\n",
    "        # submodules\n",
    "        num_nodes, d_emb = node_embeddings.shape\n",
    "        self.char_net   = CharacterNet(node_embeddings, h_char, T_sup, K)\n",
    "        self.mental_net = MentalNet(node_embeddings, h_ment, T_q)\n",
    "        # embedding to get last‐step token embedding\n",
    "        # self.embedding  = nn.Embedding(num_nodes, d_emb, padding_idx=0)\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(node_embeddings), freeze=False, padding_idx=0\n",
    "        )\n",
    "\n",
    "        # a small MLP to fuse [h_char + h_ment + d_emb] → z_dim\n",
    "        fusion_dim = h_char + 2*h_ment + d_emb\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, z_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # final prediction heads\n",
    "        self.goal_head = nn.Linear(z_dim, num_goals)\n",
    "        self.next_head = nn.Linear(z_dim, num_nodes)\n",
    "\n",
    "    def forward(self,\n",
    "                sup: torch.LongTensor,       # [B, K, T_sup]\n",
    "                prefix: torch.LongTensor,    # [B, T_q]\n",
    "                prefix_len: torch.LongTensor # [B]\n",
    "               ):\n",
    "        B, K, T_sup = sup.shape\n",
    "        _, T_q     = prefix.shape\n",
    "\n",
    "        # 1) character‐level features from the K support trajectories\n",
    "        #    --> sup_feat: [B, h_char]\n",
    "        sup_feat = self.char_net(sup)\n",
    "\n",
    "        # 2) mental‐net encoding of the current prefix\n",
    "        #    --> ment_feat: [B, h_ment]\n",
    "        ment_feat = self.mental_net(prefix, prefix_len)\n",
    "\n",
    "        # 3) take the *last non‐padded* token in each prefix, embed it\n",
    "        #    prefix_len is in [1..T_q], so subtract 1 for zero‐based index\n",
    "        last_indices = (prefix_len - 1).clamp(min=0)          # [B]\n",
    "        # gather the node index at that last step\n",
    "        last_nodes   = prefix[torch.arange(B), last_indices] # [B]\n",
    "        # embed it\n",
    "        last_emb     = self.embedding(last_nodes)            # [B, d_emb]\n",
    "\n",
    "        # 4) fuse all three representations\n",
    "        #    concat → [B, h_char + h_ment + d_emb]\n",
    "        fusion_input = torch.cat([sup_feat, ment_feat, last_emb], dim=1)\n",
    "        z            = self.fusion(fusion_input)             # [B, z_dim]\n",
    "\n",
    "        # 5) heads\n",
    "        next_logits = self.next_head(z)  # [B, num_nodes]\n",
    "        goal_logits = self.goal_head(z)  # [B, num_goals]\n",
    "\n",
    "        return next_logits, goal_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987eb6d-ef56-4190-a969-c8057514dd57",
   "metadata": {},
   "source": [
    "## Step 3: Prepare the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f981e2d-5699-40e4-b410-bf368f80096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in node2idx: 3170\n"
     ]
    }
   ],
   "source": [
    "# build node2idx so that every node in campus.G_undirected maps to 0…V−1\n",
    "all_nodes = set()\n",
    "for episode in path_data.values():\n",
    "    for path in episode.values():\n",
    "        all_nodes.update(path)\n",
    "all_nodes.update(campus.G_undirected.nodes())\n",
    "all_nodes = list(all_nodes)\n",
    "\n",
    "node2idx = {n: i for i, n in enumerate(all_nodes)}\n",
    "print(f\"Number of nodes in node2idx: {len(node2idx)}\")\n",
    "\n",
    "# all_nodes = list(campus.G_undirected.nodes())\n",
    "# node2idx  = {n:i for i,n in enumerate(all_nodes)}\n",
    "V = len(all_nodes)\n",
    "\n",
    "# build goal2idx likewise for your goals list\n",
    "goal2idx = {g:i for i,g in enumerate(goals)}\n",
    "G = len(goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc3cb833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" #Executed once - Find the node2vec embeddings in the data directory.\n",
    "\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "G = campus.G_undirected\n",
    "\n",
    "# Fitting node2vec model\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=100, num_walks=200, workers=16)\n",
    "n2v_model = node2vec.fit(window=10, min_count=1, batch_words=8)\n",
    "\n",
    "# Building a node_id -> embedding matrix\n",
    "embedding_dim = n2v_model.wv.vector_size\n",
    "node_embeddings = np.zeros((len(node2idx), embedding_dim), dtype=np.float32)\n",
    "\n",
    "for node, idx in node2idx.items():\n",
    "    key = str(node)\n",
    "    if key in n2v_model.wv:\n",
    "        node_embeddings[idx] = n2v_model.wv[key]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "np.save(\"data/node2vec_embeddings.npy\", node_embeddings)\n",
    "print(\"Node2Vec embeddings saved to data/node2vec_embeddings.npy\") \n",
    "\"\"\"\n",
    "\n",
    "node_embeddings = np.load(\"data/node2vec_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae39ba04-97e7-475d-8db7-eb71ed2f4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agent_ids = list(range(0, 70))\n",
    "test_agent_ids = list(range(70, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd493f-90b3-45bd-b3fb-9eb89e02437e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "977d257e-e483-4011-be19-2200cba11d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train examples: 289118\n",
      "# test  examples: 125153\n"
     ]
    }
   ],
   "source": [
    "# hyper‐params\n",
    "K     = 10    # number of support trajectories per agent\n",
    "T_sup = 75    # max length (pad/truncate) of each support trajectory\n",
    "T_q   = 20    # prefix length for query trajectories\n",
    "\n",
    "all_episodes    = list(path_data.keys())\n",
    "examples_train  = []\n",
    "examples_test   = []\n",
    "\n",
    "for agent in agents:\n",
    "    a_id = agent.id\n",
    "\n",
    "    # choose which list to append into\n",
    "    if a_id in train_agent_ids:\n",
    "        target = examples_train\n",
    "    elif a_id in test_agent_ids:\n",
    "        target = examples_test\n",
    "    else:\n",
    "        # silently skip any id outside 0–99\n",
    "        continue\n",
    "\n",
    "    for ep in all_episodes:\n",
    "        # ——— 1) build the K‐shot “support set” for this (agent, ep) ———\n",
    "        other_eps   = [e for e in all_episodes if e != ep]\n",
    "        support_eps = random.sample(other_eps, K)\n",
    "\n",
    "        sup_tensor = torch.zeros(K, T_sup, dtype=torch.long)\n",
    "        for k, se in enumerate(support_eps):\n",
    "            raw_sup  = path_data[se][a_id]           # e.g. [n0, n1, n2, …]\n",
    "            idxs_sup = [node2idx[n] for n in raw_sup]\n",
    "            L        = min(len(idxs_sup), T_sup)\n",
    "            sup_tensor[k, :L] = torch.tensor(idxs_sup[:L], dtype=torch.long)\n",
    "\n",
    "        # ——— 2) unroll *this* episode’s path into (prefix→next) queries ———\n",
    "        raw_q        = path_data[ep][a_id]\n",
    "        idxs_q       = [node2idx[n] for n in raw_q]\n",
    "        true_goal_idx = goal2idx[goal_data[ep][a_id]]\n",
    "\n",
    "        for t in range(1, len(idxs_q)):\n",
    "            prefix_idxs = idxs_q[:t]     # length t (we’ll pad later)\n",
    "            next_idx    = idxs_q[t]      # ground‐truth “next node”\n",
    "\n",
    "            target.append((\n",
    "                sup_tensor.clone(),      # [K×T_sup] LongTensor\n",
    "                prefix_idxs,             # Python list of length t\n",
    "                next_idx,                # int\n",
    "                true_goal_idx            # int\n",
    "            ))\n",
    "\n",
    "print(f\"# train examples: {len(examples_train)}\")\n",
    "print(f\"# test  examples: {len(examples_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba43dabd-af6c-442b-a89d-db469ce7013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ToMNetDataset(Dataset):\n",
    "    def __init__(self, examples, T_q, pad_value=0):\n",
    "        \"\"\"\n",
    "        examples: list of tuples\n",
    "            (sup_tensor, prefix_idxs, next_idx, true_goal_idx)\n",
    "        T_q: int\n",
    "            length that we will pad/truncate every prefix to\n",
    "        pad_value: int\n",
    "            index to use for padding prefixes\n",
    "        \"\"\"\n",
    "        self.examples = examples\n",
    "        self.T_q       = T_q\n",
    "        self.pad_value = pad_value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sup_tensor, prefix_list, next_idx, true_goal_idx = self.examples[idx]\n",
    "        # sup_tensor: Tensor[K, T_sup]\n",
    "        # prefix_list: Python list, length <= T_q (un‐padded)\n",
    "        # next_idx: int\n",
    "        # true_goal_idx: int\n",
    "        return sup_tensor, torch.tensor(prefix_list, dtype=torch.long), next_idx, true_goal_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a9917c4c-d249-4e75-bc0a-656a4d6ab931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomnet_collate(batch, T_q, pad_value=0):\n",
    "    \"\"\"\n",
    "    batch: list of tuples from __getitem__()\n",
    "      sup_tensor:  K×T_sup\n",
    "      prefix:     [t] (list of ints)\n",
    "      next_idx:   scalar int\n",
    "      goal_idx:   scalar int\n",
    "\n",
    "    Returns:\n",
    "      sup_batch:  (B, K, T_sup)\n",
    "      prefix_batch: (B, T_q)\n",
    "      next_batch:   (B,)\n",
    "      goal_batch:   (B,)\n",
    "      prefix_lens:  (B,)  # optional if you need to mask\n",
    "    \"\"\"\n",
    "    sup_list, prefix_list, next_list, goal_list = zip(*batch)\n",
    "    B = len(batch)\n",
    "\n",
    "    # stack support tensors\n",
    "    sup_batch = torch.stack(sup_list, dim=0)    # (B, K, T_sup)\n",
    "\n",
    "    # pad prefixes to length T_q\n",
    "    prefix_batch = torch.full((B, T_q), pad_value, dtype=torch.long)\n",
    "    prefix_lens  = torch.zeros(B, dtype=torch.long)\n",
    "    for i, p in enumerate(prefix_list):\n",
    "        L = min(len(p), T_q)\n",
    "        prefix_batch[i, :L] = p[:L]\n",
    "        prefix_lens[i]      = L\n",
    "\n",
    "    next_batch = torch.tensor(next_list, dtype=torch.long)     # (B,)\n",
    "    goal_batch = torch.tensor(goal_list, dtype=torch.long)     # (B,)\n",
    "\n",
    "    return sup_batch, prefix_batch, next_batch, goal_batch, prefix_lens\n",
    "\n",
    "def tomnet_collate_fn(batch):\n",
    "    # use your existing tomnet_collate, but wrap it\n",
    "    return tomnet_collate(batch, T_q=T_q, pad_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3a53862d-f072-4c62-856a-848c7cd9dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "72e615cb-263c-48fe-95f1-c18cc7248986",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ToMNetDataset(examples_train, T_q=T_q, pad_value=0)\n",
    "test_ds  = ToMNetDataset(examples_test,  T_q=T_q, pad_value=0)\n",
    "\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=6, collate_fn=tomnet_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ec302ed-c910-4ea1-8290-bafb4cad13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) (optional) split into train/val\n",
    "n_total = len(train_ds)\n",
    "n_val   = int(0.1 * n_total)\n",
    "n_train = n_total - n_val\n",
    "# train_ds, val_ds = random_split((train_ds), [n_train, n_val])\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size, shuffle=True,\n",
    "                                           collate_fn=tomnet_collate_fn,\n",
    "                                           num_workers=16)\n",
    "val_loader   = torch.utils.data.DataLoader(test_ds,   batch_size, shuffle=False,\n",
    "                                           collate_fn=tomnet_collate_fn,\n",
    "                                           num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b356d-8f8c-4a3b-961a-557a501d1218",
   "metadata": {},
   "source": [
    "## Step 4: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b5078dd-6b02-497b-9a8a-0e77246e9573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 4090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4d957b84-d77b-453c-9561-6332d62634ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# 1) hyper‐parameters\n",
    "lr         = 1e-3\n",
    "weight_decay = 1e-5\n",
    "num_epochs = 30\n",
    "\n",
    "# 2) model, losses, optimizer\n",
    "model = ToMNet(\n",
    "    node_embeddings = node_embeddings,\n",
    "    num_nodes   = len(node2idx),\n",
    "    num_goals   = len(goal2idx),\n",
    "    T_sup=75    # … etc …\n",
    ").to(device)\n",
    "\n",
    "loss_next = nn.CrossEntropyLoss()\n",
    "loss_goal = nn.CrossEntropyLoss()\n",
    "opt       = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2633766e-6773-4729-b265-208b132619f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30  train_loss=6.9122  val_loss=22.7074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30  train_loss=4.9487  val_loss=22.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30  train_loss=4.3502  val_loss=23.7592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30  train_loss=3.8895  val_loss=27.0902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30  train_loss=3.5232  val_loss=29.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30  train_loss=3.2446  val_loss=32.3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30  train_loss=3.0546  val_loss=34.8195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30  train_loss=2.9160  val_loss=37.3059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30  train_loss=2.8179  val_loss=40.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30  train_loss=2.7311  val_loss=40.8868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30  train_loss=2.6703  val_loss=42.4022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30  train_loss=2.6125  val_loss=43.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30  train_loss=2.5812  val_loss=44.7923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30  train_loss=2.5355  val_loss=45.6033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30  train_loss=2.5034  val_loss=47.8446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30  train_loss=2.4782  val_loss=47.7170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30  train_loss=2.4624  val_loss=48.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30  train_loss=2.4417  val_loss=50.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30  train_loss=2.4259  val_loss=50.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30  train_loss=2.4163  val_loss=51.2067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30  train_loss=2.3990  val_loss=50.9581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30  train_loss=2.3840  val_loss=51.7084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30  train_loss=2.3737  val_loss=53.2495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30  train_loss=2.3743  val_loss=53.6829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30  train_loss=2.3616  val_loss=55.0527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30  train_loss=2.3641  val_loss=54.3776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30  train_loss=2.3473  val_loss=55.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30  train_loss=2.3426  val_loss=54.6573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30  train_loss=2.3359  val_loss=55.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30  train_loss=2.3266  val_loss=54.4623\n",
      "Training complete. Best val loss: 22.00158353744319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_state    = None\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    # —————— Training ——————\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\", leave=False)\n",
    "    for sup, prefix, next_idx, goal_idx, pre_len in train_bar:\n",
    "        sup      = sup.to(device)       # [B, K, T_sup]\n",
    "        prefix   = prefix.to(device)    # [B, T_q]\n",
    "        pre_len  = pre_len.to(device)   # [B]\n",
    "        next_idx = next_idx.to(device)  # [B]\n",
    "        goal_idx = goal_idx.to(device)  # [B]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # forward\n",
    "        pred_next_logits, pred_goal_logits = model(sup, prefix, pre_len)\n",
    "\n",
    "        # compute losses\n",
    "        L_next = loss_next(pred_next_logits, next_idx)\n",
    "        L_goal = loss_goal(pred_goal_logits,   goal_idx)\n",
    "        loss   = L_next + L_goal\n",
    "\n",
    "        # backward + step\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_train_loss += loss.item() * prefix.size(0)\n",
    "\n",
    "        # update tqdm bar with current batch loss\n",
    "        train_bar.set_postfix(train_loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_train_loss / n_train\n",
    "\n",
    "    # —————— Validation ——————\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch}/{num_epochs} [Val]  \", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for sup, prefix, next_idx, goal_idx, pre_len in val_bar:\n",
    "            sup     = sup.to(device)       # [B,K,T_sup]\n",
    "            prefix  = prefix.to(device)    # [B,T_q]\n",
    "            pre_len = pre_len.to(device)   # [B]\n",
    "            next_idx= next_idx.to(device)\n",
    "            goal_idx= goal_idx.to(device)\n",
    "    \n",
    "            # forward\n",
    "            p_next, p_goal = model(sup, prefix, pre_len)\n",
    "            L_next        = loss_next(p_next, next_idx)\n",
    "            L_goal        = loss_goal(p_goal,   goal_idx)\n",
    "            batch_loss    = (L_next + L_goal).item()\n",
    "    \n",
    "            total_val_loss += batch_loss * prefix.size(0)\n",
    "            val_bar.set_postfix(val_loss=batch_loss)\n",
    "    \n",
    "    avg_val_loss = total_val_loss / n_val\n",
    "\n",
    "    # print a summary line\n",
    "    print(f\"Epoch {epoch}/{num_epochs}  \"\n",
    "          f\"train_loss={avg_train_loss:.4f}  val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    # save best\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_state    = model.state_dict()\n",
    "\n",
    "# finally, load best\n",
    "model.load_state_dict(best_state)\n",
    "print(\"Training complete. Best val loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4ce4944f-65b9-4d07-abbe-1cbd2ea660e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"data/All_en_tomnet_cuda.pth\", _use_new_zipfile_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77722b-6ada-4ea9-9b9d-de2fd758a966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19aa3684-fe0e-41a2-bb83-f60c2b2f6310",
   "metadata": {},
   "source": [
    "## Step 5: Testing and Evaluation with ToMnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5948eebd-b47f-43f2-9a09-198131fec605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_world_src.utils.metrics import brier_along_path, accuracy_along_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "305c7ac8-7199-4d54-a30f-24163b36e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def make_support_tensor(agent_id, episode_id, path_data, node2idx, K, T_sup):\n",
    "    # all eps for this agent\n",
    "    all_eps = [ep for ep in path_data.keys() if ep != episode_id]\n",
    "    # pick K random others:\n",
    "    support_eps = random.sample(all_eps, K)\n",
    "    sup_tensor = torch.zeros(K, T_sup, dtype=torch.long)\n",
    "    for k, ep in enumerate(support_eps):\n",
    "        raw = path_data[ep][agent_id]            # list of node‐ids\n",
    "        idxs = [node2idx[n] for n in raw]\n",
    "        L = min(len(idxs), T_sup)\n",
    "        sup_tensor[k, :L] = torch.tensor(idxs[:L], dtype=torch.long)\n",
    "    return sup_tensor  # (K×T_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb198264-b8ce-48e5-a108-09c77fb5b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_goal_dists(\n",
    "    model, agent_id, test_ep,\n",
    "    path_data, node2idx, goal2idx,\n",
    "    K, T_sup, T_q,\n",
    "    device='cuda'\n",
    "):\n",
    "    model.eval()\n",
    "    # 1) build support once\n",
    "    sup     = make_support_tensor(agent_id, test_ep, path_data, node2idx, K, T_sup)\n",
    "    sup     = sup.to(device).unsqueeze(0)     # add batch‐dim → [1,K,T_sup]\n",
    "\n",
    "    raw_seq = path_data[test_ep][agent_id]\n",
    "    idxs    = [node2idx[n] for n in raw_seq]\n",
    "    N       = len(idxs)\n",
    "\n",
    "    goal_dists = []   # will be list of length N each [num_goals]\n",
    "    with torch.no_grad():\n",
    "        for t in range(1, N):\n",
    "            # build prefix up to t (we treat t=0 as “no steps seen”)\n",
    "            prefix_len = min(t, T_q)\n",
    "            # pad prefix to T_q\n",
    "            prefix = torch.zeros(T_q, dtype=torch.long)\n",
    "            if prefix_len>0:\n",
    "                prefix[:prefix_len] = torch.tensor(idxs[:prefix_len], dtype=torch.long)\n",
    "            # move to device and batch‐dim\n",
    "            prefix     = prefix.to(device).unsqueeze(0)       # [1,T_q]\n",
    "            prefix_len = torch.tensor([prefix_len], dtype=torch.long, device=device)\n",
    "\n",
    "            # forward through ToMNet\n",
    "            _, goal_logits = model(sup, prefix, prefix_len)   # [1, num_goals]\n",
    "            p_goal = F.softmax(goal_logits, dim=-1)[0]        # remove batch‐dim → [num_goals]\n",
    "\n",
    "            goal_dists.append(p_goal.cpu().numpy())\n",
    "\n",
    "    return goal_dists   # shape (N × num_goals) array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "69e4ad74-c445-4c2a-b224-5b84b538674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_id=2\n",
    "test_ep=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b598a77b-1d5b-4b9d-b38e-5276a56f020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = infer_goal_dists(\n",
    "    model, agent_id, test_ep,\n",
    "    path_data, node2idx, goal2idx,\n",
    "    K=10, T_sup=75, T_q=20,\n",
    "    device='mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "54cb6ba3-5d6e-45ba-bd24-eee03c3b783f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.6353358e-01, 3.3210710e-02, 9.7256631e-08, 4.3268625e-07,\n",
       "       3.7784666e-08, 6.7487068e-04, 1.3993939e-09, 4.4296911e-16,\n",
       "       4.3171546e-15, 7.7847410e-15, 9.6222379e-13, 2.4198443e-03,\n",
       "       4.8614932e-12, 1.6025700e-04, 2.9114938e-07], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "878899dc-e522-4388-aba4-a8343dbf75c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path_data[test_ep][agent_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "26c7729b-0eff-4608-be85-58e16290ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal2idx: { goal_node_id → index }\n",
    "idx2goal = { idx: goal for goal, idx in goal2idx.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0631dd72-3d54-43fa-9be4-0c8609ac470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_posteriors = [\n",
    "    { idx2goal[i]: float(p) for i, p in enumerate(prob_row) }\n",
    "    for prob_row in dists\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f9624fb-4b64-4f68-9f6a-aead9e53a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = brier_along_path(path_data[test_ep][agent_id], \n",
    "                                  goal_data[test_ep][agent_id], \n",
    "                                  goal_posteriors, \n",
    "                                  goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7a141571-85f0-4966-baf8-78a3d716ad09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9333333333333338,\n",
       " 1.73920083467773e-05,\n",
       " 4.4062945250520044e-06,\n",
       " 0.004934948360281463,\n",
       " 0.018079484875425628,\n",
       " 0.018079484875425628,\n",
       " 0.018079484875425628,\n",
       " 0.018079484875425628,\n",
       " 0.018079484875425628,\n",
       " 0.018079484875425628,\n",
       " 0.018079484875425628]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dc49a261-2859-4710-837e-302366b8435b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{469084068: 0.9635335803031921,\n",
       "  49150691: 0.03321070969104767,\n",
       "  768264666: 9.725663119297678e-08,\n",
       "  1926666015: 4.3268624949632795e-07,\n",
       "  1926673385: 3.778466606263464e-08,\n",
       "  49309735: 0.0006748706800863147,\n",
       "  273627682: 1.399393934065074e-09,\n",
       "  445989107: 4.429691146564372e-16,\n",
       "  445992528: 4.3171545609504026e-15,\n",
       "  446128310: 7.784741005035373e-15,\n",
       "  1772230346: 9.622237902295883e-13,\n",
       "  1926673336: 0.0024198442697525024,\n",
       "  2872424923: 4.861493152485963e-12,\n",
       "  3139419286: 0.0001602569973329082,\n",
       "  4037576308: 2.9114937660779105e-07},\n",
       " {469084068: 0.9891675710678101,\n",
       "  49150691: 0.008286788128316402,\n",
       "  768264666: 1.3653706787408737e-07,\n",
       "  1926666015: 5.198809276407701e-07,\n",
       "  1926673385: 2.1881435330328713e-08,\n",
       "  49309735: 0.0005325276870280504,\n",
       "  273627682: 1.147552630698101e-08,\n",
       "  445989107: 8.841138791631663e-16,\n",
       "  445992528: 2.960048113738456e-13,\n",
       "  446128310: 4.675619327744896e-15,\n",
       "  1772230346: 5.994546764358233e-13,\n",
       "  1926673336: 0.00018444479792378843,\n",
       "  2872424923: 3.2565267756717864e-12,\n",
       "  3139419286: 0.0018277240451425314,\n",
       "  4037576308: 2.391852262917382e-07},\n",
       " {469084068: 0.9830900430679321,\n",
       "  49150691: 0.01021083164960146,\n",
       "  768264666: 4.728208011783863e-07,\n",
       "  1926666015: 4.723477559309686e-06,\n",
       "  1926673385: 7.258308953872472e-10,\n",
       "  49309735: 0.005011822562664747,\n",
       "  273627682: 6.797417029247299e-08,\n",
       "  445989107: 9.976652631875057e-16,\n",
       "  445992528: 7.266300598328043e-14,\n",
       "  446128310: 3.8288816561760086e-14,\n",
       "  1772230346: 8.435014839380806e-12,\n",
       "  1926673336: 0.00037309774779714644,\n",
       "  2872424923: 4.930429953198256e-10,\n",
       "  3139419286: 0.0013079133350402117,\n",
       "  4037576308: 9.343183364762808e-07},\n",
       " {469084068: 0.998945415019989,\n",
       "  49150691: 0.00037377572152763605,\n",
       "  768264666: 4.076560955468267e-08,\n",
       "  1926666015: 2.0920516874411987e-08,\n",
       "  1926673385: 6.851719747125173e-10,\n",
       "  49309735: 0.0006021848530508578,\n",
       "  273627682: 1.4526215785792829e-09,\n",
       "  445989107: 1.3180975094964523e-15,\n",
       "  445992528: 1.0138064500853257e-14,\n",
       "  446128310: 1.8638826173125213e-14,\n",
       "  1772230346: 1.0310122303429023e-13,\n",
       "  1926673336: 5.176917329663411e-05,\n",
       "  2872424923: 3.8217318198974226e-11,\n",
       "  3139419286: 2.56049279414583e-05,\n",
       "  4037576308: 1.2034649898851058e-06},\n",
       " {469084068: 0.9976327419281006,\n",
       "  49150691: 0.0015389174222946167,\n",
       "  768264666: 2.5698174255239792e-08,\n",
       "  1926666015: 1.7762006976340672e-08,\n",
       "  1926673385: 4.4991052550180655e-11,\n",
       "  49309735: 0.0007701638387516141,\n",
       "  273627682: 1.915182235023849e-09,\n",
       "  445989107: 9.280846035347783e-17,\n",
       "  445992528: 5.489039784190659e-16,\n",
       "  446128310: 3.5578767681304895e-15,\n",
       "  1772230346: 5.434852058412015e-14,\n",
       "  1926673336: 2.717004645091947e-05,\n",
       "  2872424923: 2.596149857592156e-12,\n",
       "  3139419286: 3.0518986022798344e-05,\n",
       "  4037576308: 4.1178213905368466e-07},\n",
       " {469084068: 0.9968118071556091,\n",
       "  49150691: 0.00010416096483822912,\n",
       "  768264666: 3.7676342046211175e-09,\n",
       "  1926666015: 6.687542395411583e-07,\n",
       "  1926673385: 2.5074458065432736e-09,\n",
       "  49309735: 0.0026580188423395157,\n",
       "  273627682: 1.264725391081356e-08,\n",
       "  445989107: 1.5627162306800803e-16,\n",
       "  445992528: 3.6659488548377184e-15,\n",
       "  446128310: 9.50316333194227e-15,\n",
       "  1772230346: 6.599953873351327e-13,\n",
       "  1926673336: 0.000387433246942237,\n",
       "  2872424923: 1.670133475961677e-10,\n",
       "  3139419286: 3.76305979443714e-05,\n",
       "  4037576308: 1.754242759943736e-07},\n",
       " {469084068: 0.9987433552742004,\n",
       "  49150691: 2.571548793639522e-05,\n",
       "  768264666: 1.1594288196192792e-08,\n",
       "  1926666015: 1.4824131540080998e-06,\n",
       "  1926673385: 1.821707007465534e-09,\n",
       "  49309735: 0.0008323630318045616,\n",
       "  273627682: 4.3873025212803896e-09,\n",
       "  445989107: 4.288255967312013e-16,\n",
       "  445992528: 3.4503815108603408e-15,\n",
       "  446128310: 3.1378712460697084e-15,\n",
       "  1772230346: 1.956118860640954e-12,\n",
       "  1926673336: 8.332176366820931e-05,\n",
       "  2872424923: 6.171018557266095e-11,\n",
       "  3139419286: 0.0003135304432362318,\n",
       "  4037576308: 1.6277917325169255e-07},\n",
       " {469084068: 0.8479758501052856,\n",
       "  49150691: 0.004914578516036272,\n",
       "  768264666: 3.09274832943629e-06,\n",
       "  1926666015: 1.240324394302661e-07,\n",
       "  1926673385: 8.580417265591223e-09,\n",
       "  49309735: 0.1453944891691208,\n",
       "  273627682: 1.2437326724068498e-08,\n",
       "  445989107: 9.729020432162894e-14,\n",
       "  445992528: 2.908977109216705e-14,\n",
       "  446128310: 2.644539521721133e-14,\n",
       "  1772230346: 1.2045480932143526e-11,\n",
       "  1926673336: 0.0009330652537755668,\n",
       "  2872424923: 8.177623023186698e-10,\n",
       "  3139419286: 0.0007760771550238132,\n",
       "  4037576308: 2.660147401911672e-06},\n",
       " {469084068: 0.9983407258987427,\n",
       "  49150691: 0.00021957514400128275,\n",
       "  768264666: 5.9188685952449305e-08,\n",
       "  1926666015: 1.4935737624455214e-07,\n",
       "  1926673385: 2.1549730888636986e-09,\n",
       "  49309735: 0.0010496774921193719,\n",
       "  273627682: 1.5055792168539028e-09,\n",
       "  445989107: 2.9128279856927193e-16,\n",
       "  445992528: 1.795281461266043e-15,\n",
       "  446128310: 1.1974497999070466e-14,\n",
       "  1772230346: 6.373190820571639e-13,\n",
       "  1926673336: 0.0002668677770998329,\n",
       "  2872424923: 1.6299379901330013e-10,\n",
       "  3139419286: 0.00012261333176866174,\n",
       "  4037576308: 3.059133177885087e-07},\n",
       " {469084068: 0.9983081817626953,\n",
       "  49150691: 0.00031235069036483765,\n",
       "  768264666: 1.8762168707553428e-08,\n",
       "  1926666015: 1.7886124581423246e-08,\n",
       "  1926673385: 1.5647035889188032e-09,\n",
       "  49309735: 0.0011913190828636289,\n",
       "  273627682: 1.359033552361666e-09,\n",
       "  445989107: 1.119011520848512e-16,\n",
       "  445992528: 1.7484600210406669e-15,\n",
       "  446128310: 4.366725216012682e-14,\n",
       "  1772230346: 1.0006202680670762e-12,\n",
       "  1926673336: 0.00016993228928186,\n",
       "  2872424923: 1.7013675190913347e-10,\n",
       "  3139419286: 1.8107311916537583e-05,\n",
       "  4037576308: 5.559465776627803e-08},\n",
       " {469084068: 0.9680229425430298,\n",
       "  49150691: 0.004061053041368723,\n",
       "  768264666: 2.126483195752371e-06,\n",
       "  1926666015: 1.4062542277315515e-06,\n",
       "  1926673385: 2.572006962964224e-08,\n",
       "  49309735: 0.019310850650072098,\n",
       "  273627682: 7.976995952674315e-09,\n",
       "  445989107: 6.969808573602937e-14,\n",
       "  445992528: 9.689734366442881e-14,\n",
       "  446128310: 2.6645791692883614e-13,\n",
       "  1772230346: 2.3416076369575656e-11,\n",
       "  1926673336: 0.00838060025125742,\n",
       "  2872424923: 1.1938349198103992e-09,\n",
       "  3139419286: 0.0002201673196395859,\n",
       "  4037576308: 8.278239533865417e-07},\n",
       " {469084068: 0.9983069896697998,\n",
       "  49150691: 0.0003778821264859289,\n",
       "  768264666: 2.384993535997637e-07,\n",
       "  1926666015: 1.5915119888632034e-08,\n",
       "  1926673385: 3.0543074736044673e-09,\n",
       "  49309735: 0.0011771913850679994,\n",
       "  273627682: 4.1389200400310244e-10,\n",
       "  445989107: 1.3222241481363568e-15,\n",
       "  445992528: 3.718837168547803e-15,\n",
       "  446128310: 2.0835269002716233e-14,\n",
       "  1772230346: 2.074534391927757e-13,\n",
       "  1926673336: 0.00010097365156980231,\n",
       "  2872424923: 1.559284507068881e-10,\n",
       "  3139419286: 3.5184646549168974e-05,\n",
       "  4037576308: 1.54708845911955e-06},\n",
       " {469084068: 0.99883633852005,\n",
       "  49150691: 3.4628355933818966e-05,\n",
       "  768264666: 1.4068025677715923e-07,\n",
       "  1926666015: 8.302153275963065e-08,\n",
       "  1926673385: 4.315799273513221e-09,\n",
       "  49309735: 0.0008879314991645515,\n",
       "  273627682: 2.1352779544514533e-09,\n",
       "  445989107: 1.822664469439822e-14,\n",
       "  445992528: 1.9442840011054362e-14,\n",
       "  446128310: 1.7315675802931363e-12,\n",
       "  1772230346: 1.7719823872108798e-11,\n",
       "  1926673336: 0.00023780809715390205,\n",
       "  2872424923: 2.643004926028425e-09,\n",
       "  3139419286: 2.8692352316284087e-06,\n",
       "  4037576308: 2.622104204874631e-07},\n",
       " {469084068: 0.957577109336853,\n",
       "  49150691: 0.04184503108263016,\n",
       "  768264666: 6.250622845982434e-07,\n",
       "  1926666015: 3.150367433590873e-08,\n",
       "  1926673385: 2.1800978800001758e-09,\n",
       "  49309735: 0.0002372445451328531,\n",
       "  273627682: 2.539774779375392e-10,\n",
       "  445989107: 3.8577731770892884e-17,\n",
       "  445992528: 1.5177520901860607e-14,\n",
       "  446128310: 4.976538929210572e-13,\n",
       "  1772230346: 2.586063741621958e-12,\n",
       "  1926673336: 0.0003213433374185115,\n",
       "  2872424923: 5.2762266777861555e-11,\n",
       "  3139419286: 8.879026609065477e-06,\n",
       "  4037576308: 9.806662092159968e-06},\n",
       " {469084068: 0.9939153790473938,\n",
       "  49150691: 0.005316350609064102,\n",
       "  768264666: 6.483209062935202e-07,\n",
       "  1926666015: 1.4709859996742125e-08,\n",
       "  1926673385: 1.6332710739419554e-09,\n",
       "  49309735: 0.0004249520425219089,\n",
       "  273627682: 1.6113750611612687e-10,\n",
       "  445989107: 4.597519078359787e-15,\n",
       "  445992528: 8.99018069732728e-15,\n",
       "  446128310: 5.753993066520344e-14,\n",
       "  1772230346: 6.986789619078948e-12,\n",
       "  1926673336: 0.0003383479779586196,\n",
       "  2872424923: 7.662342982328596e-12,\n",
       "  3139419286: 1.7868596842163242e-06,\n",
       "  4037576308: 2.515165533623076e-06},\n",
       " {469084068: 0.973848819732666,\n",
       "  49150691: 0.020545052364468575,\n",
       "  768264666: 5.070329734735424e-06,\n",
       "  1926666015: 2.8643862606259063e-06,\n",
       "  1926673385: 5.045425410798998e-08,\n",
       "  49309735: 0.0004927455447614193,\n",
       "  273627682: 2.2404209043536127e-10,\n",
       "  445989107: 1.670890543676131e-15,\n",
       "  445992528: 1.1102892287203139e-13,\n",
       "  446128310: 8.591539209668736e-14,\n",
       "  1772230346: 2.0069371164943561e-10,\n",
       "  1926673336: 0.005085255019366741,\n",
       "  2872424923: 4.834101452466655e-10,\n",
       "  3139419286: 1.2043645256198943e-05,\n",
       "  4037576308: 8.217290996981319e-06},\n",
       " {469084068: 0.9825354814529419,\n",
       "  49150691: 0.01269884966313839,\n",
       "  768264666: 2.273373684147373e-05,\n",
       "  1926666015: 5.881389597561792e-07,\n",
       "  1926673385: 4.723510471649206e-08,\n",
       "  49309735: 0.00281718117184937,\n",
       "  273627682: 2.560206213697569e-11,\n",
       "  445989107: 3.490715610445991e-14,\n",
       "  445992528: 5.926007297721303e-13,\n",
       "  446128310: 6.157581226590852e-14,\n",
       "  1772230346: 5.126388202825183e-10,\n",
       "  1926673336: 0.0015842994907870889,\n",
       "  2872424923: 8.544244756159003e-10,\n",
       "  3139419286: 1.9066972072323551e-06,\n",
       "  4037576308: 0.0003389955672901124},\n",
       " {469084068: 0.9468785524368286,\n",
       "  49150691: 0.031818777322769165,\n",
       "  768264666: 3.1441538794751978e-06,\n",
       "  1926666015: 2.8007573149579912e-08,\n",
       "  1926673385: 4.9894697262686805e-09,\n",
       "  49309735: 0.009548274800181389,\n",
       "  273627682: 1.1826725709873642e-10,\n",
       "  445989107: 1.0934317611161425e-15,\n",
       "  445992528: 7.79252523782064e-16,\n",
       "  446128310: 2.315286464881893e-14,\n",
       "  1772230346: 6.14989266109478e-12,\n",
       "  1926673336: 0.011744511313736439,\n",
       "  2872424923: 1.8243742627710446e-10,\n",
       "  3139419286: 1.508423338236753e-06,\n",
       "  4037576308: 5.182484528631903e-06},\n",
       " {469084068: 0.9467763304710388,\n",
       "  49150691: 0.04530758410692215,\n",
       "  768264666: 6.927641516085714e-05,\n",
       "  1926666015: 1.6078425915111438e-06,\n",
       "  1926673385: 3.4337672705220257e-09,\n",
       "  49309735: 0.0007140561938285828,\n",
       "  273627682: 4.5538377513310024e-09,\n",
       "  445989107: 6.894316253959129e-15,\n",
       "  445992528: 9.99107209725264e-15,\n",
       "  446128310: 1.3268742658431587e-12,\n",
       "  1772230346: 3.2631128354942973e-10,\n",
       "  1926673336: 0.006991417612880468,\n",
       "  2872424923: 9.89741955059742e-10,\n",
       "  3139419286: 7.308556632779073e-06,\n",
       "  4037576308: 0.0001324116310570389},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679},\n",
       " {469084068: 0.893905520439148,\n",
       "  49150691: 0.027121465653181076,\n",
       "  768264666: 0.00018493134120944887,\n",
       "  1926666015: 6.636668786086375e-06,\n",
       "  1926673385: 1.9830774817819474e-06,\n",
       "  49309735: 0.0004668516048695892,\n",
       "  273627682: 1.6294766425062335e-08,\n",
       "  445989107: 1.5507153894311898e-10,\n",
       "  445992528: 2.5821997318153933e-11,\n",
       "  446128310: 4.3227732504647065e-10,\n",
       "  1772230346: 2.036428092822007e-08,\n",
       "  1926673336: 0.07802267372608185,\n",
       "  2872424923: 3.21464668218141e-08,\n",
       "  3139419286: 2.5379870294273132e-06,\n",
       "  4037576308: 0.0002873380435630679}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86704b53",
   "metadata": {},
   "source": [
    "### DVIB LOSS Included - Modified Char and Mental Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "53aa5088-3575-4e85-b426-362412cc9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational CharacterNet: outputs z_char, mu_char, logvar_char.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 node_embeddings: np.ndarray, \n",
    "                 h_lstm: int = 64, \n",
    "                 T_sup: int = 50, \n",
    "                 K: int = 10, \n",
    "                 z_dim: int = 64):\n",
    "        super().__init__()\n",
    "        num_nodes, d_emb = node_embeddings.shape\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(node_embeddings), freeze=True, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(d_emb, h_lstm, batch_first=True)\n",
    "        \n",
    "        self.K = K\n",
    "        self.T_sup = T_sup\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.fc_mu = nn.Linear(h_lstm, z_dim)\n",
    "        self.fc_logvar = nn.Linear(h_lstm, z_dim)\n",
    "\n",
    "    def forward(self, support_trajs):\n",
    "        \n",
    "        B, K, T = support_trajs.size()\n",
    "        assert K == self.K and T == self.T_sup\n",
    "        \n",
    "        flat = support_trajs.view(B * K, T)\n",
    "        emb = self.embedding(flat)\n",
    "        _, (h_n, _) = self.lstm(emb)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        \n",
    "        chars = h_n.view(B, K, -1).mean(dim=1)  # [B, h_lstm]\n",
    "        mu = self.fc_mu(chars)\n",
    "        logvar = self.fc_logvar(chars)\n",
    "        \n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        \n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8d308626",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentalNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational MentalNet: outputs z_mental, mu_mental, logvar_mental.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 node_embeddings: np.ndarray, \n",
    "                 h_lstm: int = 64, \n",
    "                 T_q: int = 20, \n",
    "                 dropout: float = 0.1, \n",
    "                 use_attention: bool = True, \n",
    "                 z_dim: int = 64):\n",
    "        super().__init__()\n",
    "        num_nodes, d_emb = node_embeddings.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(node_embeddings), freeze=False, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(d_emb, h_lstm, batch_first=True, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(2 * h_lstm)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.T_q = T_q\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.use_attention = use_attention\n",
    "        \n",
    "        if use_attention:\n",
    "            self.attn = nn.Linear(h_lstm * 2, 1)\n",
    "        \n",
    "        self.fc_mu = nn.Linear(2 * h_lstm, z_dim)\n",
    "        self.fc_logvar = nn.Linear(2 * h_lstm, z_dim)\n",
    "\n",
    "    def forward(self, prefix: torch.LongTensor, prefix_len: torch.LongTensor):\n",
    "        B, T = prefix.size()\n",
    "        assert T == self.T_q, f\"Expected T_q={self.T_q}, got {T}\"\n",
    "        \n",
    "        emb = self.embedding(prefix)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths=prefix_len.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, (h_n, _) = self.lstm(packed)\n",
    "        \n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True, total_length=self.T_q)\n",
    "        out = self.layer_norm(self.dropout(out))  # [B, T_q, 2*h_lstm]\n",
    "        \n",
    "        if self.use_attention:\n",
    "            mask = torch.arange(self.T_q, device=prefix.device)[None, :] < prefix_len[:, None]\n",
    "            attn_scores = self.attn(out).squeeze(-1)\n",
    "            attn_scores[~mask] = float('-inf')\n",
    "            attn_weights = torch.softmax(attn_scores, dim=1).unsqueeze(-1)\n",
    "            feat = (out * attn_weights).sum(dim=1)\n",
    "        else:\n",
    "            idx = (prefix_len - 1).clamp(min=0)\n",
    "            feat = out[torch.arange(B), idx]\n",
    "        \n",
    "        mu = self.fc_mu(feat)\n",
    "        logvar = self.fc_logvar(feat)\n",
    "        \n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        \n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e298b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToMNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ToMNet with DVIB: CharacterNet + MentalNet + fusion MLP + prediction heads.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 node_embeddings: np.ndarray, \n",
    "                 num_nodes: int, \n",
    "                 num_goals: int, \n",
    "                 K: int = 10, \n",
    "                 T_sup: int = 50, \n",
    "                 T_q: int = 20, \n",
    "                 h_char: int = 64, \n",
    "                 h_ment: int = 64, \n",
    "                 z_dim: int = 32, \n",
    "                 dvib_z_dim: int = 64):\n",
    "        super().__init__()\n",
    "        num_nodes, d_emb = node_embeddings.shape\n",
    "        \n",
    "        self.char_net = CharacterNet(node_embeddings, h_char, T_sup, K, z_dim=dvib_z_dim)\n",
    "        self.mental_net = MentalNet(node_embeddings, h_ment, T_q, z_dim=dvib_z_dim)\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(node_embeddings), freeze=False, padding_idx=0)\n",
    "        \n",
    "        fusion_dim = dvib_z_dim + dvib_z_dim + d_emb\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, z_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.goal_head = nn.Linear(z_dim, num_goals)\n",
    "        self.next_head = nn.Linear(z_dim, num_nodes)\n",
    "\n",
    "    def forward(self, sup, prefix, prefix_len):\n",
    "        B, K, T_sup = sup.shape\n",
    "        _, T_q = prefix.shape\n",
    "        \n",
    "        z_char, mu_char, logvar_char = self.char_net(sup)\n",
    "        z_mental, mu_mental, logvar_mental = self.mental_net(prefix, prefix_len)\n",
    "        \n",
    "        last_indices = (prefix_len - 1).clamp(min=0)\n",
    "        last_nodes = prefix[torch.arange(B), last_indices]\n",
    "        last_emb = self.embedding(last_nodes)\n",
    "        \n",
    "        fusion_input = torch.cat([z_char, z_mental, last_emb], dim=1)\n",
    "        z = self.fusion(fusion_input)\n",
    "        \n",
    "        next_logits = self.next_head(z)\n",
    "        goal_logits = self.goal_head(z)\n",
    "        \n",
    "        return next_logits, goal_logits, mu_char, logvar_char, mu_mental, logvar_mental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2287ddf",
   "metadata": {},
   "source": [
    "### Training with the New Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ed72a6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 4090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42cce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# TODO: Need to play with the hyperparameters\n",
    "# 1) hyper‐parameters \n",
    "lr         = 1e-3\n",
    "weight_decay = 1e-5\n",
    "num_epochs = 30\n",
    "\n",
    "# 2) model, losses, optimizer\n",
    "model = ToMNet(\n",
    "    node_embeddings = node_embeddings,\n",
    "    num_nodes   = len(node2idx),\n",
    "    num_goals   = len(goal2idx),\n",
    "    T_sup=75    # … etc …\n",
    ").to(device)\n",
    "\n",
    "loss_next = nn.CrossEntropyLoss()\n",
    "loss_goal = nn.CrossEntropyLoss()\n",
    "opt       = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "25d69bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30  train_loss=5.3406  val_loss=22.1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30  train_loss=4.7434  val_loss=23.8398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30  train_loss=4.3669  val_loss=25.3899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30  train_loss=4.0965  val_loss=28.0717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30  train_loss=3.8553  val_loss=29.2518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30  train_loss=3.6571  val_loss=31.4405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30  train_loss=3.4994  val_loss=32.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30  train_loss=3.3719  val_loss=34.3932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30  train_loss=3.2582  val_loss=35.6223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30  train_loss=3.1493  val_loss=37.2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30  train_loss=3.0581  val_loss=39.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30  train_loss=2.9763  val_loss=40.8826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30  train_loss=2.9053  val_loss=41.8911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30  train_loss=2.8401  val_loss=44.4048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30  train_loss=2.7886  val_loss=45.3735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30  train_loss=2.7456  val_loss=47.1154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30  train_loss=2.7048  val_loss=47.8506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30  train_loss=2.6747  val_loss=47.2186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30  train_loss=2.6544  val_loss=48.7228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30  train_loss=2.6252  val_loss=50.5351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30  train_loss=2.6049  val_loss=51.4390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30  train_loss=2.5894  val_loss=53.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30  train_loss=2.5756  val_loss=53.0672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30  train_loss=2.5688  val_loss=53.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30  train_loss=2.5441  val_loss=54.2290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30  train_loss=2.5394  val_loss=55.5172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30  train_loss=2.5254  val_loss=55.8927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30  train_loss=2.5123  val_loss=54.2455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30  train_loss=2.5098  val_loss=57.7980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30  train_loss=2.4947  val_loss=57.0495\n",
      "Training complete. Best val loss: 22.177631315054054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "beta = 1e-3  # TODO: Test out different values of annealing\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_state    = None\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\", leave=False)\n",
    "    \n",
    "    for sup, prefix, next_idx, goal_idx, pre_len in train_bar:\n",
    "        sup = sup.to(device)\n",
    "        prefix = prefix.to(device)\n",
    "        pre_len = pre_len.to(device)\n",
    "        next_idx = next_idx.to(device)\n",
    "        goal_idx = goal_idx.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        pred_next_logits, pred_goal_logits, mu_char, logvar_char, mu_mental, logvar_mental = model(sup, prefix, pre_len)\n",
    "\n",
    "        # KL divergence for both character and mental\n",
    "        kl_char = -0.5 * torch.sum(1 + logvar_char - mu_char.pow(2) - logvar_char.exp(), dim=1).mean()\n",
    "        kl_mental = -0.5 * torch.sum(1 + logvar_mental - mu_mental.pow(2) - logvar_mental.exp(), dim=1).mean()\n",
    "        loss_dvib = beta * (kl_char + kl_mental)\n",
    "\n",
    "        L_next = loss_next(pred_next_logits, next_idx)\n",
    "        L_goal = loss_goal(pred_goal_logits, goal_idx)\n",
    "        loss = L_next + L_goal + loss_dvib\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_train_loss += loss.item() * prefix.size(0)\n",
    "        train_bar.set_postfix(train_loss=loss.item())\n",
    "        \n",
    "    avg_train_loss = total_train_loss / n_train\n",
    "\n",
    "    # —————— Validation ——————\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch}/{num_epochs} [Val]  \", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for sup, prefix, next_idx, goal_idx, pre_len in val_bar:\n",
    "            sup     = sup.to(device)       # [B,K,T_sup]\n",
    "            prefix  = prefix.to(device)    # [B,T_q]\n",
    "            pre_len = pre_len.to(device)   # [B]\n",
    "            next_idx= next_idx.to(device)\n",
    "            goal_idx= goal_idx.to(device)\n",
    "    \n",
    "            # forward\n",
    "            next_logits, goal_logits, mu_char, logvar_char, mu_mental, logvar_mental = model(sup, prefix, pre_len)\n",
    "            L_next        = loss_next(next_logits, next_idx)\n",
    "            L_goal        = loss_goal(goal_logits,   goal_idx)\n",
    "            batch_loss    = (L_next + L_goal).item()\n",
    "    \n",
    "            total_val_loss += batch_loss * prefix.size(0)\n",
    "            val_bar.set_postfix(val_loss=batch_loss)\n",
    "    \n",
    "    avg_val_loss = total_val_loss / n_val\n",
    "\n",
    "    # print a summary line\n",
    "    print(f\"Epoch {epoch}/{num_epochs}  \"\n",
    "          f\"train_loss={avg_train_loss:.4f}  val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    # save best\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_state    = model.state_dict()\n",
    "\n",
    "# finally, load best\n",
    "model.load_state_dict(best_state)\n",
    "print(\"Training complete. Best val loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582afd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
