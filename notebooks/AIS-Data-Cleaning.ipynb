{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1beb79-abf3-4bd2-b140-ff299088c397",
   "metadata": {},
   "source": [
    "# AIS Data Cleaning  \n",
    "This notebook will serve as the primary dev environment for loading, cleaning, and preparing the AIS data from Janurary 1st 2025 in the waters around Denmark in the North Sea. The data is stored in one large CSV that contains all ships and is approximately 2.5 GBs for a single day. Breakdown of the cleaning process:  \n",
    "1. Remove features that are unnecessary such as ROT, Heading, IMO, etc.\n",
    "2. Impute any missing values for rows that are present in other rows for the same ship.\n",
    "3. Drop features that contain large amounts of missing data.\n",
    "4. Check whether the data appears to be single routes or not. Decide on a criteria for separating ship routes if more than one appears present.\n",
    "5. Sort data into single ship routes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ed364-1a11-4710-9710-8979c51f0a35",
   "metadata": {},
   "source": [
    "## TODO:  \n",
    "Load in the other datasets. Stitch them together. Should they be put together before or after cleaning? After is probably more feasible without all the bad rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dfc3640-ef0a-457c-b770-adcd24e5a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c877c99e-18ae-4f56-9d9e-ad0c8293b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw tracks \n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def draw_tracks(data, mmsi_list):\n",
    "    data = data[data.MMSI.isin(mmsi_list)]\n",
    "    points = [Point(x, y) for x, y in zip(data.LON, data.LAT)]\n",
    "    points_df = gpd.GeoDataFrame(data, geometry=points, crs =\"EPSG:4326\")\n",
    "\n",
    "    # treat each `ID` group of points as a line\n",
    "    lines = points_df.groupby(['MMSI'])['geometry'].apply(lambda x:  LineString(x.tolist()))\n",
    "    \n",
    "    # store as a GeodataFrame and add 'ID' as a column (currently stored as the 'index')\n",
    "    lines = gpd.GeoDataFrame(lines, geometry='geometry', crs=\"EPSG:4326\") \n",
    "    lines.reset_index(inplace=True)\n",
    "    lines.plot(column='MMSI', categorical=True, legend=True)\n",
    "\n",
    "def draw_all_tracks(data):\n",
    "    all_ships = list(data.columns.values)\n",
    "    draw_tracks(data, all_ships)\n",
    "\n",
    "def prepare_data_for_vis(data):\n",
    "    uniques = np.unique(data.MMSI, return_counts=True)\n",
    "    index_to_remove = list(np.where(uniques[1] == 1)[0])\n",
    "    to_remove = uniques[0][index_to_remove]\n",
    "    return data[data.MMSI.isin(to_remove) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e801ddac-cfe1-4a4c-a967-4b5caedb70c1",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eb218ed-8d67-46b7-9075-23feea406d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(\"./data/aisdk-2025-01-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c904c806-586e-4f3c-81a5-81ae32329df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Timestamp</th>\n",
       "      <th>Type of mobile</th>\n",
       "      <th>MMSI</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Navigational status</th>\n",
       "      <th>ROT</th>\n",
       "      <th>SOG</th>\n",
       "      <th>COG</th>\n",
       "      <th>Heading</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Type of position fixing device</th>\n",
       "      <th>Draught</th>\n",
       "      <th>Destination</th>\n",
       "      <th>ETA</th>\n",
       "      <th>Data source type</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2025 00:00:00</td>\n",
       "      <td>Class A</td>\n",
       "      <td>219005904</td>\n",
       "      <td>56.041798</td>\n",
       "      <td>12.613100</td>\n",
       "      <td>Unknown value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2025 00:00:00</td>\n",
       "      <td>Base Station</td>\n",
       "      <td>2190064</td>\n",
       "      <td>56.716560</td>\n",
       "      <td>11.519037</td>\n",
       "      <td>Unknown value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2025 00:00:00</td>\n",
       "      <td>Class A</td>\n",
       "      <td>311000766</td>\n",
       "      <td>57.775863</td>\n",
       "      <td>7.901422</td>\n",
       "      <td>Under way using engine</td>\n",
       "      <td>-8.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>259.2</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2025 00:00:00</td>\n",
       "      <td>Class A</td>\n",
       "      <td>265514800</td>\n",
       "      <td>55.613652</td>\n",
       "      <td>12.997382</td>\n",
       "      <td>Under way using engine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2025 00:00:00</td>\n",
       "      <td>AtoN</td>\n",
       "      <td>992111851</td>\n",
       "      <td>54.441580</td>\n",
       "      <td>7.678878</td>\n",
       "      <td>Unknown value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           # Timestamp Type of mobile       MMSI   Latitude  Longitude  \\\n",
       "0  01/01/2025 00:00:00        Class A  219005904  56.041798  12.613100   \n",
       "1  01/01/2025 00:00:00   Base Station    2190064  56.716560  11.519037   \n",
       "2  01/01/2025 00:00:00        Class A  311000766  57.775863   7.901422   \n",
       "3  01/01/2025 00:00:00        Class A  265514800  55.613652  12.997382   \n",
       "4  01/01/2025 00:00:00           AtoN  992111851  54.441580   7.678878   \n",
       "\n",
       "      Navigational status  ROT  SOG    COG  Heading  ... Length  \\\n",
       "0           Unknown value  NaN  0.0  279.7      NaN  ...    NaN   \n",
       "1           Unknown value  NaN  NaN    NaN      NaN  ...    NaN   \n",
       "2  Under way using engine -8.7  4.1  259.2    255.0  ...    NaN   \n",
       "3  Under way using engine  NaN  0.0   74.0      NaN  ...    NaN   \n",
       "4           Unknown value  NaN  NaN    NaN      NaN  ...    NaN   \n",
       "\n",
       "  Type of position fixing device Draught Destination  ETA  Data source type  \\\n",
       "0                      Undefined     NaN     Unknown  NaN               AIS   \n",
       "1                            GPS     NaN     Unknown  NaN               AIS   \n",
       "2                      Undefined     NaN     Unknown  NaN               AIS   \n",
       "3                      Undefined     NaN     Unknown  NaN               AIS   \n",
       "4                            GPS     NaN     Unknown  NaN               AIS   \n",
       "\n",
       "    A   B   C   D  \n",
       "0 NaN NaN NaN NaN  \n",
       "1 NaN NaN NaN NaN  \n",
       "2 NaN NaN NaN NaN  \n",
       "3 NaN NaN NaN NaN  \n",
       "4 NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "927be838-b847-4a03-9346-07ac49259aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14166456, 26)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5425af32-8aba-4f79-b75f-74de84f7b872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['# Timestamp', 'Type of mobile', 'MMSI', 'Latitude', 'Longitude',\n",
       "       'Navigational status', 'ROT', 'SOG', 'COG', 'Heading', 'IMO',\n",
       "       'Callsign', 'Name', 'Ship type', 'Cargo type', 'Width', 'Length',\n",
       "       'Type of position fixing device', 'Draught', 'Destination', 'ETA',\n",
       "       'Data source type', 'A', 'B', 'C', 'D'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42551f6d-400a-4b91-9c18-9e9193363bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# Timestamp                              0\n",
       "Type of mobile                           0\n",
       "MMSI                                     0\n",
       "Latitude                                 0\n",
       "Longitude                                0\n",
       "Navigational status                      0\n",
       "ROT                                4406351\n",
       "SOG                                1198351\n",
       "COG                                2127800\n",
       "Heading                            3090271\n",
       "IMO                                      0\n",
       "Callsign                                 0\n",
       "Name                               1071632\n",
       "Ship type                                0\n",
       "Cargo type                        11926152\n",
       "Width                              1427359\n",
       "Length                             1427769\n",
       "Type of position fixing device           0\n",
       "Draught                            3934997\n",
       "Destination                           3723\n",
       "ETA                                5617596\n",
       "Data source type                         0\n",
       "A                                  1471918\n",
       "B                                  1547193\n",
       "C                                  1517954\n",
       "D                                  1567321\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b110224f-5f71-46c8-a679-a75f5e804661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unknown', '8918966', '1167312', ..., '8800157', '7931997',\n",
       "       '9122007'], shape=(1045,), dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.IMO.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab3374ed-e989-4b7c-875c-db71bdb0aab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Timestamp</th>\n",
       "      <th>Type of mobile</th>\n",
       "      <th>MMSI</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Navigational status</th>\n",
       "      <th>ROT</th>\n",
       "      <th>SOG</th>\n",
       "      <th>COG</th>\n",
       "      <th>Heading</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Type of position fixing device</th>\n",
       "      <th>Draught</th>\n",
       "      <th>Destination</th>\n",
       "      <th>ETA</th>\n",
       "      <th>Data source type</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2025 00:00:00</td>\n",
       "      <td>Class A</td>\n",
       "      <td>311000766</td>\n",
       "      <td>57.775863</td>\n",
       "      <td>7.901422</td>\n",
       "      <td>Under way using engine</td>\n",
       "      <td>-8.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>259.2</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01/01/2025 00:00:00</td>\n",
       "      <td>Class A</td>\n",
       "      <td>304010297</td>\n",
       "      <td>54.603442</td>\n",
       "      <td>11.169567</td>\n",
       "      <td>Under way using engine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>292.6</td>\n",
       "      <td>281.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01/01/2025 00:00:00</td>\n",
       "      <td>Class A</td>\n",
       "      <td>304010297</td>\n",
       "      <td>54.603442</td>\n",
       "      <td>11.169567</td>\n",
       "      <td>Under way using engine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>292.6</td>\n",
       "      <td>281.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>01/01/2025 00:00:00</td>\n",
       "      <td>Class A</td>\n",
       "      <td>304010297</td>\n",
       "      <td>54.603442</td>\n",
       "      <td>11.169567</td>\n",
       "      <td>Under way using engine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>292.6</td>\n",
       "      <td>281.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>01/01/2025 00:00:00</td>\n",
       "      <td>Class A</td>\n",
       "      <td>314583000</td>\n",
       "      <td>57.874588</td>\n",
       "      <td>10.198435</td>\n",
       "      <td>Under way using engine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>278.1</td>\n",
       "      <td>276.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            # Timestamp Type of mobile       MMSI   Latitude  Longitude  \\\n",
       "2   01/01/2025 00:00:00        Class A  311000766  57.775863   7.901422   \n",
       "12  01/01/2025 00:00:00        Class A  304010297  54.603442  11.169567   \n",
       "13  01/01/2025 00:00:00        Class A  304010297  54.603442  11.169567   \n",
       "14  01/01/2025 00:00:00        Class A  304010297  54.603442  11.169567   \n",
       "15  01/01/2025 00:00:00        Class A  314583000  57.874588  10.198435   \n",
       "\n",
       "       Navigational status  ROT  SOG    COG  Heading  ... Length  \\\n",
       "2   Under way using engine -8.7  4.1  259.2    255.0  ...    NaN   \n",
       "12  Under way using engine  0.0  4.3  292.6    281.0  ...    NaN   \n",
       "13  Under way using engine  0.0  4.3  292.6    281.0  ...    NaN   \n",
       "14  Under way using engine  0.0  4.3  292.6    281.0  ...    NaN   \n",
       "15  Under way using engine  NaN  2.5  278.1    276.0  ...    NaN   \n",
       "\n",
       "   Type of position fixing device Draught Destination  ETA  Data source type  \\\n",
       "2                       Undefined     NaN     Unknown  NaN               AIS   \n",
       "12                      Undefined     NaN     Unknown  NaN               AIS   \n",
       "13                      Undefined     NaN     Unknown  NaN               AIS   \n",
       "14                      Undefined     NaN     Unknown  NaN               AIS   \n",
       "15                      Undefined     NaN     Unknown  NaN               AIS   \n",
       "\n",
       "     A   B   C   D  \n",
       "2  NaN NaN NaN NaN  \n",
       "12 NaN NaN NaN NaN  \n",
       "13 NaN NaN NaN NaN  \n",
       "14 NaN NaN NaN NaN  \n",
       "15 NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64cf277-92ed-47bc-bf07-66ede6555c13",
   "metadata": {},
   "source": [
    "### Step 1: Remove duplicate MMSIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fa458c2-03d5-4ccc-b6b7-ba6450692c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ais = full_data.dropna(subset=['MMSI','IMO']) # Drop rows with missing IMO and MMSI because no way to identify ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff33074d-7927-4c33-b161-ac5bea048a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14166456, 26)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "928cdbe8-8374-45de-974e-0b9e09a5c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmsi_col = \"MMSI\"\n",
    "imo_col  = \"IMO\"\n",
    "\n",
    "# treat '' or 'UNKNOWN' (case-insensitive) as NA\n",
    "ais[imo_col] = ais[imo_col].replace(\n",
    "    {\"\": None, \"UNKNOWN\": None, \"Unknown\": None, \"unknown\": None}\n",
    ")\n",
    "\n",
    "# map each MMSI to the set of *known* IMOs it appears with\n",
    "mmsi_to_imo = (\n",
    "    ais.dropna(subset=[imo_col])\n",
    "       .groupby(mmsi_col)[imo_col]\n",
    "       .agg(lambda s: s.unique().tolist())\n",
    ")\n",
    "\n",
    "def resolve_imo(imolist):\n",
    "    if len(imolist) == 1:\n",
    "        return imolist[0]        # unique ⇒ OK\n",
    "    else:\n",
    "        print(\"Problem MMSI\")\n",
    "        return None              # 0 or >1 ⇒ unresolved\n",
    "\n",
    "mmsi_to_single_imo = mmsi_to_imo.apply(resolve_imo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40af5bbe-451e-4487-b148-939a28972470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6180176)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais.IMO.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b686594f-83cf-420f-ae46-25799778406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Series we can map with\n",
    "impute_map = mmsi_to_single_imo.dropna()  # keep only MMSI with a unique IMO\n",
    "\n",
    "# fill NA IMO values where possible\n",
    "mask_missing = ais[imo_col].isna()\n",
    "ais.loc[mask_missing, imo_col] = (\n",
    "    ais.loc[mask_missing, mmsi_col]\n",
    "       .map(impute_map)          # map returns NaN if MMSI not in `impute_map`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "160b0a2b-5f9b-4318-a9a8-f4f64c97e442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6147440)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais.IMO.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8cb48b0-4882-4797-a0a4-2082c3de1255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean ais without ships that did not report an IMO\n",
    "ais = ais[ais[imo_col].notna()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fb0ffa0-3f11-46e8-ac6d-49c8f781abd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8019016, 26)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e8613-7cce-43bc-b9a8-360eed8d9302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00fd179-3f0f-4244-8d9d-428c3dc1a47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e892d929-31d0-40b6-ae57-b8c0da2a1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to individual CSVs\n",
    "for imo, df_vessel in ais.groupby('IMO'):\n",
    "    if df_vessel.shape[0] > 100000:\n",
    "        print(\"Size of trajectory: {}\".format(df_vessel.shape[0]))\n",
    "    df_vessel.to_csv(f\"./data/trajectories/IMO_{imo}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a9e0e1-2a54-4af2-893f-23ee09388d4b",
   "metadata": {},
   "source": [
    "### Step 2: Remove outliers in each trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d583e214-5545-43ca-934b-6118635004fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1867e7b1-8690-4a0d-b572-7a43d6d54869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Transformer\n",
    "\n",
    "# Geodetic WGS84  →  metric UTM 32N\n",
    "to_utm = Transformer.from_crs(\"epsg:4326\", \"epsg:25832\", always_xy=True).transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d4128fc-98e4-4156-9147-eff4ef83e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAT_MIN, LAT_MAX = -85.05113, 85.05113     # Web-Mercator safe limits\n",
    "LON_MIN, LON_MAX = -180.0, 180.0\n",
    "\n",
    "def clean_latlon(df, lat_col='Latitude', lon_col='Longitude'):\n",
    "    mask_lat = df[lat_col].between(LAT_MIN, LAT_MAX)\n",
    "    mask_lon = df[lon_col].between(LON_MIN, LON_MAX)\n",
    "    cleaned   = df[mask_lat & mask_lon].copy()\n",
    "    dropped_n = len(df) - len(cleaned)\n",
    "    if dropped_n:\n",
    "        print(f\"Dropped {dropped_n} rows with impossible lat/lon.\")\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "567cfbfb-0c9b-4f7b-b613-0bc57a38aa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:   0%|▏                                                                | 3/1044 [00:00<02:28,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:   1%|▌                                                                | 9/1044 [00:02<05:19,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:   3%|█▉                                                              | 31/1044 [00:04<01:33, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:   4%|██▍                                                             | 40/1044 [00:06<02:43,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:   5%|███▏                                                            | 52/1044 [00:08<02:32,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:   6%|███▋                                                            | 61/1044 [00:09<01:51,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:   6%|████                                                            | 67/1044 [00:12<04:37,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:   7%|████▎                                                           | 71/1044 [00:12<03:13,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 1355 rows with impossible lat/lon.\n",
      "Trajectory too small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:   9%|█████▋                                                          | 92/1044 [00:21<04:05,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 10152 rows with impossible lat/lon.\n",
      "Trajectory too small\n",
      "Dropped 4 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:   9%|█████▉                                                          | 96/1044 [00:21<02:44,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 66 rows with impossible lat/lon.\n",
      "Trajectory too small\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  10%|██████▏                                                        | 103/1044 [00:23<03:23,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  10%|██████▍                                                        | 106/1044 [00:24<02:45,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory too small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  11%|███████                                                        | 117/1044 [00:25<02:30,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  12%|███████▎                                                       | 121/1044 [00:26<01:39,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  13%|████████                                                       | 133/1044 [00:27<01:18, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  13%|████████▏                                                      | 135/1044 [00:27<01:26, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  15%|█████████▎                                                     | 155/1044 [00:30<01:33,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  16%|█████████▉                                                     | 164/1044 [00:31<02:11,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  17%|██████████▋                                                    | 178/1044 [00:36<03:32,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  18%|███████████                                                    | 184/1044 [00:37<01:52,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  18%|███████████▌                                                   | 191/1044 [00:40<04:42,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 35 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  19%|███████████▊                                                   | 195/1044 [00:42<06:36,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  19%|████████████                                                   | 200/1044 [00:43<04:28,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  22%|█████████████▋                                                 | 226/1044 [00:45<00:58, 14.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  23%|██████████████▊                                                | 245/1044 [00:49<02:42,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  24%|███████████████▏                                               | 252/1044 [00:51<03:02,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  25%|███████████████▊                                               | 263/1044 [00:52<01:36,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  26%|████████████████▌                                              | 274/1044 [00:53<00:58, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  29%|██████████████████▎                                            | 304/1044 [01:00<04:49,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  31%|███████████████████▋                                           | 326/1044 [01:06<05:52,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  32%|███████████████████▉                                           | 331/1044 [01:07<03:24,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  32%|████████████████████                                           | 333/1044 [01:08<03:33,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n",
      "Dropped 6 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  32%|████████████████████▍                                          | 339/1044 [01:12<05:38,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  33%|████████████████████▌                                          | 340/1044 [01:13<06:54,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  34%|█████████████████████▏                                         | 351/1044 [01:14<01:46,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  34%|█████████████████████▌                                         | 357/1044 [01:14<01:13,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  35%|█████████████████████▉                                         | 364/1044 [01:18<03:38,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  36%|██████████████████████▌                                        | 373/1044 [01:18<01:34,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  36%|██████████████████████▋                                        | 375/1044 [01:18<01:23,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  38%|████████████████████████                                       | 399/1044 [01:21<00:58, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  39%|████████████████████████▊                                      | 411/1044 [01:22<00:55, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  40%|████████████████████████▉                                      | 413/1044 [01:23<01:48,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  40%|█████████████████████████▎                                     | 420/1044 [01:24<01:07,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  42%|██████████████████████████▋                                    | 442/1044 [01:26<00:57, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  44%|███████████████████████████▉                                   | 463/1044 [01:27<00:45, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  46%|█████████████████████████████▏                                 | 484/1044 [01:29<00:33, 16.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  47%|█████████████████████████████▊                                 | 493/1044 [01:30<00:26, 21.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  48%|██████████████████████████████▏                                | 501/1044 [01:30<00:35, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  49%|███████████████████████████████                                | 514/1044 [01:32<00:36, 14.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  51%|████████████████████████████████▏                              | 533/1044 [01:33<00:29, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  52%|████████████████████████████████▌                              | 540/1044 [01:35<01:32,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  53%|█████████████████████████████████▎                             | 553/1044 [01:36<01:03,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 5 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  55%|██████████████████████████████████▌                            | 572/1044 [01:48<02:23,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  56%|███████████████████████████████████▏                           | 583/1044 [01:49<01:00,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  58%|████████████████████████████████████▎                          | 601/1044 [01:51<00:51,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  59%|████████████████████████████████████▊                          | 611/1044 [01:52<00:36, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  59%|█████████████████████████████████████▍                         | 620/1044 [01:53<00:21, 19.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  61%|██████████████████████████████████████▏                        | 632/1044 [01:53<00:15, 26.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  62%|██████████████████████████████████████▊                        | 643/1044 [01:54<00:21, 18.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  62%|███████████████████████████████████████▏                       | 649/1044 [01:54<00:19, 20.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  63%|███████████████████████████████████████▋                       | 657/1044 [01:54<00:16, 23.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  64%|████████████████████████████████████████▎                      | 667/1044 [01:55<00:12, 29.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  64%|████████████████████████████████████████▍                      | 671/1044 [01:55<00:20, 18.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  66%|█████████████████████████████████████████▌                     | 689/1044 [01:56<00:21, 16.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  67%|██████████████████████████████████████████▍                    | 703/1044 [01:59<00:59,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  68%|██████████████████████████████████████████▉                    | 711/1044 [02:00<00:31, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  69%|███████████████████████████████████████████▌                   | 722/1044 [02:04<01:07,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  70%|████████████████████████████████████████████▎                  | 735/1044 [02:06<00:41,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  71%|████████████████████████████████████████████▋                  | 741/1044 [02:08<01:21,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  72%|█████████████████████████████████████████████▌                 | 756/1044 [02:11<00:47,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  73%|█████████████████████████████████████████████▉                 | 761/1044 [02:14<01:57,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  74%|██████████████████████████████████████████████▌                | 771/1044 [02:18<01:25,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 5 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  74%|██████████████████████████████████████████████▊                | 775/1044 [02:18<00:55,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  75%|███████████████████████████████████████████████▍               | 786/1044 [02:20<00:44,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 3 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  76%|███████████████████████████████████████████████▉               | 795/1044 [02:21<00:37,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory too small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  76%|████████████████████████████████████████████████▏              | 798/1044 [02:21<00:31,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  77%|████████████████████████████████████████████████▍              | 803/1044 [02:22<00:29,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  78%|█████████████████████████████████████████████████              | 813/1044 [02:24<00:43,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  78%|█████████████████████████████████████████████████▍             | 819/1044 [02:25<00:34,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  79%|█████████████████████████████████████████████████▋             | 823/1044 [02:25<00:28,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  80%|██████████████████████████████████████████████████▌            | 838/1044 [02:26<00:12, 17.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  81%|██████████████████████████████████████████████████▊            | 841/1044 [02:26<00:11, 17.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  82%|███████████████████████████████████████████████████▌           | 854/1044 [02:29<00:27,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  82%|███████████████████████████████████████████████████▋           | 857/1044 [02:31<00:46,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  83%|████████████████████████████████████████████████████           | 863/1044 [02:33<00:45,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  87%|██████████████████████████████████████████████████████▊        | 908/1044 [02:43<00:14,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  90%|████████████████████████████████████████████████████████▋      | 940/1044 [03:01<00:19,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  91%|█████████████████████████████████████████████████████████▏     | 948/1044 [03:02<00:11,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  93%|██████████████████████████████████████████████████████████▋    | 973/1044 [03:13<00:12,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  93%|██████████████████████████████████████████████████████████▉    | 976/1044 [03:13<00:11,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n",
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  96%|███████████████████████████████████████████████████████████▍  | 1000/1044 [03:20<00:06,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  96%|███████████████████████████████████████████████████████████▌  | 1004/1044 [03:21<00:09,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories:  97%|███████████████████████████████████████████████████████████▉  | 1010/1044 [03:22<00:05,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cleaning trajectories: 100%|██████████████████████████████████████████████████████████████| 1044/1044 [03:26<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 rows with impossible lat/lon.\n",
      "Dropped 1 rows with impossible lat/lon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pyproj import Transformer\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "LAT_COL, LON_COL = \"Latitude\", \"Longitude\"\n",
    "EPS_METERS       = 300          # DBSCAN ε\n",
    "MIN_SAMPLES      = 3            # DBSCAN minPts\n",
    "MIN_VALID_PTS    = MIN_SAMPLES+1  # skip smaller tracks\n",
    "\n",
    "in_dir  = Path(\"./data/trajectories\")\n",
    "out_dir = Path(\"./data/trajectories_clean\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "proj = Transformer.from_crs(\"EPSG:4326\", \"EPSG:25832\", always_xy=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "files = sorted(glob.glob(str(in_dir / \"IMO_*.csv\")))\n",
    "\n",
    "for fp in tqdm(files, desc=\"cleaning trajectories\"):\n",
    "    df = pd.read_csv(fp)\n",
    "    #print(\"Size of file: {}\".format(df.shape[0]))\n",
    "    df = clean_latlon(df).dropna(subset=[LAT_COL, LON_COL])\n",
    "\n",
    "    # if after cleaning we have almost no points → skip / drop\n",
    "    if len(df) < MIN_VALID_PTS:\n",
    "        # choose one: either skip completely or save it unchanged\n",
    "        # 1) skip:\n",
    "        print(\"Trajectory too small\")\n",
    "        continue\n",
    "        # 2) keep a copy (unfiltered) so downstream code sees it:\n",
    "        #out_fp = out_dir / Path(fp).name\n",
    "        #df.to_csv(out_fp, index=False)\n",
    "        #continue\n",
    "\n",
    "    # project to metres\n",
    "    x, y   = proj.transform(df[LON_COL].values, df[LAT_COL].values)\n",
    "    coords = np.column_stack([x, y])\n",
    "\n",
    "    # DBSCAN on tracks with enough points\n",
    "    labels = DBSCAN(\n",
    "        eps=EPS_METERS,\n",
    "        min_samples=MIN_SAMPLES,\n",
    "        metric=\"euclidean\"\n",
    "    ).fit_predict(coords)\n",
    "\n",
    "    df[\"label\"] = labels\n",
    "    df_clean    = df[df[\"label\"] != -1].drop(columns=\"label\")\n",
    "\n",
    "    # optional: if *all* points became noise, you might drop the file\n",
    "    if df_clean.empty:\n",
    "        continue\n",
    "\n",
    "    df_clean.to_csv(out_dir / Path(fp).name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e4c46-9491-43ff-8171-9d5e3d7571fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6aea8fa0-8c81-434e-9edd-50c0aac51857",
   "metadata": {},
   "source": [
    "### Step 3: Removing stationary trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "617af2b0-6ab4-44bf-b2b6-6413c5427a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, pathlib, math\n",
    "from haversine import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a0d9bb5-0100-447b-aa0b-aee4fd35d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering stationary tracks: 100%|████████████████████████████████████████████████████████| 1038/1038 [00:43<00:00, 23.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Done.  Kept 447 moving tracks, skipped 591 stationary ones.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1. parameters – ADJUST as you wish\n",
    "# -----------------------------------------------------------\n",
    "SRC_DIR   = \"./data/trajectories_clean\"       # input          (CSV files)\n",
    "DST_DIR   = \"./data/moving_trajectories\"     # output (only “moving” ones)\n",
    "\n",
    "MIN_DURATION_MIN  = 30       # track must span ≥ 30 min\n",
    "MIN_DISPLACEMENT_KM = 5.0    # start–end distance  ≥ 5 km\n",
    "MIN_TRACK_LEN_KM   = 5.0     # sum of segment lengths ≥ 5 km\n",
    "LAT_COL, LON_COL   = \"Latitude\", \"Longitude\"\n",
    "TIME_COL           = \"# Timestamp\"           # adjust to your column name\n",
    "\n",
    "pathlib.Path(DST_DIR).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. helper to get simple movement statistics\n",
    "# -----------------------------------------------------------\n",
    "def track_stats(df):\n",
    "    \"\"\"\n",
    "    Returns duration (minutes), displacement_km, track_len_km\n",
    "    `df` must be sorted by timestamp already.\n",
    "    \"\"\"\n",
    "    # duration\n",
    "    t0, t1 = pd.to_datetime(df[TIME_COL].iloc[[0, -1]])\n",
    "    duration_min = (t1 - t0).total_seconds() / 60.0\n",
    "\n",
    "    # displacement (great-circle between first & last point)\n",
    "    start = (df[LAT_COL].iloc[0], df[LON_COL].iloc[0])\n",
    "    end   = (df[LAT_COL].iloc[-1], df[LON_COL].iloc[-1])\n",
    "    displacement_km = haversine(start, end)\n",
    "\n",
    "    # track length = sum of distance between consecutive points\n",
    "    coords = df[[LAT_COL, LON_COL]].to_numpy()\n",
    "    track_len_km = sum(haversine(tuple(coords[i-1]), tuple(coords[i]))\n",
    "                       for i in range(1, len(coords)))\n",
    "\n",
    "    return duration_min, displacement_km, track_len_km\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. sweep through files\n",
    "# -----------------------------------------------------------\n",
    "src_files = sorted(glob.glob(os.path.join(SRC_DIR, \"IMO_*.csv\")))\n",
    "print(len(src_files))\n",
    "kept, skipped = 0, 0\n",
    "\n",
    "for fp in tqdm(src_files, desc=\"Filtering stationary tracks\"):\n",
    "    df = pd.read_csv(fp)\n",
    "\n",
    "    # sort by time for safety\n",
    "    df = df.sort_values(TIME_COL).reset_index(drop=True)\n",
    "\n",
    "    # --------- compute stats ----------\n",
    "    dur_min, disp_km, track_km = track_stats(df)\n",
    "\n",
    "    # --------- keep / discard ----------\n",
    "    if (dur_min >= MIN_DURATION_MIN and\n",
    "        disp_km  >= MIN_DISPLACEMENT_KM and\n",
    "        track_km >= MIN_TRACK_LEN_KM):\n",
    "\n",
    "        out_fp = os.path.join(DST_DIR, os.path.basename(fp))\n",
    "        df.to_csv(out_fp, index=False)\n",
    "        kept += 1\n",
    "    else:\n",
    "        skipped += 1\n",
    "\n",
    "print(f\"✔ Done.  Kept {kept} moving tracks, skipped {skipped} stationary ones.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b29a9ef2-1e9d-4e38-acb4-8bf947721a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_track(df,\n",
    "               *,\n",
    "               zoom=11,            # basemap zoom   (6-18, ↑ = closer)\n",
    "               margin_m=2_000,     # extra metres around the track\n",
    "               figsize=(8, 8),\n",
    "               pts_kw=None,        # styling dict for points/line\n",
    "               basemap=ctx.providers.OpenStreetMap.Mapnik,\n",
    "               title=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Must contain 'Latitude' and 'Longitude' in WGS-84 degrees.\n",
    "    zoom : int\n",
    "        Slippy-tile zoom level for the basemap.\n",
    "    margin_m : float\n",
    "        Padding (metres) added to each side of the track’s bounding box.\n",
    "    pts_kw : dict\n",
    "        Extra kwargs passed to GeoPandas `.plot()` for the track\n",
    "        (e.g. {'color':'crimson','markersize':12,'linewidth':1}).\n",
    "    \"\"\"\n",
    "    if pts_kw is None:\n",
    "        pts_kw = {\"color\": \"crimson\", \"markersize\": 18}\n",
    "\n",
    "    # ---- 1. convert to GeoDataFrame in Web-Mercator (EPSG:3857) ----------\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        geometry=[Point(lon, lat) for lon, lat in zip(df.Longitude, df.Latitude)],\n",
    "        crs=\"EPSG:4326\"\n",
    "    ).to_crs(epsg=3857)\n",
    "\n",
    "    # ---- 2. figure & basemap --------------------------------------------\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "    ax.set_xlim(xmin - margin_m, xmax + margin_m)\n",
    "    ax.set_ylim(ymin - margin_m, ymax + margin_m)\n",
    "\n",
    "    ctx.add_basemap(ax, source=basemap, zoom=zoom, crs=\"EPSG:3857\", zorder=1)\n",
    "\n",
    "    # ---- 3. plot the track ----------------------------------------------\n",
    "    gdf.plot(ax=ax, zorder=2, **pts_kw)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2982471-0c6e-4aee-a35d-9623e46390e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder that contains your cleaned tracks\n",
    "clean_dir = \"./data/moving_trajectories\"\n",
    "csv_files = sorted(glob.glob(f\"{clean_dir}/IMO_*.csv\"))\n",
    "\n",
    "# pick (say) three files to preview\n",
    "for fp in random.sample(csv_files, k=3):\n",
    "    df  = pd.read_csv(fp)\n",
    "    imo = pathlib.Path(fp).stem      # 'IMO_1234567'\n",
    "    plot_track(df, title=imo, zoom=10, margin_m=3_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "994695d9-7380-4977-b00c-b2ec8c794a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Timestamp</th>\n",
       "      <th>Type of mobile</th>\n",
       "      <th>MMSI</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Navigational status</th>\n",
       "      <th>ROT</th>\n",
       "      <th>SOG</th>\n",
       "      <th>COG</th>\n",
       "      <th>Heading</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Type of position fixing device</th>\n",
       "      <th>Draught</th>\n",
       "      <th>Destination</th>\n",
       "      <th>ETA</th>\n",
       "      <th>Data source type</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2025 00:01:50</td>\n",
       "      <td>Class A</td>\n",
       "      <td>314525000</td>\n",
       "      <td>56.813753</td>\n",
       "      <td>10.631133</td>\n",
       "      <td>At anchor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2025 00:01:50</td>\n",
       "      <td>Class A</td>\n",
       "      <td>314525000</td>\n",
       "      <td>56.813753</td>\n",
       "      <td>10.631133</td>\n",
       "      <td>At anchor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2025 00:03:14</td>\n",
       "      <td>Class A</td>\n",
       "      <td>314525000</td>\n",
       "      <td>56.813753</td>\n",
       "      <td>10.631133</td>\n",
       "      <td>At anchor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>GPS</td>\n",
       "      <td>7.2</td>\n",
       "      <td>ILHFA</td>\n",
       "      <td>16/01/2025 14:00:00</td>\n",
       "      <td>AIS</td>\n",
       "      <td>93.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2025 00:04:49</td>\n",
       "      <td>Class A</td>\n",
       "      <td>314525000</td>\n",
       "      <td>56.813737</td>\n",
       "      <td>10.631172</td>\n",
       "      <td>At anchor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>GPS</td>\n",
       "      <td>7.2</td>\n",
       "      <td>ILHFA</td>\n",
       "      <td>16/01/2025 14:00:00</td>\n",
       "      <td>AIS</td>\n",
       "      <td>93.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2025 00:04:49</td>\n",
       "      <td>Class A</td>\n",
       "      <td>314525000</td>\n",
       "      <td>56.813737</td>\n",
       "      <td>10.631172</td>\n",
       "      <td>At anchor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>GPS</td>\n",
       "      <td>7.2</td>\n",
       "      <td>ILHFA</td>\n",
       "      <td>16/01/2025 14:00:00</td>\n",
       "      <td>AIS</td>\n",
       "      <td>93.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7407</th>\n",
       "      <td>01/01/2025 23:59:27</td>\n",
       "      <td>Class A</td>\n",
       "      <td>314525000</td>\n",
       "      <td>57.805335</td>\n",
       "      <td>10.935092</td>\n",
       "      <td>Under way using engine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>298.6</td>\n",
       "      <td>295.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>GPS</td>\n",
       "      <td>7.2</td>\n",
       "      <td>ILHFA</td>\n",
       "      <td>16/01/2025 14:00:00</td>\n",
       "      <td>AIS</td>\n",
       "      <td>93.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7408</th>\n",
       "      <td>01/01/2025 23:59:31</td>\n",
       "      <td>Class A</td>\n",
       "      <td>314525000</td>\n",
       "      <td>57.805402</td>\n",
       "      <td>10.934857</td>\n",
       "      <td>Under way using engine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>303.1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>GPS</td>\n",
       "      <td>7.2</td>\n",
       "      <td>ILHFA</td>\n",
       "      <td>16/01/2025 14:00:00</td>\n",
       "      <td>AIS</td>\n",
       "      <td>93.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7409</th>\n",
       "      <td>01/01/2025 23:59:34</td>\n",
       "      <td>Class A</td>\n",
       "      <td>314525000</td>\n",
       "      <td>57.805453</td>\n",
       "      <td>10.934682</td>\n",
       "      <td>Under way using engine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>299.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>GPS</td>\n",
       "      <td>7.2</td>\n",
       "      <td>ILHFA</td>\n",
       "      <td>16/01/2025 14:00:00</td>\n",
       "      <td>AIS</td>\n",
       "      <td>93.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7410</th>\n",
       "      <td>01/01/2025 23:59:41</td>\n",
       "      <td>Class A</td>\n",
       "      <td>314525000</td>\n",
       "      <td>57.805577</td>\n",
       "      <td>10.934278</td>\n",
       "      <td>Under way using engine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>294.8</td>\n",
       "      <td>295.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>GPS</td>\n",
       "      <td>7.2</td>\n",
       "      <td>ILHFA</td>\n",
       "      <td>16/01/2025 14:00:00</td>\n",
       "      <td>AIS</td>\n",
       "      <td>93.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7411</th>\n",
       "      <td>01/01/2025 23:59:50</td>\n",
       "      <td>Class A</td>\n",
       "      <td>314525000</td>\n",
       "      <td>57.805742</td>\n",
       "      <td>10.933758</td>\n",
       "      <td>Under way using engine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>305.2</td>\n",
       "      <td>295.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>GPS</td>\n",
       "      <td>7.2</td>\n",
       "      <td>ILHFA</td>\n",
       "      <td>16/01/2025 14:00:00</td>\n",
       "      <td>AIS</td>\n",
       "      <td>93.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7412 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              # Timestamp Type of mobile       MMSI   Latitude  Longitude  \\\n",
       "0     01/01/2025 00:01:50        Class A  314525000  56.813753  10.631133   \n",
       "1     01/01/2025 00:01:50        Class A  314525000  56.813753  10.631133   \n",
       "2     01/01/2025 00:03:14        Class A  314525000  56.813753  10.631133   \n",
       "3     01/01/2025 00:04:49        Class A  314525000  56.813737  10.631172   \n",
       "4     01/01/2025 00:04:49        Class A  314525000  56.813737  10.631172   \n",
       "...                   ...            ...        ...        ...        ...   \n",
       "7407  01/01/2025 23:59:27        Class A  314525000  57.805335  10.935092   \n",
       "7408  01/01/2025 23:59:31        Class A  314525000  57.805402  10.934857   \n",
       "7409  01/01/2025 23:59:34        Class A  314525000  57.805453  10.934682   \n",
       "7410  01/01/2025 23:59:41        Class A  314525000  57.805577  10.934278   \n",
       "7411  01/01/2025 23:59:50        Class A  314525000  57.805742  10.933758   \n",
       "\n",
       "         Navigational status  ROT  SOG    COG  Heading  ...  Length  \\\n",
       "0                  At anchor  0.0  0.0    0.0    199.0  ...     NaN   \n",
       "1                  At anchor  0.0  0.0    0.0    199.0  ...     NaN   \n",
       "2                  At anchor  0.0  0.0    0.0    199.0  ...   108.0   \n",
       "3                  At anchor  0.0  0.1    0.0    204.0  ...   108.0   \n",
       "4                  At anchor  0.0  0.1    0.0    204.0  ...   108.0   \n",
       "...                      ...  ...  ...    ...      ...  ...     ...   \n",
       "7407  Under way using engine  0.0  7.6  298.6    295.0  ...   108.0   \n",
       "7408  Under way using engine  0.0  7.6  303.1    296.0  ...   108.0   \n",
       "7409  Under way using engine  0.0  7.7  299.0    295.0  ...   108.0   \n",
       "7410  Under way using engine  0.0  7.6  294.8    295.0  ...   108.0   \n",
       "7411  Under way using engine  0.0  7.7  305.2    295.0  ...   108.0   \n",
       "\n",
       "     Type of position fixing device Draught Destination                  ETA  \\\n",
       "0                         Undefined     NaN     Unknown                  NaN   \n",
       "1                         Undefined     NaN     Unknown                  NaN   \n",
       "2                               GPS     7.2       ILHFA  16/01/2025 14:00:00   \n",
       "3                               GPS     7.2       ILHFA  16/01/2025 14:00:00   \n",
       "4                               GPS     7.2       ILHFA  16/01/2025 14:00:00   \n",
       "...                             ...     ...         ...                  ...   \n",
       "7407                            GPS     7.2       ILHFA  16/01/2025 14:00:00   \n",
       "7408                            GPS     7.2       ILHFA  16/01/2025 14:00:00   \n",
       "7409                            GPS     7.2       ILHFA  16/01/2025 14:00:00   \n",
       "7410                            GPS     7.2       ILHFA  16/01/2025 14:00:00   \n",
       "7411                            GPS     7.2       ILHFA  16/01/2025 14:00:00   \n",
       "\n",
       "      Data source type     A     B     C    D  \n",
       "0                  AIS   NaN   NaN   NaN  NaN  \n",
       "1                  AIS   NaN   NaN   NaN  NaN  \n",
       "2                  AIS  93.0  15.0  13.0  5.0  \n",
       "3                  AIS  93.0  15.0  13.0  5.0  \n",
       "4                  AIS  93.0  15.0  13.0  5.0  \n",
       "...                ...   ...   ...   ...  ...  \n",
       "7407               AIS  93.0  15.0  13.0  5.0  \n",
       "7408               AIS  93.0  15.0  13.0  5.0  \n",
       "7409               AIS  93.0  15.0  13.0  5.0  \n",
       "7410               AIS  93.0  15.0  13.0  5.0  \n",
       "7411               AIS  93.0  15.0  13.0  5.0  \n",
       "\n",
       "[7412 rows x 26 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c194e00-ddbb-4bc0-b824-693935efd37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       9218193\n",
       "1       9218193\n",
       "2       9218193\n",
       "3       9218193\n",
       "4       9218193\n",
       "         ...   \n",
       "7407    9218193\n",
       "7408    9218193\n",
       "7409    9218193\n",
       "7410    9218193\n",
       "7411    9218193\n",
       "Name: IMO, Length: 7412, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.IMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2042e3cf-3056-4b9b-9dd0-bd426bdcdcea",
   "metadata": {},
   "source": [
    "## Step 4: Create distinct trips  \n",
    "I have been able to separate all trips by day and into their own respective files. Now, I need to be able to stitch these files together for a single IMO and create the distinct tracks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4dfb5c4-e7ae-495c-b676-7e5718653d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a46d956-b232-4fa9-94aa-12adf5a4ca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1149 unique IMOs.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = \"../notebooks/data/trips\"\n",
    "imo_set = set()\n",
    "\n",
    "# Regex to extract IMO number from filenames like \"IMO_9431234.csv\"\n",
    "pattern = re.compile(r\"IMO_(\\d+)\\.csv\")\n",
    "\n",
    "# Traverse each day folder\n",
    "for day_folder in os.listdir(BASE_DIR):\n",
    "    day_path = os.path.join(BASE_DIR, day_folder)\n",
    "    if not os.path.isdir(day_path):\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(day_path):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            imo = match.group(1)\n",
    "            imo_set.add(imo)\n",
    "\n",
    "# Print or use the unique IMO set\n",
    "print(f\"Found {len(imo_set)} unique IMOs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1eaf137a-0def-4b94-8e2a-7dff4fae14e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VoyageID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01 00:00:10</td>\n",
       "      <td>2025-01-01 23:59:55</td>\n",
       "      <td>12485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-01 00:00:24</td>\n",
       "      <td>2025-02-01 02:07:38</td>\n",
       "      <td>1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-01 16:39:08</td>\n",
       "      <td>2025-04-01 23:59:40</td>\n",
       "      <td>1496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         min                 max  count\n",
       "VoyageID                                               \n",
       "1        2025-01-01 00:00:10 2025-01-01 23:59:55  12485\n",
       "2        2025-02-01 00:00:24 2025-02-01 02:07:38   1512\n",
       "3        2025-04-01 16:39:08 2025-04-01 23:59:40   1496"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------- Configuration --------\n",
    "BASE_DIR = \"./data/trips\"\n",
    "IMO = \"6617855\"  # example IMO, update this\n",
    "FILENAME = f\"IMO_{IMO}.csv\"\n",
    "\n",
    "# -------- Load all matching CSVs across days --------\n",
    "all_dfs = []\n",
    "\n",
    "for day_folder in sorted(os.listdir(BASE_DIR)):\n",
    "    day_path = os.path.join(BASE_DIR, day_folder)\n",
    "    if not os.path.isdir(day_path):\n",
    "        continue\n",
    "\n",
    "    imo_path = os.path.join(day_path, FILENAME)\n",
    "    if os.path.exists(imo_path):\n",
    "        df = pd.read_csv(imo_path)\n",
    "        df[\"source_day\"] = day_folder  # optional: keep track of origin\n",
    "        all_dfs.append(df)\n",
    "\n",
    "if not all_dfs:\n",
    "    raise FileNotFoundError(f\"No data found for IMO {IMO}\")\n",
    "\n",
    "full_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# -------- Preprocessing --------\n",
    "# Ensure timestamps are in datetime format\n",
    "full_df[\"# Timestamp\"] = pd.to_datetime(full_df[\"# Timestamp\"])  # Adjust column name if needed\n",
    "full_df = full_df.sort_values(\"# Timestamp\").reset_index(drop=True)\n",
    "\n",
    "# -------- Voyage Segmentation --------\n",
    "# Define threshold for gap between pings (e.g., 4 hours) to indicate new voyage\n",
    "GAP_HOURS = 4\n",
    "GAP = timedelta(hours=GAP_HOURS)\n",
    "\n",
    "# Compute time differences between consecutive points\n",
    "full_df[\"TimeDiff\"] = full_df[\"# Timestamp\"].diff()\n",
    "full_df[\"NewVoyage\"] = (full_df[\"TimeDiff\"] > GAP) | (full_df[\"TimeDiff\"].isna())\n",
    "\n",
    "# Assign voyage ID\n",
    "full_df[\"VoyageID\"] = full_df[\"NewVoyage\"].cumsum().astype(int)\n",
    "\n",
    "# -------- Result --------\n",
    "# Show summary of voyages\n",
    "voyage_summary = full_df.groupby(\"VoyageID\")[\"# Timestamp\"].agg([\"min\", \"max\", \"count\"])\n",
    "display(voyage_summary)\n",
    "\n",
    "# -------- Config --------\n",
    "PROCESSED_DIR = \"../notebooks/data/processed_trips\"\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Make sure 'IMO' is a scalar (from the grouped data or filename)\n",
    "imo_number = full_df[\"IMO\"].iloc[0]  # assuming consistent IMO per track\n",
    "\n",
    "# -------- Save Each Voyage --------\n",
    "for i, voyage_id in enumerate(sorted(full_df[\"VoyageID\"].unique()), start=1):\n",
    "    voyage_df = full_df[full_df[\"VoyageID\"] == voyage_id]\n",
    "    out_filename = f\"IMO_{imo_number}_trip_{i}.csv\"\n",
    "    out_path = os.path.join(PROCESSED_DIR, out_filename)\n",
    "    voyage_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved {i} voyages for IMO {imo_number} to {PROCESSED_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab44e2ab-bdff-4dbe-91e3-7ce08ba1ef49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f53e0-bc5b-469c-a705-82f265939726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tom)",
   "language": "python",
   "name": "tom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
