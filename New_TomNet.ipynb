{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661b332f-6eae-4acc-9a92-3d6207778a21",
   "metadata": {},
   "source": [
    "# ToMnet  \n",
    "\n",
    "In this notebook we are going to develop the codebase for ToMNet to work on our simulation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fb351db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%ext` not found.\n"
     ]
    }
   ],
   "source": [
    "%ext autoreload 2\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3637e333-6b37-42de-a0ae-75f9db6fc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "import wandb\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de85f71e-7d64-4264-9500-ae64e257ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import osmnx as ox\n",
    "\n",
    "# Adjust this path as needed to point to your project root\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "757e0029",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dd1a603-1b06-4747-8c23-62d35a466e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "mp.set_start_method('fork', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1e8c6d4-ffd3-44d8-8a23-6d37a93f6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_world_src.environment.campus_env import CampusEnvironment\n",
    "from real_world_src.agents.agent_factory import AgentFactory\n",
    "from real_world_src.agents.agent_species import ShortestPathAgent\n",
    "from real_world_src.simulation.simulator import Simulator\n",
    "#from real_world_src.simulation.experiment_1 import Simulator\n",
    "\n",
    "from real_world_src.utils.run_manager import RunManager\n",
    "from real_world_src.utils.config import VISUAL_CONFIG\n",
    "from real_world_src.utils.config import get_agent_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495bee3-fe4c-449e-b383-71dffececdab",
   "metadata": {},
   "source": [
    "## Step 1: Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29bfc584-7cfe-408f-be2b-f7d5b68b44b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from ucsd_campus.graphml...\n",
      "Environment loaded with 3151 nodes and 8746 edges\n"
     ]
    }
   ],
   "source": [
    "# Create a run manager\n",
    "# run_manager = RunManager('visuals')\n",
    "# run_dir = run_manager.start_new_run()\n",
    "\n",
    "# Initialize campus environment\n",
    "campus = CampusEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59d36b7b-9778-4e7c-b6e6-9946da46e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to establish the set of common goals (just choose the landmark nodes)\n",
    "goals = [469084068, 49150691, 768264666, 1926666015, 1926673385, 49309735,\n",
    "         273627682, 445989107, 445992528, 446128310, 1772230346, 1926673336, \n",
    "         2872424923, 3139419286, 4037576308]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c8ddb05-8af6-4915-b424-59f6d79ea0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2181847/4214467372.py:5: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  agents = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# if you used dill, just replace pickle with dill\n",
    "\n",
    "with open('./../data/1k/agents.pkl', 'rb') as f:\n",
    "    agents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2f34921-df42-40b0-9b12-4b2df0e4bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./../data/1k/path_data.json\", 'r') as file:\n",
    "    path_data = json.load(file)\n",
    "\n",
    "with open(\"./../data/1k/goal_data.json\", 'r') as file:\n",
    "    goal_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c93c2e69-3ea5-402a-b014-f49b1a88dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_keys_to_int(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {int(k) if isinstance(k, str) and k.isdigit() else k: convert_keys_to_int(v) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [convert_keys_to_int(item) for item in data]\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d09bd6a6-181a-485f-bfd4-80db4d858f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_data = convert_keys_to_int(goal_data)\n",
    "path_data = convert_keys_to_int(path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c4eb8-925b-440f-bc9a-4c9ab04c120d",
   "metadata": {},
   "source": [
    "## Step 2: Defining ToMnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bf98054-1d2f-4952-8679-e8265adfed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2573a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational CharacterNet: outputs z_char, mu_char, logvar_char.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 node_embeddings: np.ndarray, \n",
    "                 h_lstm: int = 64, \n",
    "                 T_sup: int = 50, \n",
    "                 K: int = 10, \n",
    "                 z_dim: int = 64,\n",
    "                 dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        num_nodes, d_emb = node_embeddings.shape\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(node_embeddings), freeze=True, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(d_emb, h_lstm, batch_first=True)\n",
    "        self.layer_norm = nn.LayerNorm(h_lstm)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.K = K\n",
    "        self.T_sup = T_sup\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.fc_mu = nn.Linear(h_lstm, z_dim)\n",
    "        self.fc_logvar = nn.Linear(h_lstm, z_dim)\n",
    "\n",
    "    def forward(self, support_trajs):\n",
    "        \n",
    "        B, K, T = support_trajs.size()\n",
    "        assert K == self.K and T == self.T_sup\n",
    "        \n",
    "        flat = support_trajs.view(B * K, T)\n",
    "        emb = self.embedding(flat)\n",
    "        _, (h_n, _) = self.lstm(emb)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        h_n = self.layer_norm(self.dropout(h_n))\n",
    "        \n",
    "        chars = h_n.view(B, K, -1).mean(dim=1)  # [B, h_lstm]\n",
    "        mu = self.fc_mu(chars)\n",
    "        logvar = self.fc_logvar(chars)\n",
    "        \n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        \n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eea9a5f4-8456-4489-8446-42cf6fe18eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentalNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational MentalNet: outputs z_mental, mu_mental, logvar_mental.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 node_embeddings: np.ndarray, \n",
    "                 h_lstm: int = 64, \n",
    "                 T_q: int = 20, \n",
    "                 dropout: float = 0.5, \n",
    "                 use_attention: bool = True, \n",
    "                 z_dim: int = 64):\n",
    "        super().__init__()\n",
    "        num_nodes, d_emb = node_embeddings.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(node_embeddings), freeze=False, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(d_emb, h_lstm, batch_first=True, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(2 * h_lstm)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.T_q = T_q\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.use_attention = use_attention\n",
    "        \n",
    "        if use_attention:\n",
    "            self.attn = nn.Linear(h_lstm * 2, 1)\n",
    "        \n",
    "        self.fc_mu = nn.Linear(2 * h_lstm, z_dim)\n",
    "        self.fc_logvar = nn.Linear(2 * h_lstm, z_dim)\n",
    "\n",
    "    def forward(self, prefix: torch.LongTensor, prefix_len: torch.LongTensor):\n",
    "        B, T = prefix.size()\n",
    "        assert T == self.T_q, f\"Expected T_q={self.T_q}, got {T}\"\n",
    "        \n",
    "        emb = self.embedding(prefix)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths=prefix_len.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, (h_n, _) = self.lstm(packed)\n",
    "        \n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True, total_length=self.T_q)\n",
    "        out = self.layer_norm(self.dropout(out))  # [B, T_q, 2*h_lstm]\n",
    "        \n",
    "        if self.use_attention:\n",
    "            mask = torch.arange(self.T_q, device=prefix.device)[None, :] < prefix_len[:, None]\n",
    "            attn_scores = self.attn(out).squeeze(-1)\n",
    "            attn_scores[~mask] = float('-inf')\n",
    "            attn_weights = torch.softmax(attn_scores, dim=1).unsqueeze(-1)\n",
    "            feat = (out * attn_weights).sum(dim=1)\n",
    "        else:\n",
    "            idx = (prefix_len - 1).clamp(min=0)\n",
    "            feat = out[torch.arange(B), idx]\n",
    "        \n",
    "        mu = self.fc_mu(feat)\n",
    "        logvar = self.fc_logvar(feat)\n",
    "        \n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        \n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "754ef7ef-ca59-4a29-8cc7-1211435686f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToMNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ToMNet with DVIB: CharacterNet + MentalNet + fusion MLP + prediction heads.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 node_embeddings: np.ndarray, \n",
    "                 num_nodes: int, \n",
    "                 num_goals: int, \n",
    "                 K: int = 10, \n",
    "                 T_sup: int = 50, \n",
    "                 T_q: int = 20, \n",
    "                 h_char: int = 64, \n",
    "                 h_ment: int = 64, \n",
    "                 z_dim: int = 32, \n",
    "                 dvib_z_dim: int = 64):\n",
    "        super().__init__()\n",
    "        num_nodes, d_emb = node_embeddings.shape\n",
    "        \n",
    "        self.char_net = CharacterNet(node_embeddings, h_char, T_sup, K, z_dim=dvib_z_dim)\n",
    "        self.mental_net = MentalNet(node_embeddings, h_ment, T_q, z_dim=dvib_z_dim)\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(node_embeddings), freeze=False, padding_idx=0)\n",
    "        \n",
    "        fusion_dim = dvib_z_dim + dvib_z_dim + d_emb\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, z_dim),\n",
    "            nn.LayerNorm(z_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.goal_head = nn.Linear(z_dim, num_goals)\n",
    "        self.next_head = nn.Linear(z_dim, num_nodes)\n",
    "\n",
    "    def forward(self, sup, prefix, prefix_len):\n",
    "        B, K, T_sup = sup.shape\n",
    "        _, T_q = prefix.shape\n",
    "        \n",
    "        z_char, mu_char, logvar_char = self.char_net(sup)\n",
    "        z_mental, mu_mental, logvar_mental = self.mental_net(prefix, prefix_len)\n",
    "        \n",
    "        last_indices = (prefix_len - 1).clamp(min=0)\n",
    "        last_nodes = prefix[torch.arange(B), last_indices]\n",
    "        last_emb = self.embedding(last_nodes)\n",
    "        \n",
    "        fusion_input = torch.cat([z_char, z_mental, last_emb], dim=1)\n",
    "        z = self.fusion(fusion_input)\n",
    "        \n",
    "        next_logits = self.next_head(z)\n",
    "        goal_logits = self.goal_head(z)\n",
    "        \n",
    "        return next_logits, goal_logits, mu_char, logvar_char, mu_mental, logvar_mental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987eb6d-ef56-4190-a969-c8057514dd57",
   "metadata": {},
   "source": [
    "## Step 3: Prepare the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f981e2d-5699-40e4-b410-bf368f80096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in node2idx: 3185\n"
     ]
    }
   ],
   "source": [
    "# build node2idx so that every node in campus.G_undirected maps to 0…V−1\n",
    "all_nodes = set()\n",
    "for episode in path_data.values():\n",
    "    for path in episode.values():\n",
    "        if isinstance(path, (list, tuple, set)):\n",
    "            all_nodes.update(path)\n",
    "        else:\n",
    "            all_nodes.add(path)\n",
    "all_nodes.update(campus.G_undirected.nodes())\n",
    "all_nodes = list(all_nodes)\n",
    "\n",
    "node2idx = {n: i for i, n in enumerate(all_nodes)}\n",
    "print(f\"Number of nodes in node2idx: {len(node2idx)}\")\n",
    "\n",
    "V = len(all_nodes)\n",
    "\n",
    "# build goal2idx likewise for your goals list\n",
    "goal2idx = {g:i for i,g in enumerate(goals)}\n",
    "G = len(goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc3cb833",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Executed once - Find the node2vec embeddings in the data directory.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnode2vec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Node2Vec\n\u001b[32m      5\u001b[39m G = campus.G_undirected\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Fitting node2vec model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tom/lib/python3.12/site-packages/node2vec/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m edges\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnode2vec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Node2Vec\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metadata\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tom/lib/python3.12/site-packages/node2vec/edges.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheck_gensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_dated_gensim_version\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KeyedVectors\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mEdgeEmbedder\u001b[39;00m(ABC):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tom/lib/python3.12/site-packages/gensim/__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m4.3.3\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m     14\u001b[39m logger = logging.getLogger(\u001b[33m'\u001b[39m\u001b[33mgensim\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger.handlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tom/lib/python3.12/site-packages/gensim/corpora/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexedcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmmcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbleicorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tom/lib/python3.12/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[32m     16\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIndexedCorpus\u001b[39;00m(interfaces.CorpusABC):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tom/lib/python3.12/site-packages/gensim/interfaces.py:19\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[33;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[32m     22\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCorpusABC\u001b[39;00m(utils.SaveLoad):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tom/lib/python3.12/site-packages/gensim/matutils.py:1034\u001b[39m\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1.\u001b[39m - \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 & set2)) / \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1033\u001b[39m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_matutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlogsumexp\u001b[39m(x):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tom/lib/python3.12/site-packages/gensim/_matutils.pyx:1\u001b[39m, in \u001b[36minit gensim._matutils\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "#Executed once - Find the node2vec embeddings in the data directory.\n",
    "\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "G = campus.G_undirected\n",
    "\n",
    "# Fitting node2vec model\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=100, num_walks=200, workers=16)\n",
    "n2v_model = node2vec.fit(window=10, min_count=1, batch_words=8)\n",
    "\n",
    "# Building a node_id -> embedding matrix\n",
    "embedding_dim = n2v_model.wv.vector_size\n",
    "node_embeddings = np.zeros((len(node2idx), embedding_dim), dtype=np.float32)\n",
    "\n",
    "for node, idx in node2idx.items():\n",
    "    key = str(node)\n",
    "    if key in n2v_model.wv:\n",
    "        node_embeddings[idx] = n2v_model.wv[key]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "np.save(\"data/node2vec_embeddings.npy\", node_embeddings)\n",
    "print(\"Node2Vec embeddings saved to data/node2vec_embeddings.npy\") \n",
    "\n",
    "\n",
    "# node_embeddings = np.load(\"./../data/data_utils/New_node2vec_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae39ba04-97e7-475d-8db7-eb71ed2f4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agent_ids = list(range(0, 70))\n",
    "test_agent_ids = list(range(70, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "977d257e-e483-4011-be19-2200cba11d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train examples: 295111\n",
      "# test  examples: 124001\n"
     ]
    }
   ],
   "source": [
    "# hyper‐params\n",
    "K     = 10    # number of support trajectories per agent\n",
    "T_sup = 75    # max length (pad/truncate) of each support trajectory\n",
    "T_q   = 20    # prefix length for query trajectories\n",
    "\n",
    "all_episodes    = list(path_data.keys())\n",
    "examples_train  = []\n",
    "examples_test   = []\n",
    "\n",
    "for agent in agents:\n",
    "    a_id = agent.id\n",
    "\n",
    "    # choose which list to append into\n",
    "    if a_id in train_agent_ids:\n",
    "        target = examples_train\n",
    "    elif a_id in test_agent_ids:\n",
    "        target = examples_test\n",
    "    else:\n",
    "        # silently skip any id outside 0–99\n",
    "        continue\n",
    "\n",
    "    for ep in all_episodes:\n",
    "        # ——— 1) build the K‐shot “support set” for this (agent, ep) ———\n",
    "        other_eps   = [e for e in all_episodes if e != ep]\n",
    "        support_eps = random.sample(other_eps, K)\n",
    "\n",
    "        sup_tensor = torch.zeros(K, T_sup, dtype=torch.long)\n",
    "        for k, se in enumerate(support_eps):\n",
    "            raw_sup  = path_data[se][a_id]           # e.g. [n0, n1, n2, …]\n",
    "            idxs_sup = [node2idx[n] for n in raw_sup]\n",
    "            L        = min(len(idxs_sup), T_sup)\n",
    "            sup_tensor[k, :L] = torch.tensor(idxs_sup[:L], dtype=torch.long)\n",
    "\n",
    "        # ——— 2) unroll *this* episode’s path into (prefix→next) queries ———\n",
    "        raw_q        = path_data[ep][a_id]\n",
    "        idxs_q       = [node2idx[n] for n in raw_q]\n",
    "        true_goal_idx = goal2idx[goal_data[ep][a_id]]\n",
    "\n",
    "        for t in range(1, len(idxs_q)):\n",
    "            prefix_idxs = idxs_q[:t]     # length t (we’ll pad later)\n",
    "            next_idx    = idxs_q[t]      # ground‐truth “next node”\n",
    "\n",
    "            target.append((\n",
    "                sup_tensor.clone(),      # [K×T_sup] LongTensor\n",
    "                prefix_idxs,             # Python list of length t\n",
    "                next_idx,                # int\n",
    "                true_goal_idx            # int\n",
    "            ))\n",
    "\n",
    "print(f\"# train examples: {len(examples_train)}\")\n",
    "print(f\"# test  examples: {len(examples_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35109e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def augment_trajectory(traj, drop_prob=0.1, swap_prob=0.05):\n",
    "    # Randomly drop nodes\n",
    "    traj = [n for n in traj if random.random() > drop_prob or len(traj) <= 2]\n",
    "    # Randomly swap adjacent nodes\n",
    "    if len(traj) > 2 and random.random() < swap_prob:\n",
    "        i = random.randint(0, len(traj)-2)\n",
    "        traj[i], traj[i+1] = traj[i+1], traj[i]\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b147c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomnet_collate(batch, T_q, pad_value=0):\n",
    "    \"\"\"\n",
    "    batch: list of tuples from __getitem__()\n",
    "      sup_tensor:  K×T_sup\n",
    "      prefix:     [t] (list of ints)\n",
    "      next_idx:   scalar int\n",
    "      goal_idx:   scalar int\n",
    "\n",
    "    Returns:\n",
    "      sup_batch:  (B, K, T_sup)\n",
    "      prefix_batch: (B, T_q)\n",
    "      next_batch:   (B,)\n",
    "      goal_batch:   (B,)\n",
    "      prefix_lens:  (B,)  # optional if you need to mask\n",
    "    \"\"\"\n",
    "    sup_list, prefix_list, next_list, goal_list = zip(*batch)\n",
    "    B = len(batch)\n",
    "\n",
    "    sup_batch = torch.stack(sup_list, dim=0)    # (B, K, T_sup)\n",
    "\n",
    "    prefix_batch = torch.full((B, T_q), pad_value, dtype=torch.long)\n",
    "    prefix_lens  = torch.zeros(B, dtype=torch.long)\n",
    "    for i, p in enumerate(prefix_list):\n",
    "        L = min(len(p), T_q)\n",
    "        if L == 0:\n",
    "            # Ensure at least one token (e.g., pad with 0)\n",
    "            prefix_batch[i, 0] = pad_value\n",
    "            prefix_lens[i] = 1\n",
    "        else:\n",
    "            prefix_batch[i, :L] = p[:L]\n",
    "            prefix_lens[i]      = L\n",
    "\n",
    "    next_batch = torch.tensor(next_list, dtype=torch.long)     # (B,)\n",
    "    goal_batch = torch.tensor(goal_list, dtype=torch.long)     # (B,)\n",
    "\n",
    "    return sup_batch, prefix_batch, next_batch, goal_batch, prefix_lens\n",
    "\n",
    "def tomnet_collate_fn(batch):\n",
    "    # use your existing tomnet_collate, but wrap it\n",
    "    return tomnet_collate(batch, T_q=T_q, pad_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "class H5ToMNetDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 path_h5_path: str,\n",
    "                 goal_h5_path: str,\n",
    "                 node2idx: dict,\n",
    "                 goal2idx: dict,\n",
    "                 K: int = 10,\n",
    "                 T_sup: int = 75,\n",
    "                 T_q: int = 20,\n",
    "                 pad_value: int = 0,\n",
    "                 augment=True):\n",
    "        \"\"\"\n",
    "        path_h5_path:    large path_data.h5\n",
    "        goal_h5_path:    large goal_data.h5\n",
    "        node2idx, goal2idx: mappings from original node/goal IDs → [0..V), [0..G)\n",
    "        K, T_sup, T_q:   as before\n",
    "        pad_value:       embedding padding index (0)\n",
    "        augment:         whether to apply augment_trajectory\n",
    "        \"\"\"\n",
    "        self.path_h5_path = path_h5_path\n",
    "        self.goal_h5_path = goal_h5_path\n",
    "        self.node2idx     = node2idx\n",
    "        self.goal2idx     = goal2idx\n",
    "        self.K            = K\n",
    "        self.T_sup        = T_sup\n",
    "        self.T_q          = T_q\n",
    "        self.pad_value    = pad_value\n",
    "        self.augment      = augment\n",
    "\n",
    "        # list of (episode:str, agent_id:str, t:int) for every valid time‑step\n",
    "        # this index is small (~#episodes × #agents × avg path length), so can live in RAM\n",
    "        self.examples = []\n",
    "        with h5py.File(self.path_h5_path, 'r') as pf:\n",
    "            for ep in pf.keys():                            # ep = '0', '1', ...\n",
    "                grp = pf[ep]\n",
    "                for agent_id in grp.keys():                  # agent_id = '0', '1', ...\n",
    "                    L = grp[agent_id].shape[0]\n",
    "                    # we'll predict t=1..(L−1)\n",
    "                    for t in range(1, L):\n",
    "                        self.examples.append((ep, agent_id, t))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # lazily open once per worker\n",
    "        if not hasattr(self, 'pf'):\n",
    "            # swmr=True if you might write concurrently; safe anyway\n",
    "            self.pf = h5py.File(self.path_h5_path, 'r', swmr=True)\n",
    "            self.gf = h5py.File(self.goal_h5_path, 'r', swmr=True)\n",
    "\n",
    "        ep, agent_id, t = self.examples[idx]\n",
    "\n",
    "        # --- load raw path and goal ---\n",
    "        raw_path = self.pf[ep][agent_id][()]    # numpy array of node‑IDs shape (L,)\n",
    "        raw_goal = int(self.gf[ep][agent_id][()])\n",
    "\n",
    "        # map to indices\n",
    "        idxs = [ self.node2idx[n] for n in raw_path ]\n",
    "        true_goal = self.goal2idx[raw_goal]\n",
    "\n",
    "        # --- build support set ---\n",
    "        all_eps = list(self.pf.keys())\n",
    "        other_eps = [e for e in all_eps if e != ep]\n",
    "        support_eps = random.sample(other_eps, self.K)\n",
    "\n",
    "        sup_tensor = torch.zeros(self.K, self.T_sup, dtype=torch.long)\n",
    "        for k, se in enumerate(support_eps):\n",
    "            seq = self.pf[se][agent_id][()]\n",
    "            idxs_sup = [ self.node2idx[n] for n in seq ]\n",
    "            Lk = min(len(idxs_sup), self.T_sup)\n",
    "            sup_tensor[k, :Lk] = torch.tensor(idxs_sup[:Lk], dtype=torch.long)\n",
    "\n",
    "        # --- build prefix & next_idx ---\n",
    "        prefix_idxs = idxs[:t]\n",
    "        next_idx    = idxs[t]\n",
    "\n",
    "        if self.augment:\n",
    "            prefix_idxs = augment_trajectory(prefix_idxs)\n",
    "            # optionally, augment sup_tensor here too…\n",
    "\n",
    "        # pad/truncate prefix to T_q\n",
    "        prefix = torch.full((self.T_q,), self.pad_value, dtype=torch.long)\n",
    "        Lp = min(len(prefix_idxs), self.T_q)\n",
    "        if Lp > 0:\n",
    "            prefix[:Lp] = torch.tensor(prefix_idxs[:Lp], dtype=torch.long)\n",
    "        prefix_len = Lp if Lp>0 else 1\n",
    "\n",
    "        return sup_tensor, prefix, next_idx, true_goal, prefix_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed0f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate stays the same as your tomnet_collate\n",
    "from torch.utils.data import DataLoader\n",
    "train_ds = H5ToMNetDataset(\n",
    "    path_h5_path = './../data/10k/path_data.h5',\n",
    "    goal_h5_path = './../data/10k/goal_data.h5',\n",
    "    node2idx     = node2idx,\n",
    "    goal2idx     = goal2idx,\n",
    "    K            = 10,\n",
    "    T_sup        = 75,\n",
    "    T_q          = 20,\n",
    "    pad_value    = 0,\n",
    "    augment      = True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size       = 256,\n",
    "    shuffle          = True,\n",
    "    num_workers      = 16,\n",
    "    pin_memory       = True,\n",
    "    prefetch_factor  = 2,\n",
    "    persistent_workers = True,\n",
    "    collate_fn       = tomnet_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43dabd-af6c-442b-a89d-db469ce7013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ToMNetDataset(Dataset):\n",
    "    def __init__(self, examples, T_q, pad_value=0):\n",
    "        \"\"\"\n",
    "        examples: list of tuples\n",
    "            (sup_tensor, prefix_idxs, next_idx, true_goal_idx)\n",
    "        T_q: int\n",
    "            length that we will pad/truncate every prefix to\n",
    "        pad_value: int\n",
    "            index to use for padding prefixes\n",
    "        \"\"\"\n",
    "        self.examples = examples\n",
    "        self.T_q       = T_q\n",
    "        self.pad_value = pad_value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sup_tensor, prefix_list, next_idx, true_goal_idx = self.examples[idx]\n",
    "        # Augment prefix_list (query) and support trajectories\n",
    "        prefix_list = augment_trajectory(prefix_list)\n",
    "        # Optionally, augment support trajectories as well\n",
    "        for k in range(sup_tensor.shape[0]):\n",
    "            traj = sup_tensor[k].tolist()\n",
    "            traj = augment_trajectory(traj)\n",
    "            sup_tensor[k] = torch.tensor(traj + [0]*(sup_tensor.shape[1]-len(traj)), dtype=torch.long)[:sup_tensor.shape[1]]\n",
    "        return sup_tensor, torch.tensor(prefix_list, dtype=torch.long), next_idx, true_goal_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9917c4c-d249-4e75-bc0a-656a4d6ab931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a53862d-f072-4c62-856a-848c7cd9dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72e615cb-263c-48fe-95f1-c18cc7248986",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ToMNetDataset(examples_train, T_q=T_q, pad_value=0)\n",
    "test_ds  = ToMNetDataset(examples_test,  T_q=T_q, pad_value=0)\n",
    "\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=6, collate_fn=tomnet_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ec302ed-c910-4ea1-8290-bafb4cad13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) (optional) split into train/val\n",
    "n_total = len(train_ds)\n",
    "n_val   = int(0.1 * n_total)\n",
    "n_train = n_total - n_val\n",
    "# train_ds, val_ds = random_split((train_ds), [n_train, n_val])\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size, shuffle=True,\n",
    "                                           collate_fn=tomnet_collate_fn,\n",
    "                                           num_workers=16)\n",
    "val_loader   = torch.utils.data.DataLoader(test_ds,   batch_size, shuffle=False,\n",
    "                                           collate_fn=tomnet_collate_fn,\n",
    "\n",
    "                                           num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9687570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the required compute metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(model, loader, device):\n",
    "    model.eval()\n",
    "    all_goal_true, all_goal_pred = [], []\n",
    "    all_next_true, all_next_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for sup, prefix, next_idx, goal_idx, pre_len in loader:\n",
    "            sup = sup.to(device)\n",
    "            prefix = prefix.to(device)\n",
    "            pre_len = pre_len.to(device)\n",
    "            next_idx = next_idx.to(device)\n",
    "            goal_idx = goal_idx.to(device)\n",
    "            next_logits, goal_logits, *_ = model(sup, prefix, pre_len)\n",
    "            # Next-node prediction\n",
    "            next_pred = next_logits.argmax(dim=1)\n",
    "            all_next_true.extend(next_idx.cpu().numpy())\n",
    "            all_next_pred.extend(next_pred.cpu().numpy())\n",
    "            # Goal prediction\n",
    "            goal_pred = goal_logits.argmax(dim=1)\n",
    "            all_goal_true.extend(goal_idx.cpu().numpy())\n",
    "            all_goal_pred.extend(goal_pred.cpu().numpy())\n",
    "    # Accuracy\n",
    "    goal_acc = accuracy_score(all_goal_true, all_goal_pred)\n",
    "    next_acc = accuracy_score(all_next_true, all_next_pred)\n",
    "    # Confusion matrices\n",
    "    goal_cm = confusion_matrix(all_goal_true, all_goal_pred)\n",
    "    next_cm = confusion_matrix(all_next_true, all_next_pred)\n",
    "    return goal_acc, next_acc, goal_cm, next_cm\n",
    "\n",
    "def plot_and_log_confusion_matrix(cm, labels, title, wandb_key):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=False, fmt=\"d\", cmap=\"viridis\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    # Log to wandb\n",
    "    wandb.log({wandb_key: wandb.Image(plt.gcf())})\n",
    "    # plt.show()\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b356d-8f8c-4a3b-961a-557a501d1218",
   "metadata": {},
   "source": [
    "## Step 4: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b5078dd-6b02-497b-9a8a-0e77246e9573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 4090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d957b84-d77b-453c-9561-6332d62634ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# TODO: Need to play with the hyperparameters\n",
    "# 1) hyper‐parameters \n",
    "lr         = 1e-3\n",
    "weight_decay = 5e-4\n",
    "num_epochs = 30\n",
    "\n",
    "# 2) model, losses, optimizer\n",
    "model = ToMNet(\n",
    "    node_embeddings = node_embeddings,\n",
    "    num_nodes       = len(node2idx),\n",
    "    num_goals       = len(goal2idx),\n",
    "    T_sup           = 75\n",
    ").to(device)\n",
    "\n",
    "loss_next = nn.CrossEntropyLoss()\n",
    "loss_goal = nn.CrossEntropyLoss()\n",
    "opt       = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer=opt, mode='min', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633766e-6773-4729-b265-208b132619f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrah-m\u001b[0m (\u001b[33mrebot\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/Theory-of-mind/notebooks/wandb/run-20250709_144257-gfgyvct3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rebot/tomnet/runs/gfgyvct3' target=\"_blank\">New_TomNet_run</a></strong> to <a href='https://wandb.ai/rebot/tomnet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rebot/tomnet' target=\"_blank\">https://wandb.ai/rebot/tomnet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rebot/tomnet/runs/gfgyvct3' target=\"_blank\">https://wandb.ai/rebot/tomnet/runs/gfgyvct3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Acc: 0.205 | Next-node Acc: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Acc: 0.223 | Next-node Acc: 0.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Acc: 0.216 | Next-node Acc: 0.017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Acc: 0.239 | Next-node Acc: 0.023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Acc: 0.251 | Next-node Acc: 0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Acc: 0.252 | Next-node Acc: 0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Acc: 0.254 | Next-node Acc: 0.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Acc: 0.260 | Next-node Acc: 0.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Acc: 0.254 | Next-node Acc: 0.030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Acc: 0.258 | Next-node Acc: 0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Acc: 0.247 | Next-node Acc: 0.030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_148040/599476142.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(8, 6))\n",
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Acc: 0.250 | Next-node Acc: 0.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [Train]:  39%|███▉      | 448/1153 [00:23<00:14, 47.87it/s, train_loss=8.73]"
     ]
    }
   ],
   "source": [
    "beta = 1e-3  # TODO: Test out different values of annealing\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_state    = None\n",
    "patience          = 5\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Loss Weights\n",
    "goal_weight = 2.0\n",
    "\n",
    "# Initialize wandb at the start of your run (do this only once)\n",
    "wandb.init(project=\"tomnet\", name=\"New_TomNet_run\", config={\n",
    "    \"epochs\": num_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"lr\": lr,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"goal_weight\": goal_weight,\n",
    "})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\", leave=False)\n",
    "    \n",
    "    for sup, prefix, next_idx, goal_idx, pre_len in train_bar:\n",
    "        sup = sup.to(device)\n",
    "        prefix = prefix.to(device)\n",
    "        pre_len = pre_len.to(device)\n",
    "        next_idx = next_idx.to(device)\n",
    "        goal_idx = goal_idx.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        pred_next_logits, pred_goal_logits, mu_char, logvar_char, mu_mental, logvar_mental = model(sup, prefix, pre_len)\n",
    "\n",
    "        # KL divergence for both character and mental\n",
    "        kl_char = -0.5 * torch.sum(1 + logvar_char - mu_char.pow(2) - logvar_char.exp(), dim=1).mean()\n",
    "        kl_mental = -0.5 * torch.sum(1 + logvar_mental - mu_mental.pow(2) - logvar_mental.exp(), dim=1).mean()\n",
    "        loss_dvib = beta * (kl_char + kl_mental)\n",
    "\n",
    "        L_next = loss_next(pred_next_logits, next_idx)\n",
    "        L_goal = loss_goal(pred_goal_logits, goal_idx)\n",
    "        loss = L_next + goal_weight*L_goal + loss_dvib\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_train_loss += loss.item() * prefix.size(0)\n",
    "        train_bar.set_postfix(train_loss=loss.item())\n",
    "        \n",
    "    avg_train_loss = total_train_loss / n_train\n",
    "\n",
    "    # —————— Validation ——————\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch}/{num_epochs} [Val]  \", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for sup, prefix, next_idx, goal_idx, pre_len in val_bar:\n",
    "            sup     = sup.to(device)       # [B,K,T_sup]\n",
    "            prefix  = prefix.to(device)    # [B,T_q]\n",
    "            pre_len = pre_len.to(device)   # [B]\n",
    "            next_idx= next_idx.to(device)\n",
    "            goal_idx= goal_idx.to(device)\n",
    "    \n",
    "            # forward\n",
    "            next_logits, goal_logits, mu_char, logvar_char, mu_mental, logvar_mental = model(sup, prefix, pre_len)\n",
    "            L_next        = loss_next(next_logits, next_idx)\n",
    "            L_goal        = loss_goal(goal_logits,   goal_idx)\n",
    "            batch_loss    = (L_next + L_goal).item()\n",
    "    \n",
    "            total_val_loss += batch_loss * prefix.size(0)\n",
    "            val_bar.set_postfix(val_loss=batch_loss)\n",
    "    \n",
    "    avg_val_loss = total_val_loss / n_val\n",
    "\n",
    "    goal_acc, next_acc, goal_cm, next_cm = compute_metrics(model, val_loader, device)\n",
    "    per_goal_acc = goal_cm.diagonal() / goal_cm.sum(axis=1)\n",
    "    print(f\"Goal Acc: {goal_acc:.3f} | Next-node Acc: {next_acc:.3f}\")\n",
    "    # print(\"Goal Confusion Matrix:\\n\", goal_cm)\n",
    "    # print(\"Next-node Confusion Matrix:\\n\", next_cm)\n",
    "    # print(\"Per-goal accuracy:\", per_goal_acc)\n",
    "\n",
    "    # Log confusion matrices to wandb\n",
    "    goal_labels = [str(g) for g in range(len(goal2idx))]\n",
    "    next_labels = [str(n) for n in range(len(node2idx))]\n",
    "    plot_and_log_confusion_matrix(goal_cm, goal_labels, \"Goal Confusion Matrix\", \"goal_confusion_matrix\")\n",
    "    plot_and_log_confusion_matrix(next_cm, next_labels, \"Next-node Confusion Matrix\", \"next_confusion_matrix\")\n",
    "\n",
    "    # Log scalar metrics to wandb\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"goal_accuracy\": goal_acc,\n",
    "        \"next_node_accuracy\": next_acc,\n",
    "        \"per_goal_accuracy\": wandb.Histogram(per_goal_acc)\n",
    "    })\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # print a summary line\n",
    "    print(f\"Epoch {epoch}/{num_epochs}  \"\n",
    "          f\"train_loss={avg_train_loss:.4f}  val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    # save best\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_state    = model.state_dict()\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# finally, load best\n",
    "model.load_state_dict(best_state)\n",
    "print(\"Training complete. Best val loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce4944f-65b9-4d07-abbe-1cbd2ea660e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./../models/New_Tomnet_cuda.pth\", _use_new_zipfile_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77722b-6ada-4ea9-9b9d-de2fd758a966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19aa3684-fe0e-41a2-bb83-f60c2b2f6310",
   "metadata": {},
   "source": [
    "## Step 5: Testing and Evaluation with ToMnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5948eebd-b47f-43f2-9a09-198131fec605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_world_src.utils.metrics import brier_along_path, accuracy_along_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c7ac8-7199-4d54-a30f-24163b36e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def make_support_tensor(agent_id, episode_id, path_data, node2idx, K, T_sup):\n",
    "    # all eps for this agent\n",
    "    all_eps = [ep for ep in path_data.keys() if ep != episode_id]\n",
    "    # pick K random others:\n",
    "    support_eps = random.sample(all_eps, K)\n",
    "    sup_tensor = torch.zeros(K, T_sup, dtype=torch.long)\n",
    "    for k, ep in enumerate(support_eps):\n",
    "        raw = path_data[ep][agent_id]            # list of node‐ids\n",
    "        idxs = [node2idx[n] for n in raw]\n",
    "        L = min(len(idxs), T_sup)\n",
    "        sup_tensor[k, :L] = torch.tensor(idxs[:L], dtype=torch.long)\n",
    "    return sup_tensor  # (K×T_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb198264-b8ce-48e5-a108-09c77fb5b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_goal_dists(\n",
    "    model, agent_id, test_ep,\n",
    "    path_data, node2idx, goal2idx,\n",
    "    K, T_sup, T_q,\n",
    "    device='cuda'\n",
    "):\n",
    "    model.eval()\n",
    "    # 1) build support once\n",
    "    sup     = make_support_tensor(agent_id, test_ep, path_data, node2idx, K, T_sup)\n",
    "    sup     = sup.to(device).unsqueeze(0)     # add batch‐dim → [1,K,T_sup]\n",
    "\n",
    "    raw_seq = path_data[test_ep][agent_id]\n",
    "    idxs    = [node2idx[n] for n in raw_seq]\n",
    "    N       = len(idxs)\n",
    "\n",
    "    goal_dists = []   # will be list of length N each [num_goals]\n",
    "    with torch.no_grad():\n",
    "        for t in range(1, N):\n",
    "            # build prefix up to t (we treat t=0 as “no steps seen”)\n",
    "            prefix_len = min(t, T_q)\n",
    "            # pad prefix to T_q\n",
    "            prefix = torch.zeros(T_q, dtype=torch.long)\n",
    "            if prefix_len>0:\n",
    "                prefix[:prefix_len] = torch.tensor(idxs[:prefix_len], dtype=torch.long)\n",
    "            # move to device and batch‐dim\n",
    "            prefix     = prefix.to(device).unsqueeze(0)       # [1,T_q]\n",
    "            prefix_len = torch.tensor([prefix_len], dtype=torch.long, device=device)\n",
    "\n",
    "            # forward through ToMNet\n",
    "            _, goal_logits = model(sup, prefix, prefix_len)   # [1, num_goals]\n",
    "            p_goal = F.softmax(goal_logits, dim=-1)[0]        # remove batch‐dim → [num_goals]\n",
    "\n",
    "            goal_dists.append(p_goal.cpu().numpy())\n",
    "\n",
    "    return goal_dists   # shape (N × num_goals) array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4ad74-c445-4c2a-b224-5b84b538674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_id=2\n",
    "test_ep=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598a77b-1d5b-4b9d-b38e-5276a56f020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = infer_goal_dists(\n",
    "    model, agent_id, test_ep,\n",
    "    path_data, node2idx, goal2idx,\n",
    "    K=10, T_sup=75, T_q=20,\n",
    "    device='mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb6ba3-5d6e-45ba-bd24-eee03c3b783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878899dc-e522-4388-aba4-a8343dbf75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(path_data[test_ep][agent_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c7729b-0eff-4608-be85-58e16290ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal2idx: { goal_node_id → index }\n",
    "idx2goal = { idx: goal for goal, idx in goal2idx.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631dd72-3d54-43fa-9be4-0c8609ac470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_posteriors = [\n",
    "    { idx2goal[i]: float(p) for i, p in enumerate(prob_row) }\n",
    "    for prob_row in dists\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9624fb-4b64-4f68-9f6a-aead9e53a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = brier_along_path(path_data[test_ep][agent_id], \n",
    "                                  goal_data[test_ep][agent_id], \n",
    "                                  goal_posteriors, \n",
    "                                  goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a141571-85f0-4966-baf8-78a3d716ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc49a261-2859-4710-837e-302366b8435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_posteriors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
